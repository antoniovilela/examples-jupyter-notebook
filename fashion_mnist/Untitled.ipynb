{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([505., 142., 104.,  64.,  36.,  47.,  37.,  23.,  21.,  21.]),\n",
       " array([0.00030039, 0.0032699 , 0.00623942, 0.00920893, 0.01217845,\n",
       "        0.01514796, 0.01811748, 0.02108699, 0.02405651, 0.02702602,\n",
       "        0.02999554]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "plt.hist( reciprocal(3e-4, 3e-2).rvs(size=1000) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RandomizedSearchCV()\n",
      "\n",
      "Randomized search on hyper parameters.\n",
      "\n",
      "RandomizedSearchCV implements a \"fit\" and a \"score\" method.\n",
      "It also implements \"predict\", \"predict_proba\", \"decision_function\",\n",
      "\"transform\" and \"inverse_transform\" if they are implemented in the\n",
      "estimator used.\n",
      "\n",
      "The parameters of the estimator used to apply these methods are optimized\n",
      "by cross-validated search over parameter settings.\n",
      "\n",
      "In contrast to GridSearchCV, not all parameter values are tried out, but\n",
      "rather a fixed number of parameter settings is sampled from the specified\n",
      "distributions. The number of parameter settings that are tried is\n",
      "given by n_iter.\n",
      "\n",
      "If all parameters are presented as a list,\n",
      "sampling without replacement is performed. If at least one parameter\n",
      "is given as a distribution, sampling with replacement is used.\n",
      "It is highly recommended to use continuous distributions for continuous\n",
      "parameters.\n",
      "\n",
      "Read more in the :ref:`User Guide <randomized_parameter_search>`.\n",
      "\n",
      ".. versionadded:: 0.14\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "estimator : estimator object.\n",
      "    A object of that type is instantiated for each grid point.\n",
      "    This is assumed to implement the scikit-learn estimator interface.\n",
      "    Either estimator needs to provide a ``score`` function,\n",
      "    or ``scoring`` must be passed.\n",
      "\n",
      "param_distributions : dict or list of dicts\n",
      "    Dictionary with parameters names (`str`) as keys and distributions\n",
      "    or lists of parameters to try. Distributions must provide a ``rvs``\n",
      "    method for sampling (such as those from scipy.stats.distributions).\n",
      "    If a list is given, it is sampled uniformly.\n",
      "    If a list of dicts is given, first a dict is sampled uniformly, and\n",
      "    then a parameter is sampled using that dict as above.\n",
      "\n",
      "n_iter : int, default=10\n",
      "    Number of parameter settings that are sampled. n_iter trades\n",
      "    off runtime vs quality of the solution.\n",
      "\n",
      "scoring : str, callable, list/tuple or dict, default=None\n",
      "    A single str (see :ref:`scoring_parameter`) or a callable\n",
      "    (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
      "\n",
      "    For evaluating multiple metrics, either give a list of (unique) strings\n",
      "    or a dict with names as keys and callables as values.\n",
      "\n",
      "    NOTE that when using custom scorers, each scorer should return a single\n",
      "    value. Metric functions returning a list/array of values can be wrapped\n",
      "    into multiple scorers that return one value each.\n",
      "\n",
      "    See :ref:`multimetric_grid_search` for an example.\n",
      "\n",
      "    If None, the estimator's score method is used.\n",
      "\n",
      "n_jobs : int, default=None\n",
      "    Number of jobs to run in parallel.\n",
      "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "    for more details.\n",
      "\n",
      "    .. versionchanged:: v0.20\n",
      "       `n_jobs` default changed from 1 to None\n",
      "\n",
      "pre_dispatch : int, or str, default=None\n",
      "    Controls the number of jobs that get dispatched during parallel\n",
      "    execution. Reducing this number can be useful to avoid an\n",
      "    explosion of memory consumption when more jobs get dispatched\n",
      "    than CPUs can process. This parameter can be:\n",
      "\n",
      "        - None, in which case all the jobs are immediately\n",
      "          created and spawned. Use this for lightweight and\n",
      "          fast-running jobs, to avoid delays due to on-demand\n",
      "          spawning of the jobs\n",
      "\n",
      "        - An int, giving the exact number of total jobs that are\n",
      "          spawned\n",
      "\n",
      "        - A str, giving an expression as a function of n_jobs,\n",
      "          as in '2*n_jobs'\n",
      "\n",
      "iid : bool, default=False\n",
      "    If True, return the average score across folds, weighted by the number\n",
      "    of samples in each test set. In this case, the data is assumed to be\n",
      "    identically distributed across the folds, and the loss minimized is\n",
      "    the total loss per sample, and not the mean loss across the folds.\n",
      "\n",
      "    .. deprecated:: 0.22\n",
      "        Parameter ``iid`` is deprecated in 0.22 and will be removed in 0.24\n",
      "\n",
      "cv : int, cross-validation generator or an iterable, default=None\n",
      "    Determines the cross-validation splitting strategy.\n",
      "    Possible inputs for cv are:\n",
      "\n",
      "    - None, to use the default 5-fold cross validation,\n",
      "    - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      "    - :term:`CV splitter`,\n",
      "    - An iterable yielding (train, test) splits as arrays of indices.\n",
      "\n",
      "    For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      "    either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "    other cases, :class:`KFold` is used.\n",
      "\n",
      "    Refer :ref:`User Guide <cross_validation>` for the various\n",
      "    cross-validation strategies that can be used here.\n",
      "\n",
      "    .. versionchanged:: 0.22\n",
      "        ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "\n",
      "refit : bool, str, or callable, default=True\n",
      "    Refit an estimator using the best found parameters on the whole\n",
      "    dataset.\n",
      "\n",
      "    For multiple metric evaluation, this needs to be a `str` denoting the\n",
      "    scorer that would be used to find the best parameters for refitting\n",
      "    the estimator at the end.\n",
      "\n",
      "    Where there are considerations other than maximum score in\n",
      "    choosing a best estimator, ``refit`` can be set to a function which\n",
      "    returns the selected ``best_index_`` given the ``cv_results``. In that\n",
      "    case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      "    according to the returned ``best_index_`` while the ``best_score_``\n",
      "    attribute will not be available.\n",
      "\n",
      "    The refitted estimator is made available at the ``best_estimator_``\n",
      "    attribute and permits using ``predict`` directly on this\n",
      "    ``RandomizedSearchCV`` instance.\n",
      "\n",
      "    Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      "    ``best_score_`` and ``best_params_`` will only be available if\n",
      "    ``refit`` is set and all of them will be determined w.r.t this specific\n",
      "    scorer.\n",
      "\n",
      "    See ``scoring`` parameter to know more about multiple metric\n",
      "    evaluation.\n",
      "\n",
      "    .. versionchanged:: 0.20\n",
      "        Support for callable added.\n",
      "\n",
      "verbose : integer\n",
      "    Controls the verbosity: the higher, the more messages.\n",
      "\n",
      "random_state : int or RandomState instance, default=None\n",
      "    Pseudo random number generator state used for random uniform sampling\n",
      "    from lists of possible values instead of scipy.stats distributions.\n",
      "    Pass an int for reproducible output across multiple\n",
      "    function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "error_score : 'raise' or numeric, default=np.nan\n",
      "    Value to assign to the score if an error occurs in estimator fitting.\n",
      "    If set to 'raise', the error is raised. If a numeric value is given,\n",
      "    FitFailedWarning is raised. This parameter does not affect the refit\n",
      "    step, which will always raise the error.\n",
      "\n",
      "return_train_score : bool, default=False\n",
      "    If ``False``, the ``cv_results_`` attribute will not include training\n",
      "    scores.\n",
      "    Computing training scores is used to get insights on how different\n",
      "    parameter settings impact the overfitting/underfitting trade-off.\n",
      "    However computing the scores on the training set can be computationally\n",
      "    expensive and is not strictly required to select the parameters that\n",
      "    yield the best generalization performance.\n",
      "\n",
      "    .. versionadded:: 0.19\n",
      "\n",
      "    .. versionchanged:: 0.21\n",
      "        Default value was changed from ``True`` to ``False``\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "cv_results_ : dict of numpy (masked) ndarrays\n",
      "    A dict with keys as column headers and values as columns, that can be\n",
      "    imported into a pandas ``DataFrame``.\n",
      "\n",
      "    For instance the below given table\n",
      "\n",
      "    +--------------+-------------+-------------------+---+---------------+\n",
      "    | param_kernel | param_gamma | split0_test_score |...|rank_test_score|\n",
      "    +==============+=============+===================+===+===============+\n",
      "    |    'rbf'     |     0.1     |       0.80        |...|       2       |\n",
      "    +--------------+-------------+-------------------+---+---------------+\n",
      "    |    'rbf'     |     0.2     |       0.90        |...|       1       |\n",
      "    +--------------+-------------+-------------------+---+---------------+\n",
      "    |    'rbf'     |     0.3     |       0.70        |...|       1       |\n",
      "    +--------------+-------------+-------------------+---+---------------+\n",
      "\n",
      "    will be represented by a ``cv_results_`` dict of::\n",
      "\n",
      "        {\n",
      "        'param_kernel' : masked_array(data = ['rbf', 'rbf', 'rbf'],\n",
      "                                      mask = False),\n",
      "        'param_gamma'  : masked_array(data = [0.1 0.2 0.3], mask = False),\n",
      "        'split0_test_score'  : [0.80, 0.90, 0.70],\n",
      "        'split1_test_score'  : [0.82, 0.50, 0.70],\n",
      "        'mean_test_score'    : [0.81, 0.70, 0.70],\n",
      "        'std_test_score'     : [0.01, 0.20, 0.00],\n",
      "        'rank_test_score'    : [3, 1, 1],\n",
      "        'split0_train_score' : [0.80, 0.92, 0.70],\n",
      "        'split1_train_score' : [0.82, 0.55, 0.70],\n",
      "        'mean_train_score'   : [0.81, 0.74, 0.70],\n",
      "        'std_train_score'    : [0.01, 0.19, 0.00],\n",
      "        'mean_fit_time'      : [0.73, 0.63, 0.43],\n",
      "        'std_fit_time'       : [0.01, 0.02, 0.01],\n",
      "        'mean_score_time'    : [0.01, 0.06, 0.04],\n",
      "        'std_score_time'     : [0.00, 0.00, 0.00],\n",
      "        'params'             : [{'kernel' : 'rbf', 'gamma' : 0.1}, ...],\n",
      "        }\n",
      "\n",
      "    NOTE\n",
      "\n",
      "    The key ``'params'`` is used to store a list of parameter\n",
      "    settings dicts for all the parameter candidates.\n",
      "\n",
      "    The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      "    ``std_score_time`` are all in seconds.\n",
      "\n",
      "    For multi-metric evaluation, the scores for all the scorers are\n",
      "    available in the ``cv_results_`` dict at the keys ending with that\n",
      "    scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      "    above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      "\n",
      "best_estimator_ : estimator\n",
      "    Estimator that was chosen by the search, i.e. estimator\n",
      "    which gave highest score (or smallest loss if specified)\n",
      "    on the left out data. Not available if ``refit=False``.\n",
      "\n",
      "    For multi-metric evaluation, this attribute is present only if\n",
      "    ``refit`` is specified.\n",
      "\n",
      "    See ``refit`` parameter for more information on allowed values.\n",
      "\n",
      "best_score_ : float\n",
      "    Mean cross-validated score of the best_estimator.\n",
      "\n",
      "    For multi-metric evaluation, this is not available if ``refit`` is\n",
      "    ``False``. See ``refit`` parameter for more information.\n",
      "\n",
      "    This attribute is not available if ``refit`` is a function.\n",
      "\n",
      "best_params_ : dict\n",
      "    Parameter setting that gave the best results on the hold out data.\n",
      "\n",
      "    For multi-metric evaluation, this is not available if ``refit`` is\n",
      "    ``False``. See ``refit`` parameter for more information.\n",
      "\n",
      "best_index_ : int\n",
      "    The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      "    candidate parameter setting.\n",
      "\n",
      "    The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      "    the parameter setting for the best model, that gives the highest\n",
      "    mean score (``search.best_score_``).\n",
      "\n",
      "    For multi-metric evaluation, this is not available if ``refit`` is\n",
      "    ``False``. See ``refit`` parameter for more information.\n",
      "\n",
      "scorer_ : function or a dict\n",
      "    Scorer function used on the held out data to choose the best\n",
      "    parameters for the model.\n",
      "\n",
      "    For multi-metric evaluation, this attribute holds the validated\n",
      "    ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      "\n",
      "n_splits_ : int\n",
      "    The number of cross-validation splits (folds/iterations).\n",
      "\n",
      "refit_time_ : float\n",
      "    Seconds used for refitting the best model on the whole dataset.\n",
      "\n",
      "    This is present only if ``refit`` is not False.\n",
      "\n",
      "    .. versionadded:: 0.20\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The parameters selected are those that maximize the score of the held-out\n",
      "data, according to the scoring parameter.\n",
      "\n",
      "If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      "parameter setting(and not `n_jobs` times). This is done for efficiency\n",
      "reasons if individual jobs take very little time, but may raise errors if\n",
      "the dataset is large and not enough memory is available.  A workaround in\n",
      "this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      "`pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      "n_jobs`.\n",
      "\n",
      "See Also\n",
      "--------\n",
      ":class:`GridSearchCV`:\n",
      "    Does exhaustive search over a grid of parameters.\n",
      "\n",
      ":class:`ParameterSampler`:\n",
      "    A generator over parameter settings, constructed from\n",
      "    param_distributions.\n",
      "\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.datasets import load_iris\n",
      ">>> from sklearn.linear_model import LogisticRegression\n",
      ">>> from sklearn.model_selection import RandomizedSearchCV\n",
      ">>> from scipy.stats import uniform\n",
      ">>> iris = load_iris()\n",
      ">>> logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n",
      "...                               random_state=0)\n",
      ">>> distributions = dict(C=uniform(loc=0, scale=4),\n",
      "...                      penalty=['l2', 'l1'])\n",
      ">>> clf = RandomizedSearchCV(logistic, distributions, random_state=0)\n",
      ">>> search = clf.fit(iris.data, iris.target)\n",
      ">>> search.best_params_\n",
      "{'C': 2..., 'penalty': 'l1'}\n",
      "\n",
      "\n",
      "Methods:\n",
      "\n",
      "  decision_function  --  Call decision_function on the estimator with the best found parameters.\n",
      "  fit  --  Run fit with all sets of parameters.\n",
      "  get_params  --  Get parameters for this estimator.\n",
      "  inverse_transform  --  Call inverse_transform on the estimator with the best found params.\n",
      "  predict  --  Call predict on the estimator with the best found parameters.\n",
      "  predict_log_proba  --  Call predict_log_proba on the estimator with the best found parameters.\n",
      "  predict_proba  --  Call predict_proba on the estimator with the best found parameters.\n",
      "  score  --  Returns the score on the given data, if the estimator has been refit.\n",
      "  set_params  --  Set the parameters of this estimator.\n",
      "  transform  --  Call transform on the estimator with the best found parameters.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "np.info( RandomizedSearchCV )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
