{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print ( \"sklearn: {}\".format(sklearn.__version__) )\n",
    "print ( \"tensorflow: {}\".format(tf.__version__) )\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( X_train.shape )\n",
    "X_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i_entry = 20\n",
    "plt.imshow( X_train[i_entry], cmap=\"binary\" )\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "class_names[ y_train[i_entry] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = X_train.mean( axis=0 )\n",
    "X_std = X_train.std( axis=0 )\n",
    "X_train_scaled = ( X_train - X_mean ) / X_std\n",
    "X_valid_scaled = ( X_valid - X_mean ) / X_std\n",
    "X_test_scaled  = ( X_test - X_mean ) / X_std\n",
    "X_train_scaled[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model build function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=50, learning_rate=5e-4, input_shape=[28,28], dropout=0.20):\n",
    "    print( \"Building model with:\" )\n",
    "    print( \"Number of hidden layers: {}\".format(n_hidden) )\n",
    "    print( \"Number of neurons per layer: {}\".format(n_neurons) )\n",
    "    print( \"Learning rate: {}\".format(learning_rate) )\n",
    "    print( \"Input shape: {}\".format(input_shape) )\n",
    "    print( \"Dropout rate: {}\".format(dropout) )\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add( keras.layers.Flatten(input_shape=input_shape) )\n",
    "    for layer in range(n_hidden):\n",
    "        if dropout > 0.:\n",
    "            model.add( keras.layers.Dropout(rate=dropout) )\n",
    "        model.add( keras.layers.Dense(n_neurons, activation=\"elu\", kernel_initializer=\"he_normal\") )\n",
    "    if dropout > 0.:\n",
    "        model.add( keras.layers.Dropout(rate=dropout) )    \n",
    "    model.add( keras.layers.Dense(10, activation=\"softmax\") )\n",
    "    \n",
    "    #optimizer = keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "    optimizer = keras.optimizers.Nadam(lr=learning_rate)\n",
    "    model.compile( loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir(log_dir):\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(log_dir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callbacks(patience=10, log_dir=\"\"):\n",
    "    callbacks_ = []\n",
    "    # Early stopping\n",
    "    if patience > 0:\n",
    "        early_stopping_cb_ = keras.callbacks.EarlyStopping( patience=patience, restore_best_weights=True )\n",
    "        callbacks_.append( early_stopping_cb_ )\n",
    "        \n",
    "    # TensorBoard\n",
    "    if log_dir:\n",
    "        run_logdir = get_run_logdir(log_dir)\n",
    "        print ( \"Log dir: {}\".format(run_logdir) )\n",
    "        tensorboard_cb_ = keras.callbacks.TensorBoard( run_logdir )\n",
    "        callbacks_.append( tensorboard_cb_ )\n",
    "    \n",
    "    return callbacks_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_dir=\"fashion_mnist_logs\"\n",
    "callbacks_ = callbacks(patience=10, log_dir=log_dir)\n",
    "callbacks_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_learning_rate( lr_init=1e-4, lr_end=5e-2, steps=20, epochs=30, model_build_fn=build_model, *build_fn_args, **build_fn_kwargs ):\n",
    "    results_ = {}\n",
    "    results_['learning_rate'] = []\n",
    "    results_['loss'] = []\n",
    "    results_['accuracy'] = []\n",
    "    results_['val_loss'] = []\n",
    "    results_['val_accuracy'] = []\n",
    "    c_ = (lr_end/lr_init) ** (1/steps)\n",
    "    lr_ = lr_init\n",
    "    for i_it in range( steps + 1 ):\n",
    "        results_['learning_rate'].append( lr_ )\n",
    "        model_ = model_build_fn( *build_fn_args, **build_fn_kwargs, learning_rate=lr_ )\n",
    "        callbacks_ = callbacks(patience=10)\n",
    "        history_ = model_.fit( X_train_scaled, y_train, epochs=epochs, validation_data=(X_valid_scaled, y_valid), callbacks=callbacks_ )\n",
    "        results_['loss'].append( history_.history['loss'] )\n",
    "        results_['accuracy'].append( history_.history['accuracy'] )\n",
    "        results_['val_loss'].append( history_.history['val_loss'] )\n",
    "        results_['val_accuracy'].append( history_.history['val_accuracy'] )\n",
    "        # Update lerning rate\n",
    "        lr_ = lr_ * c_\n",
    "        \n",
    "    return results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = find_max_learning_rate(\n",
    "            lr_init=1e-4,\n",
    "            lr_end=2e-2,\n",
    "            steps=10,\n",
    "            epochs=20,\n",
    "            model_build_fn=build_model,\n",
    "            n_hidden=5,\n",
    "            n_neurons=100,\n",
    "            input_shape=[28,28],\n",
    "            dropout=0.40\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame( np.array( results['val_loss'] ).T,\n",
    "#              columns=[\"lr_{}\".format(lr_) for lr_ in np.round( results['learning_rate'], 4)]  ).plot( figsize=(12,10) )\n",
    "\n",
    "epochs=20\n",
    "metrics_ = 'val_loss'\n",
    "columns=[\"lr_{}\".format(lr_) for lr_ in np.round( results['learning_rate'], 4)] \n",
    "df = pd.DataFrame( np.full((epochs,len(columns)),np.nan), columns=columns ) \n",
    "for i_lr_,col_ in enumerate(columns):\n",
    "    df[col_] = pd.Series( results[ metrics_ ][i_lr_] )\n",
    "df.plot( figsize=(12,10) )\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "build_fn_ = lambda n_hidden, n_neurons: build_model(n_hidden, n_neurons, learning_rate=8e-4, input_shape=[28,28], dropout=0.40)\n",
    "\n",
    "keras_clf = keras.wrappers.scikit_learn.KerasClassifier( build_fn_ )\n",
    "\n",
    "param_grid = [\n",
    "    { \"n_hidden\": np.arange(1,5),\n",
    "      \"n_neurons\": [10,20,50,100] }\n",
    "    ]\n",
    "\n",
    "grid_search = GridSearchCV( keras_clf, param_grid, cv=4 )\n",
    "\n",
    "callbacks_ = callbacks(patience=10)\n",
    "print ( callbacks_ )\n",
    "\n",
    "grid_search.fit( X_train_scaled, y_train, epochs=100, validation_data=(X_valid_scaled, y_valid), callbacks=callbacks_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model( \n",
    "    n_hidden=5,\n",
    "    n_neurons=100,\n",
    "    learning_rate=8e-4,\n",
    "    input_shape=[28,28],\n",
    "    dropout=0.40\n",
    "    )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"fashion_mnist_logs\"\n",
    "callbacks_ = callbacks(patience=10, log_dir=log_dir)\n",
    "print ( callbacks_ )\n",
    "\n",
    "history = model.fit( X_train_scaled, y_train, epochs=100, validation_data=(X_valid_scaled, y_valid), callbacks=callbacks_ )\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame( history.history ).plot( figsize=(12,10) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on training data (without dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate( X_train_scaled, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(keras.wrappers.scikit_learn.KerasClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
