{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: 0.23.2\n",
      "tensorflow: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print ( \"sklearn: {}\".format(sklearn.__version__) )\n",
    "print ( \"tensorflow: {}\".format(tf.__version__) )\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.29019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.05882353, 0.3254902 , 0.        , 0.        ,\n",
       "        0.        , 0.00392157, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1372549 , 0.58431373, 0.78823529,\n",
       "        0.91764706, 0.83529412, 0.82745098, 0.64313725, 0.65098039,\n",
       "        0.80784314, 0.89019608, 0.89411765, 0.74901961, 0.58823529,\n",
       "        0.05882353, 0.        , 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.22352941, 0.84313725, 0.96862745, 0.93333333,\n",
       "        0.88235294, 0.8627451 , 0.79607843, 0.72156863, 0.75294118,\n",
       "        0.69019608, 0.71372549, 0.84705882, 0.77254902, 0.71764706,\n",
       "        0.4627451 , 0.04313725, 0.        , 0.00784314, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.00392157, 0.        ,\n",
       "        0.04705882, 0.32941176, 0.03137255, 0.11372549, 0.30588235,\n",
       "        0.4627451 , 0.11372549, 0.03921569, 0.03529412, 0.50980392,\n",
       "        0.23921569, 0.08627451, 0.11764706, 0.01568627, 0.        ,\n",
       "        0.3372549 , 0.66666667, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.00784314, 0.        ,\n",
       "        0.17647059, 0.55686275, 0.57254902, 0.23921569, 0.        ,\n",
       "        0.01176471, 0.        , 0.03137255, 0.        , 0.14901961,\n",
       "        0.2627451 , 0.00392157, 0.        , 0.04313725, 0.40392157,\n",
       "        0.30588235, 0.83137255, 0.07843137, 0.        , 0.00392157,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.00392157, 0.        ,\n",
       "        0.11764706, 0.3254902 , 0.36470588, 0.05490196, 0.00392157,\n",
       "        0.10196078, 0.03921569, 0.16470588, 0.12156863, 0.0745098 ,\n",
       "        0.09411765, 0.        , 0.0745098 , 0.        , 0.10196078,\n",
       "        0.37254902, 0.60392157, 0.14901961, 0.        , 0.00392157,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.28235294, 0.51764706, 0.62745098, 0.41960784, 0.25882353,\n",
       "        0.41568627, 0.31372549, 0.29019608, 0.20392157, 0.44313725,\n",
       "        0.5372549 , 0.22352941, 0.55686275, 0.67058824, 0.87843137,\n",
       "        0.80784314, 0.75294118, 0.54901961, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.01568627,\n",
       "        0.81960784, 0.6745098 , 0.77254902, 0.09803922, 0.01568627,\n",
       "        0.15294118, 0.        , 0.07843137, 0.15294118, 0.04313725,\n",
       "        0.        , 0.        , 0.        , 0.23137255, 0.60784314,\n",
       "        0.77254902, 0.45490196, 0.63921569, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.20784314, 0.30980392, 0.59215686, 0.13333333, 0.00784314,\n",
       "        0.        , 0.        , 0.01568627, 0.19215686, 0.14901961,\n",
       "        0.        , 0.01176471, 0.16470588, 0.29019608, 0.72941176,\n",
       "        0.60392157, 0.05882353, 0.29411765, 0.01568627, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.2745098 , 0.41568627, 0.68627451, 0.43921569, 0.07843137,\n",
       "        0.        , 0.04313725, 0.01176471, 0.00392157, 0.1372549 ,\n",
       "        0.05098039, 0.01176471, 0.20392157, 0.02352941, 0.69019608,\n",
       "        0.14117647, 0.24705882, 0.60392157, 0.07843137, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.16470588, 0.10196078, 0.71372549, 0.5254902 , 0.39607843,\n",
       "        0.1372549 , 0.52941176, 0.59215686, 0.03137255, 0.6627451 ,\n",
       "        0.59215686, 0.34901961, 0.72156863, 0.59607843, 0.72941176,\n",
       "        0.03921569, 0.15294118, 0.47058824, 0.15294118, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.65490196,\n",
       "        0.65490196, 0.47058824, 0.83921569, 0.63921569, 0.29803922,\n",
       "        0.01568627, 0.02352941, 0.24705882, 0.        , 0.09803922,\n",
       "        0.1372549 , 0.        , 0.2627451 , 0.31372549, 0.93333333,\n",
       "        0.49411765, 0.49019608, 0.68235294, 0.75686275, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.07843137, 0.44705882,\n",
       "        0.03529412, 0.38039216, 0.2627451 , 0.05098039, 0.15686275,\n",
       "        0.08627451, 0.14509804, 0.25490196, 0.1254902 , 0.05882353,\n",
       "        0.01568627, 0.        , 0.07058824, 0.02352941, 0.29803922,\n",
       "        0.21176471, 0.27843137, 0.14901961, 0.86666667, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.09411765, 0.40392157,\n",
       "        0.        , 0.88627451, 0.56862745, 0.        , 0.11764706,\n",
       "        0.        , 0.44705882, 0.22745098, 0.01960784, 0.07843137,\n",
       "        0.        , 0.01176471, 0.03137255, 0.23921569, 0.19215686,\n",
       "        0.41960784, 0.55294118, 0.        , 0.71372549, 0.27843137,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.26666667, 0.56470588,\n",
       "        0.00392157, 0.89019608, 0.5254902 , 0.01960784, 0.28235294,\n",
       "        0.        , 0.50196078, 0.32941176, 0.        , 0.07843137,\n",
       "        0.14117647, 0.        , 0.00784314, 0.10588235, 0.34901961,\n",
       "        0.41960784, 1.        , 0.44313725, 0.6       , 0.27843137,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.6       , 0.6       ,\n",
       "        0.47058824, 0.64313725, 0.49803922, 0.25098039, 0.4627451 ,\n",
       "        0.51372549, 0.36862745, 0.58039216, 0.75686275, 0.9372549 ,\n",
       "        0.        , 0.03921569, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01176471, 0.        , 0.01960784, 0.42352941, 0.10588235,\n",
       "        0.44313725, 0.03137255, 0.        , 0.06666667, 0.01960784,\n",
       "        0.        , 0.07843137, 0.05490196, 0.05490196, 0.85098039,\n",
       "        0.        , 0.        , 0.        , 0.00392157, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.00392157, 0.        ,\n",
       "        0.00392157, 0.        , 0.01568627, 0.29411765, 0.16470588,\n",
       "        0.25098039, 0.10588235, 0.12941176, 0.08235294, 0.        ,\n",
       "        0.        , 0.05882353, 0.01176471, 0.        , 0.52156863,\n",
       "        0.00392157, 0.        , 0.01176471, 0.00784314, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01960784, 0.2745098 , 0.14901961,\n",
       "        0.41568627, 0.14509804, 0.1372549 , 0.07058824, 0.07843137,\n",
       "        0.30196078, 0.22352941, 0.        , 0.05882353, 0.39215686,\n",
       "        0.02352941, 0.        , 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.29411765, 0.        ,\n",
       "        0.09803922, 0.        , 0.00784314, 0.0745098 , 0.04705882,\n",
       "        0.39607843, 0.14509804, 0.04313725, 0.00392157, 0.19215686,\n",
       "        0.09411765, 0.        , 0.01176471, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01176471, 0.        , 0.        , 0.90980392, 0.49411765,\n",
       "        0.63137255, 0.62745098, 0.29019608, 0.43137255, 0.29411765,\n",
       "        0.25098039, 0.08235294, 0.22745098, 0.19607843, 0.5254902 ,\n",
       "        0.24313725, 0.        , 0.01176471, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.01176471, 0.        , 0.03137255, 0.83529412, 0.44705882,\n",
       "        0.69803922, 0.34509804, 0.03921569, 0.10588235, 0.10196078,\n",
       "        0.05098039, 0.11372549, 0.        , 0.02352941, 0.23137255,\n",
       "        0.08235294, 0.        , 0.01568627, 0.00392157, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.        , 0.        , 0.61176471, 0.        ,\n",
       "        0.10196078, 0.        , 0.        , 0.04705882, 0.02352941,\n",
       "        0.23921569, 0.25882353, 0.11764706, 0.03529412, 0.03137255,\n",
       "        0.06666667, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01960784, 0.60784314, 0.20392157,\n",
       "        0.11372549, 0.09411765, 0.        , 0.15686275, 0.08235294,\n",
       "        0.        , 0.05098039, 0.42352941, 0.        , 0.04705882,\n",
       "        0.19607843, 0.        , 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.        , 0.00784314, 0.69411765, 0.36862745,\n",
       "        0.2745098 , 0.20392157, 0.18431373, 0.21568627, 0.23529412,\n",
       "        0.29411765, 0.04705882, 0.21960784, 0.30980392, 0.48627451,\n",
       "        0.6627451 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.00392157, 0.        ,\n",
       "        0.00392157, 0.        , 0.17254902, 0.72941176, 0.05490196,\n",
       "        0.39607843, 0.20392157, 0.05490196, 0.        , 0.1254902 ,\n",
       "        0.47058824, 0.00784314, 0.26666667, 0.37254902, 0.36470588,\n",
       "        0.49803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00784314, 0.        , 0.08235294, 0.16862745, 0.        ,\n",
       "        0.43921569, 0.32156863, 0.29411765, 0.32156863, 0.1372549 ,\n",
       "        0.40784314, 0.03921569, 0.39215686, 0.25490196, 0.22352941,\n",
       "        0.47058824, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00784314, 0.        , 0.01176471, 0.27843137, 0.23529412,\n",
       "        0.16470588, 0.26666667, 0.31372549, 0.19607843, 0.3372549 ,\n",
       "        0.49803922, 0.32156863, 0.37254902, 0.33333333, 0.51372549,\n",
       "        0.40392157, 0.        , 0.        , 0.00392157, 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ( X_train.shape )\n",
    "X_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAIU0lEQVR4nO3dO49VZRsG4DXjcJCTAuIBCgRRIaGg5SdAZUJnYuUfoeYPUFnQEaKlFZ0dhygowRgOhijhpA5HOQgzVlbfrOfxm535uIfvusq586699xruWcl+eNeamp+fH4A80y/7DQALU04IpZwQSjkhlHJCqJkm91UuLL2phX7oygmhlBNCKSeEUk4IpZwQSjkhlHJCKOWEUMoJoZQTQiknhFJOCKWcEEo5IZRyQijlhFDKCaGUE0IpJ4RSTgilnBBKOSGUckIo5YRQygmhlBNCKSeEUk4IpZwQSjkhlHJCKOWEUMoJoZQTQiknhFJOCKWcEEo5IZRyQijlhFDKCaGUE0IpJ4RSTgilnBBKOSHUzMt+A/+P5ufnR7Opqaklfe25ubkyn55eur/XX331VZkfOnRo0ceuzukwLP15XQqunBBKOSGUckIo5YRQygmhlBNCTTVfQdffTxNnKUcK3bE///zzMv/xxx/L/Pnz56PZmTNnyrUvUzee6kxPTy/4S3HlhFDKCaGUE0IpJ4RSTgilnBBKOSGUOecrZim3hH322WdlvmnTpjK/efNmmZ89e3Y0++STT8q1R44cKfPXXnutzF8yc05YTpQTQiknhFJOCKWcEEo5IZRyQii3xnzFdHsuO7/88sto1s0pHz16VOa3b98u848++mg0O3XqVLl27dq1Zb5nz54y//TTT8u8muFu3bq1XHvgwIEyH+PKCaGUE0IpJ4RSTgilnBBKOSGUckIoc85XzIsXL8q829dYzROfPHlSrn3rrbfK/OHDh2Ve3be2u99uN8fctm1bmX///fdlfv/+/dGsOy87duwo8927dy/4c1dOCKWcEEo5IZRyQijlhFDKCaGUE0KZcy4z3X7NlStXTnT8as65a9euiY79/vvvl/nFixdHs24+281333777TLvZrTr1q0bzWZnZ8u1O3fuLPMxrpwQSjkhlHJCKOWEUMoJoZQTQhmlLDPd1qnO6dOny/yLL74YzQ4ePFiuffDgQZmPbY36x+rVq0ezaswyDP12tB9++KHMN2/eXOZ//fXXaLZq1apy7WLHW66cEEo5IZRyQijlhFDKCaGUE0IpJ4SaqrYgzTf7kyadufHfe/bsWZl//fXXZX7lypUyr36nJ0+eLNd2W8Kq20sOQz1LfPr0abn20qVLZf748eMyX79+fZnPzIz/l4BuG9+5c+fKfBiGBU+6KyeEUk4IpZwQSjkhlHJCKOWEUMoJocr9nOaYS+PRo0ej2fHjx8u13Ryzu0XkBx98UObVLSi7OWY3a+xmlRs2bBjNqhnoMPSf6/fffy/ze/fulfnrr78+mnXvbbFcOSGUckIo5YRQygmhlBNCKSeEUk4INdF9a7t9bHNzc6PZUs9Qq+NP+to3b94s8y+//LLMv/3229Gsm1N+/PHHZX7r1q0y/+6778q8mudNT9d/y69fv17m3Tywewxfpfq3NgzDsGXLljJ/5513yrzaR/vzzz+Xa588eVLmY/frdeWEUMoJoZQTQiknhFJOCKWcEEo5IdREc85uXljtDUx29OjRMj927FiZ79q1q8w3bdo0mnWzwm4/56TnvLq3bDenrD7XMAzDjRs3ynx2dnY062asv/32W5l3z8is9pIOwzDs3LlzNOvOS7eXdNu2bQv+3JUTQiknhFJOCKWcEEo5IZRyQqiJRimdbhtPpbtVYTdy+PXXX0ezb775plzbbQnbt29fmXe3gLxw4cJo1o2n3nzzzTJfsWJFmXfvrdqytnbt2nJtNQoZhmF47733yry6veX58+fLtQ8ePCjzHTt2lHn32arbmVbb7Iah3wY4xpUTQiknhFJOCKWcEEo5IZRyQijlhFDlnLObzxw+fLjMq9lTNxvqZqTdNp3nz58v+tjdLLHbllXdRrEzM1OPnrvX7s7LJLcF7WbPb7zxRpl38+FqS9mHH35Yrt27d2+Zd7dxreaY3fpuu9rjx4/LfIwrJ4RSTgilnBBKOSGUckIo5YRQygmhpqr5zdzcXDkcunr1annw6lF3P/30U7n29u3bZd49Vq3SzZ2q20MOwzDcuXOnzLtZZPXZx26T+I/Lly+X+STz32EYhu3bt49m3aPuullj9zu7e/fuaLZ79+5y7cOHD8u8s2rVqjKv5vLd/wc4ceJEmb/77rsLDp9dOSGUckIo5YRQygmhlBNCKSeEUk4IVc457969W845u5nali1bFveu/oVub2H12LVujtnNzLp53SSfuzunGzduLPNu32I3k6tev5vfdjPU7ne2fv36Rb92d7/e7hGA69atK/M1a9aMZt0e2W6uvnnzZnNOWE6UE0IpJ4RSTgilnBBKOSFUOUp59uxZ+b38tWvXyoNXX52vXr26XLthw4Yy70YK1SPdpqcn+5vUbZ3qHkdXfa3fjVK6UUg3zug+e3X87tjde+tu+1l99u68/Pnnn2W+2Mfw/RvdsbtHH+7fv98oBZYT5YRQygmhlBNCKSeEUk4IpZwQqpxzDsNQ7z9qVMfuZoGzs7Nl3j3G7+nTp6NZN6/r5nF//PHHRHl1m8Xu0Yjd1qlu+1K3tapa321H6157kvXdsbv5bXfeuvNezaa797Z169YyH4bBnBOWE+WEUMoJoZQTQiknhFJOCKWcEGpJ55zAv2LOCcuJckIo5YRQygmhlBNCKSeEUk4IpZwQSjkhlHJCKOWEUMoJoZQTQiknhFJOCKWcEEo5IZRyQijlhFDKCaGUE0IpJ4RSTgilnBBKOSGUckIo5YRQygmhlBNCKSeEUk4IpZwQSjkhlHJCKOWEUMoJoZQTQiknhJpp8qn/ybsA/oMrJ4RSTgilnBBKOSGUckIo5YRQfwNb7isvyVaOZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i_entry = 20\n",
    "plt.imshow( X_train[i_entry], cmap=\"binary\" )\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sneaker'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "class_names[ y_train[i_entry] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.10756256e-03, -2.28603570e-02, -4.82088628e-02,\n",
       "        -4.02934756e-02, -5.69705778e-02, -7.09606828e-02,\n",
       "        -9.84522372e-02, -1.55930716e-01, -2.38698115e-01,\n",
       "        -3.77802968e-01,  7.13591316e-01, -6.94190179e-01,\n",
       "        -7.58510471e-01, -7.49138359e-01, -7.48505062e-01,\n",
       "        -7.74760766e-01, -5.35939431e-01,  6.76180943e-01,\n",
       "        -5.03267070e-01, -3.19310624e-01, -2.02581239e-01,\n",
       "        -6.79116469e-02, -1.08753643e-01, -9.15151738e-02,\n",
       "        -6.79206056e-02, -5.08848835e-02, -3.37408758e-02,\n",
       "        -1.44791524e-02],\n",
       "       [-1.20517269e-02, -1.68631769e-02, -3.29494819e-02,\n",
       "        -5.55665050e-02, -7.76432672e-02, -1.31607643e-01,\n",
       "        -2.43396081e-01,  3.61994118e-01,  1.78051200e+00,\n",
       "         1.80178775e+00,  1.61776470e+00,  1.13037122e+00,\n",
       "         9.44258605e-01,  5.13504614e-01,  5.56761075e-01,\n",
       "         8.81063939e-01,  1.14789468e+00,  1.41303676e+00,\n",
       "         1.30127870e+00,  1.38508262e+00, -1.88169080e-01,\n",
       "        -3.16365678e-01, -1.40536008e-01, -1.48364190e-01,\n",
       "        -1.18267576e-01, -9.04785085e-02, -5.88949935e-02,\n",
       "        -2.95404587e-02],\n",
       "       [-1.52942664e-02, -2.54310596e-02, -4.54435412e-02,\n",
       "        -7.28474361e-02, -1.28987392e-01, -2.69280351e-01,\n",
       "         5.93207702e-01,  2.58986708e+00,  2.50241032e+00,\n",
       "         1.92068903e+00,  1.39012381e+00,  1.25675814e+00,\n",
       "         1.01912031e+00,  7.91627560e-01,  8.63270819e-01,\n",
       "         7.00235386e-01,  8.19193803e-01,  1.24605941e+00,\n",
       "         1.17288377e+00,  1.40426114e+00,  9.49244570e-01,\n",
       "        -3.21483245e-01, -3.72197774e-01, -1.85176407e-01,\n",
       "        -1.69401286e-01, -1.29928465e-01, -8.80578669e-02,\n",
       "        -5.14606566e-02],\n",
       "       [-2.50385338e-02, -4.08662330e-02, -6.54114335e-02,\n",
       "        -2.99550580e-02, -2.14993315e-01, -1.44759327e-01,\n",
       "         7.13450618e-01, -5.36436201e-01, -4.24154946e-01,\n",
       "        -6.93923857e-02,  1.99221324e-01, -7.85309200e-01,\n",
       "        -9.99464084e-01, -1.01131183e+00,  2.43890544e-01,\n",
       "        -4.89315048e-01, -9.14367565e-01, -8.15069429e-01,\n",
       "        -1.04783270e+00, -9.44343133e-01,  2.66228821e-01,\n",
       "         1.58126090e+00, -4.87617122e-01, -3.49119799e-01,\n",
       "        -2.34162037e-01, -1.72464109e-01, -1.19987180e-01,\n",
       "        -7.31734917e-02],\n",
       "       [-3.84221462e-02, -6.21891887e-02, -9.05591689e-02,\n",
       "        -4.97542751e-02, -2.89608132e-01,  2.62416688e-01,\n",
       "         1.22614984e+00,  1.01090546e+00, -1.29789757e-01,\n",
       "        -9.81713589e-01, -1.04758516e+00, -1.11191173e+00,\n",
       "        -1.02993738e+00, -1.12690934e+00, -7.45572769e-01,\n",
       "        -4.54003755e-01, -1.19267135e+00, -1.19941237e+00,\n",
       "        -1.04158298e+00,  1.16816156e-01,  2.25449065e-02,\n",
       "         1.75267217e+00, -3.41887335e-01, -4.42694376e-01,\n",
       "        -2.89469834e-01, -2.28350074e-01, -1.64112098e-01,\n",
       "        -9.84337473e-02],\n",
       "       [-5.22635759e-02, -8.54040359e-02, -1.23061782e-01,\n",
       "        -1.64352193e-01, -3.50093065e-01, -1.07315117e-01,\n",
       "         3.26500647e-01,  2.98473439e-01, -7.11640316e-01,\n",
       "        -1.01425431e+00, -8.26114829e-01, -1.02113853e+00,\n",
       "        -6.74254802e-01, -8.22015624e-01, -9.91375589e-01,\n",
       "        -9.65505249e-01, -1.27298539e+00, -1.06988976e+00,\n",
       "        -1.24619600e+00, -8.42757338e-01,  1.08253760e-01,\n",
       "         9.02776101e-01, -2.49610040e-01, -5.33962354e-01,\n",
       "        -3.73125843e-01, -2.96454186e-01, -2.16233938e-01,\n",
       "        -1.25823858e-01],\n",
       "       [-6.74574128e-02, -1.08049013e-01, -1.54560969e-01,\n",
       "        -2.46153964e-01, -4.01544066e-01,  3.59845759e-01,\n",
       "         8.09378788e-01,  9.81222122e-01,  2.84167909e-01,\n",
       "        -3.23486892e-01,  3.04531924e-02, -2.68268618e-01,\n",
       "        -3.43856475e-01, -6.25318621e-01, -6.35466397e-03,\n",
       "         2.27752004e-01, -7.12020372e-01,  2.56965905e-01,\n",
       "         6.16876419e-01,  1.30784308e+00,  1.23297230e+00,\n",
       "         1.19044042e+00,  8.04663354e-01, -6.16836315e-01,\n",
       "        -4.61272337e-01, -3.63757806e-01, -2.61658154e-01,\n",
       "        -1.47848643e-01],\n",
       "       [-8.45664147e-02, -1.30368938e-01, -1.84957836e-01,\n",
       "        -2.85973864e-01, -3.79340297e-01,  1.98954457e+00,\n",
       "         1.17907639e+00,  1.30254608e+00, -6.50258512e-01,\n",
       "        -1.02126610e+00, -7.17174466e-01, -1.17919683e+00,\n",
       "        -9.66512046e-01, -8.01737219e-01, -1.17815406e+00,\n",
       "        -1.38407038e+00, -1.47779894e+00, -1.50172227e+00,\n",
       "        -7.38681730e-01,  4.64871598e-01,  1.03377574e+00,\n",
       "         2.51883224e-01,  9.28603959e-01, -6.93858663e-01,\n",
       "        -5.29166214e-01, -4.26005255e-01, -3.03890879e-01,\n",
       "        -1.64341818e-01],\n",
       "       [-9.60655201e-02, -1.49801023e-01, -2.11430849e-01,\n",
       "        -3.16445394e-01, -4.73202587e-01, -1.99962478e-02,\n",
       "         9.56686279e-02,  7.31360367e-01, -5.74987663e-01,\n",
       "        -1.04918250e+00, -1.15911565e+00, -1.20415356e+00,\n",
       "        -1.17884629e+00, -7.30950402e-01, -9.09786391e-01,\n",
       "        -1.51572344e+00, -1.61181888e+00, -1.14492624e+00,\n",
       "        -6.34640319e-01,  7.64126591e-01,  4.70642603e-01,\n",
       "        -9.14442683e-01, -1.37577062e-01, -7.23261869e-01,\n",
       "        -5.96812242e-01, -4.88822759e-01, -3.47438868e-01,\n",
       "        -1.86271557e-01],\n",
       "       [-1.06383251e-01, -1.66656694e-01, -2.29073293e-01,\n",
       "        -3.36609633e-01, -4.79945415e-01,  1.43567258e-01,\n",
       "         3.64827840e-01,  9.43150207e-01,  2.32783692e-01,\n",
       "        -8.54790134e-01, -1.17928632e+00, -1.11459900e+00,\n",
       "        -1.23937774e+00, -1.35370438e+00, -1.03169606e+00,\n",
       "        -1.58510684e+00, -1.86609775e+00, -1.19809722e+00,\n",
       "        -1.54735244e+00,  6.10686709e-01, -8.54645510e-01,\n",
       "        -4.62000032e-01,  6.41037698e-01, -6.08023073e-01,\n",
       "        -6.63358189e-01, -5.59545646e-01, -3.97809423e-01,\n",
       "        -2.15043654e-01],\n",
       "       [-1.16331384e-01, -1.80071291e-01, -2.36956617e-01,\n",
       "        -3.41329729e-01, -4.90068825e-01, -1.99777454e-01,\n",
       "        -5.06189607e-01,  1.01247634e+00,  4.51737814e-01,\n",
       "         2.70586799e-02, -8.33924122e-01,  2.23974320e-01,\n",
       "         3.35165190e-01, -1.43750670e+00,  4.86847724e-01,\n",
       "         2.94713102e-02, -8.41297790e-01,  4.78291450e-01,\n",
       "         1.55551434e-01,  6.93875994e-01, -1.17190440e+00,\n",
       "        -7.49495352e-01,  2.27620528e-01, -4.57513495e-01,\n",
       "        -7.17892454e-01, -6.19072874e-01, -4.54342668e-01,\n",
       "        -2.41094789e-01],\n",
       "       [-1.29339778e-01, -1.92211435e-01, -2.38326580e-01,\n",
       "        -3.35398055e-01,  1.90628882e+00,  1.26456322e+00,\n",
       "         5.34249968e-01,  1.36135863e+00,  7.47601900e-01,\n",
       "        -2.82049717e-01, -1.28946207e+00, -1.40363785e+00,\n",
       "        -8.42688964e-01, -1.68447172e+00, -1.37472801e+00,\n",
       "        -1.58696935e+00, -2.13759304e+00, -1.19984364e+00,\n",
       "        -8.48572422e-01,  1.26056412e+00,  1.92688038e-02,\n",
       "         1.20145441e-01,  7.61010545e-01,  1.18392817e+00,\n",
       "        -7.52626355e-01, -6.52931612e-01, -5.06190530e-01,\n",
       "        -2.69621135e-01],\n",
       "       [-1.43476822e-01, -2.03872032e-01, -2.45757662e-01,\n",
       "         4.92706145e-02,  1.12752493e+00, -5.70022409e-01,\n",
       "         2.86479593e-01, -1.82360703e-01, -8.97448824e-01,\n",
       "        -7.93809388e-01, -1.25638899e+00, -1.18658622e+00,\n",
       "        -9.36745032e-01, -1.36387561e+00, -1.54734681e+00,\n",
       "        -2.05844448e+00, -2.19062685e+00, -1.93838912e+00,\n",
       "        -1.91544035e+00, -7.15172595e-01, -8.34526640e-01,\n",
       "        -5.08879085e-01, -7.41065182e-01,  1.41762803e+00,\n",
       "        -7.74031361e-01, -6.68073468e-01, -5.43123150e-01,\n",
       "        -3.03138189e-01],\n",
       "       [-1.52358111e-01, -2.19310117e-01, -2.63852809e-01,\n",
       "         8.78459804e-02,  8.98536282e-01, -7.13108474e-01,\n",
       "         1.63548674e+00,  5.88490587e-01, -1.12403193e+00,\n",
       "        -1.00796614e+00, -1.62211152e+00, -3.12060310e-01,\n",
       "        -1.12993771e+00, -1.78304228e+00, -1.50807157e+00,\n",
       "        -2.12679123e+00, -2.17782786e+00, -2.09518845e+00,\n",
       "        -1.23000523e+00, -1.04885094e+00, -2.46000429e-01,\n",
       "         2.20303159e-01, -1.16065089e+00,  9.57207858e-01,\n",
       "         1.21916114e-02, -6.75275828e-01, -5.68763792e-01,\n",
       "        -3.34298949e-01],\n",
       "       [-1.82237724e-01, -2.72651371e-01, -3.25050866e-01,\n",
       "         7.23929196e-01,  1.28402582e+00, -7.85066953e-01,\n",
       "         1.54637886e+00,  4.25561315e-01, -1.11147384e+00,\n",
       "        -5.91754809e-01, -1.73773310e+00, -2.24444889e-01,\n",
       "        -8.80057131e-01, -1.88666330e+00, -1.51059689e+00,\n",
       "        -1.62419004e+00, -2.24718082e+00, -2.22375555e+00,\n",
       "        -1.74322216e+00, -5.66213690e-01, -2.17113950e-01,\n",
       "         1.43742724e+00,  3.14512986e-02,  6.32153652e-01,\n",
       "        -1.71605242e-03, -6.83617907e-01, -5.93621695e-01,\n",
       "        -3.63546504e-01],\n",
       "       [-2.49525785e-01, -3.53273569e-01, -3.97716616e-01,\n",
       "        -4.95053867e-01, -6.89656621e-01, -8.56561645e-01,\n",
       "        -9.43620197e-01, -1.03719354e+00,  5.13297235e-01,\n",
       "         2.83277780e-01, -3.29731730e-01,  1.81641939e-01,\n",
       "        -3.57141783e-01, -1.07802817e+00, -2.85276740e-01,\n",
       "        -3.24700811e-01, -9.44360350e-01, -1.56594486e-01,\n",
       "         5.14086685e-01,  1.24948248e+00, -1.40692476e+00,\n",
       "        -1.16515133e+00, -1.16756249e+00, -1.02824729e+00,\n",
       "        -8.24293876e-01, -6.98022373e-01, -6.15834123e-01,\n",
       "        -3.90078103e-01],\n",
       "       [-3.10251385e-01, -4.02804889e-01, -4.45937322e-01,\n",
       "        -5.47800752e-01, -7.47617107e-01, -8.71891357e-01,\n",
       "        -9.92960647e-01, -1.03412251e+00, -5.46018721e-02,\n",
       "        -1.35096433e+00, -5.19114226e-01, -2.12958542e+00,\n",
       "        -2.20246002e+00, -1.73589482e+00, -1.74505347e+00,\n",
       "        -2.17105764e+00, -2.10179017e+00, -2.19654163e+00,\n",
       "        -2.02958666e+00,  9.71538789e-01, -1.38472202e+00,\n",
       "        -1.25006143e+00, -1.16168652e+00, -1.02815581e+00,\n",
       "        -8.42205218e-01, -7.08125881e-01, -6.26054682e-01,\n",
       "        -4.10260223e-01],\n",
       "       [-3.21566417e-01, -4.32156916e-01, -4.85774877e-01,\n",
       "        -5.77422866e-01, -7.93561229e-01, -9.28632192e-01,\n",
       "        -1.02668515e+00, -1.08091982e+00, -4.80975069e-01,\n",
       "        -1.24020655e+00, -1.26446710e+00, -1.91064833e+00,\n",
       "        -1.77089682e+00, -1.68049537e+00, -1.81546167e+00,\n",
       "        -2.15944433e+00, -2.17838505e+00, -2.32894794e+00,\n",
       "        -2.13389128e+00, -1.74262460e-02, -1.30021704e+00,\n",
       "        -1.19128849e+00, -1.08597491e+00, -9.94966520e-01,\n",
       "        -8.30587414e-01, -6.90504030e-01, -6.08646054e-01,\n",
       "        -4.06247387e-01],\n",
       "       [-2.93350605e-01, -4.30643364e-01, -5.01601509e-01,\n",
       "        -6.13482043e-01, -8.15957341e-01, -9.50052428e-01,\n",
       "        -1.03445456e+00, -1.07582686e+00, -5.49700165e-01,\n",
       "        -1.27799290e+00, -6.42551536e-01, -1.69302323e+00,\n",
       "        -1.66298132e+00, -1.62817435e+00, -1.48661136e+00,\n",
       "        -9.82759435e-01, -1.42110328e+00, -2.17823558e+00,\n",
       "        -1.74690892e+00, -3.42088720e-01, -1.16918701e+00,\n",
       "        -1.13409970e+00, -1.06264818e+00, -9.86124623e-01,\n",
       "        -8.10747179e-01, -6.67106315e-01, -5.84315824e-01,\n",
       "        -3.95935374e-01],\n",
       "       [-2.72858545e-01, -4.01501097e-01, -4.77496268e-01,\n",
       "        -5.98308745e-01, -8.03288951e-01, -9.27503415e-01,\n",
       "        -1.01057439e+00, -1.10893738e+00, -4.69456209e-01,\n",
       "        -1.67510234e+00, -1.65981445e+00, -2.07457058e+00,\n",
       "        -1.99800566e+00, -1.53395336e+00, -1.51143853e+00,\n",
       "        -5.87576709e-01, -1.57680668e+00, -1.86431446e+00,\n",
       "        -1.78197174e+00, -8.71918268e-01, -9.06292126e-01,\n",
       "        -1.08324966e+00, -1.00004237e+00, -9.54673185e-01,\n",
       "        -7.87271762e-01, -6.39532876e-01, -5.45913469e-01,\n",
       "        -3.58998329e-01],\n",
       "       [-2.63446200e-01, -3.80695677e-01, -4.50056567e-01,\n",
       "        -5.66934091e-01, -7.67709771e-01, -8.54971480e-01,\n",
       "        -9.67150678e-01, -1.05787786e+00,  1.34794542e+00,\n",
       "        -7.85766758e-02,  2.12805371e-01,  1.52890705e-01,\n",
       "        -9.25567335e-01, -3.19537899e-01, -6.53971712e-01,\n",
       "        -9.26968339e-01, -1.56137024e+00, -1.03790314e+00,\n",
       "        -9.85382241e-01,  1.98589625e-01, -3.82745714e-01,\n",
       "        -9.97179054e-01, -9.25711686e-01, -8.90286662e-01,\n",
       "        -7.33358903e-01, -5.80569152e-01, -4.77809344e-01,\n",
       "        -3.02933784e-01],\n",
       "       [-2.46719269e-01, -3.52721015e-01, -4.21804277e-01,\n",
       "        -5.39383755e-01, -7.20769531e-01, -8.08193508e-01,\n",
       "        -9.08939997e-01, -8.94202916e-01,  1.14897921e+00,\n",
       "        -1.45237609e-01,  4.73672434e-01, -6.56660627e-01,\n",
       "        -1.55770402e+00, -1.18943251e+00, -1.10332889e+00,\n",
       "        -1.37016610e+00, -1.26052814e+00, -1.52647078e+00,\n",
       "        -1.31267850e+00, -5.29184441e-01, -7.43381592e-01,\n",
       "        -9.06775365e-01, -8.35645081e-01, -8.06555928e-01,\n",
       "        -6.69645657e-01, -5.20163671e-01, -4.22680870e-01,\n",
       "        -2.68797770e-01],\n",
       "       [-2.18762400e-01, -3.11349656e-01, -3.79537820e-01,\n",
       "        -4.98254811e-01, -6.86431029e-01, -7.76218282e-01,\n",
       "        -8.51289164e-01, -9.15042226e-01,  5.79662291e-01,\n",
       "        -1.31818590e+00, -1.20940537e+00, -1.56632633e+00,\n",
       "        -1.53590647e+00, -1.24623974e+00, -1.21009992e+00,\n",
       "        -6.83527425e-01, -6.82400571e-01, -1.02306733e+00,\n",
       "        -1.14129102e+00, -9.88857594e-01, -7.11165694e-01,\n",
       "        -8.36605577e-01, -8.11486638e-01, -7.55604629e-01,\n",
       "        -6.15431703e-01, -4.66520091e-01, -3.70713336e-01,\n",
       "        -2.29578593e-01],\n",
       "       [-1.85117565e-01, -2.63459224e-01, -3.33542847e-01,\n",
       "        -4.53997423e-01, -6.35221516e-01, -7.27137432e-01,\n",
       "        -7.83534585e-01, -7.76961716e-01,  6.52846799e-01,\n",
       "        -6.32727835e-01, -1.02886057e+00, -1.14473089e+00,\n",
       "        -1.38171374e+00, -8.17371323e-01, -9.29880058e-01,\n",
       "        -1.21296423e+00, -1.12359892e+00, -6.81769491e-02,\n",
       "        -1.12759311e+00, -8.57872218e-01, -2.53955712e-01,\n",
       "        -7.64122334e-01, -7.33764503e-01, -6.91878142e-01,\n",
       "        -5.57511912e-01, -4.07885593e-01, -3.13113355e-01,\n",
       "        -1.87556207e-01],\n",
       "       [-1.39772956e-01, -2.11082295e-01, -2.83363323e-01,\n",
       "        -4.06856788e-01, -5.85023636e-01, -6.61994331e-01,\n",
       "        -7.24290700e-01, -7.36211038e-01,  1.00179174e+00,\n",
       "        -7.02094073e-02, -4.50311457e-01, -7.09384148e-01,\n",
       "        -7.42206081e-01, -5.46540666e-01, -4.05758523e-01,\n",
       "        -2.95806711e-01, -1.01363692e+00, -5.26368903e-01,\n",
       "        -1.82963919e-01,  4.40821309e-01,  1.24168623e+00,\n",
       "        -7.03741360e-01, -6.90560172e-01, -6.38373181e-01,\n",
       "        -5.06378061e-01, -3.54924201e-01, -2.61559117e-01,\n",
       "        -1.50395802e-01],\n",
       "       [-1.00080238e-01, -1.61440183e-01, -2.33652743e-01,\n",
       "        -3.39309403e-01, -5.33705269e-01, -6.08738044e-01,\n",
       "        -6.64108545e-01, -1.33713534e-01,  1.25416389e+00,\n",
       "        -7.91113656e-01,  2.68698305e-02, -5.64661046e-01,\n",
       "        -9.50588076e-01, -1.00427799e+00, -5.85483128e-01,\n",
       "         3.07606752e-01, -1.00404075e+00, -2.93176318e-01,\n",
       "         9.58777812e-02,  2.15359114e-01,  8.83731992e-01,\n",
       "        -6.45033241e-01, -6.37538376e-01, -5.82491150e-01,\n",
       "        -4.52323894e-01, -2.97301075e-01, -2.08848530e-01,\n",
       "        -1.10789442e-01],\n",
       "       [-5.60055659e-02, -1.04085247e-01, -1.77207615e-01,\n",
       "        -3.05389703e-01, -4.75292621e-01, -5.35209388e-01,\n",
       "        -5.95074722e-01, -3.20579765e-01, -1.89791796e-01,\n",
       "        -8.09933602e-01,  2.24447102e-01, -1.61586831e-01,\n",
       "        -2.20499861e-01, -5.90329769e-02, -4.58424928e-01,\n",
       "         1.88565789e-01, -8.16602646e-01,  9.55703973e-02,\n",
       "        -1.48164978e-01, -5.97299338e-02,  9.47222129e-01,\n",
       "        -5.73196129e-01, -5.74695184e-01, -5.20074404e-01,\n",
       "        -3.97156170e-01, -2.41654513e-01, -1.54498161e-01,\n",
       "        -7.50588115e-02],\n",
       "       [-2.45250161e-02, -4.82037608e-02, -1.01600908e-01,\n",
       "        -2.09072195e-01, -3.40741661e-01, -3.85820771e-01,\n",
       "        -4.37007660e-01, -3.34691657e-01,  1.01448873e+00,\n",
       "         5.38773856e-01,  4.60632528e-03,  2.42226447e-01,\n",
       "         3.94498938e-01,  5.25000877e-02,  6.54609926e-01,\n",
       "         1.22779248e+00,  4.67021355e-01,  7.36055391e-01,\n",
       "         8.78912131e-01,  2.20834602e+00,  2.05288002e+00,\n",
       "        -4.07819392e-01, -4.42067930e-01, -3.74005574e-01,\n",
       "        -2.87358942e-01, -1.56166422e-01, -8.90840596e-02,\n",
       "        -3.39927363e-02]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mean = X_train.mean( axis=0 )\n",
    "X_std = X_train.std( axis=0 )\n",
    "X_train_scaled = ( X_train - X_mean ) / X_std\n",
    "X_valid_scaled = ( X_valid - X_mean ) / X_std\n",
    "X_test_scaled  = ( X_test - X_mean ) / X_std\n",
    "X_train_scaled[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model build function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=50, learning_rate=5e-4, input_shape=[28,28], dropout=0.20):\n",
    "    print( \"Building model with:\" )\n",
    "    print( \"Number of hidden layers: {}\".format(n_hidden) )\n",
    "    print( \"Number of neurons per layer: {}\".format(n_neurons) )\n",
    "    print( \"Learning rate: {}\".format(learning_rate) )\n",
    "    print( \"Input shape: {}\".format(input_shape) )\n",
    "    print( \"Dropout rate: {}\".format(dropout) )\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add( keras.layers.Flatten(input_shape=input_shape) )\n",
    "    for layer in range(n_hidden):\n",
    "        if dropout > 0.:\n",
    "            model.add( keras.layers.Dropout(rate=dropout) )\n",
    "        model.add( keras.layers.Dense(n_neurons, activation=\"elu\", kernel_initializer=\"he_normal\") )\n",
    "    if dropout > 0.:\n",
    "        model.add( keras.layers.Dropout(rate=dropout) )    \n",
    "    model.add( keras.layers.Dense(10, activation=\"softmax\") )\n",
    "    \n",
    "    #optimizer = keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "    optimizer = keras.optimizers.Nadam(lr=learning_rate)\n",
    "    model.compile( loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir(log_dir):\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(log_dir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callbacks(patience=10, log_dir=\"\"):\n",
    "    callbacks_ = []\n",
    "    # Early stopping\n",
    "    if patience > 0:\n",
    "        early_stopping_cb_ = keras.callbacks.EarlyStopping( patience=patience, restore_best_weights=True )\n",
    "        callbacks_.append( early_stopping_cb_ )\n",
    "        \n",
    "    # TensorBoard\n",
    "    if log_dir:\n",
    "        run_logdir = get_run_logdir(log_dir)\n",
    "        print ( \"Log dir: {}\".format(run_logdir) )\n",
    "        tensorboard_cb_ = keras.callbacks.TensorBoard( run_logdir )\n",
    "        callbacks_.append( tensorboard_cb_ )\n",
    "    \n",
    "    return callbacks_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log dir: fashion_mnist_logs/run_2020_11_12-17_11_13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.callbacks.EarlyStopping at 0x7f74fcc859d0>,\n",
       " <tensorflow.python.keras.callbacks.TensorBoard at 0x7f74f0e30150>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir=\"fashion_mnist_logs\"\n",
    "callbacks_ = callbacks(patience=10, log_dir=log_dir)\n",
    "callbacks_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 99,710\n",
      "Trainable params: 99,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model( \n",
    "    n_hidden=3,\n",
    "    n_neurons=100,\n",
    "    learning_rate=8e-4,\n",
    "    input_shape=[28,28],\n",
    "    dropout=0.40\n",
    "    )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/1719 [..............................] - ETA: 0s - loss: 5.9160 - accuracy: 0.1250WARNING:tensorflow:From /home/antoniovilela/workspace/envs/tf-gpu-py37/lib64/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1719 [..............................] - ETA: 3:06 - loss: 6.5422 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.2165s). Check your callbacks.\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 1.2072 - accuracy: 0.6449 - val_loss: 0.4596 - val_accuracy: 0.8328\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6528 - accuracy: 0.7692 - val_loss: 0.4250 - val_accuracy: 0.8438\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5917 - accuracy: 0.7906 - val_loss: 0.4171 - val_accuracy: 0.8506\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5531 - accuracy: 0.8037 - val_loss: 0.3891 - val_accuracy: 0.8592\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5319 - accuracy: 0.8116 - val_loss: 0.3766 - val_accuracy: 0.8668\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5202 - accuracy: 0.8167 - val_loss: 0.3694 - val_accuracy: 0.8650\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5079 - accuracy: 0.8201 - val_loss: 0.3605 - val_accuracy: 0.8664\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4976 - accuracy: 0.8244 - val_loss: 0.3588 - val_accuracy: 0.8712\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4921 - accuracy: 0.8244 - val_loss: 0.3490 - val_accuracy: 0.8702\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4803 - accuracy: 0.8294 - val_loss: 0.3448 - val_accuracy: 0.8726\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4719 - accuracy: 0.8322 - val_loss: 0.3428 - val_accuracy: 0.8738\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4720 - accuracy: 0.8323 - val_loss: 0.3507 - val_accuracy: 0.8694\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4693 - accuracy: 0.8331 - val_loss: 0.3362 - val_accuracy: 0.8774\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4598 - accuracy: 0.8374 - val_loss: 0.3409 - val_accuracy: 0.8736\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4548 - accuracy: 0.8375 - val_loss: 0.3409 - val_accuracy: 0.8752\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4581 - accuracy: 0.8378 - val_loss: 0.3330 - val_accuracy: 0.8776\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4520 - accuracy: 0.8390 - val_loss: 0.3388 - val_accuracy: 0.8722\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4501 - accuracy: 0.8389 - val_loss: 0.3306 - val_accuracy: 0.8806\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4477 - accuracy: 0.8400 - val_loss: 0.3402 - val_accuracy: 0.8736\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4504 - accuracy: 0.8408 - val_loss: 0.3225 - val_accuracy: 0.8788\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4441 - accuracy: 0.8418 - val_loss: 0.3322 - val_accuracy: 0.8816\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4429 - accuracy: 0.8426 - val_loss: 0.3215 - val_accuracy: 0.8784\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4390 - accuracy: 0.8422 - val_loss: 0.3220 - val_accuracy: 0.8812\n",
      "Epoch 24/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4417 - accuracy: 0.8427 - val_loss: 0.3265 - val_accuracy: 0.8788\n",
      "Epoch 25/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4356 - accuracy: 0.8438 - val_loss: 0.3226 - val_accuracy: 0.8756\n",
      "Epoch 26/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4408 - accuracy: 0.8434 - val_loss: 0.3134 - val_accuracy: 0.8822\n",
      "Epoch 27/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4373 - accuracy: 0.8451 - val_loss: 0.3237 - val_accuracy: 0.8810\n",
      "Epoch 28/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4345 - accuracy: 0.8464 - val_loss: 0.3301 - val_accuracy: 0.8758\n",
      "Epoch 29/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4363 - accuracy: 0.8461 - val_loss: 0.3193 - val_accuracy: 0.8790\n",
      "Epoch 30/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4358 - accuracy: 0.8460 - val_loss: 0.3263 - val_accuracy: 0.8778\n",
      "Epoch 31/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4329 - accuracy: 0.8457 - val_loss: 0.3261 - val_accuracy: 0.8782\n",
      "Epoch 32/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4333 - accuracy: 0.8457 - val_loss: 0.3149 - val_accuracy: 0.8824\n",
      "Epoch 33/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4255 - accuracy: 0.8473 - val_loss: 0.3254 - val_accuracy: 0.8816\n",
      "Epoch 34/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4262 - accuracy: 0.8473 - val_loss: 0.3182 - val_accuracy: 0.8814\n",
      "Epoch 35/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4331 - accuracy: 0.8465 - val_loss: 0.3139 - val_accuracy: 0.8840\n",
      "Epoch 36/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4254 - accuracy: 0.8490 - val_loss: 0.3237 - val_accuracy: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [1.2071599960327148,\n",
       "  0.6528141498565674,\n",
       "  0.5916562080383301,\n",
       "  0.5531163811683655,\n",
       "  0.531863808631897,\n",
       "  0.5202404856681824,\n",
       "  0.5078991651535034,\n",
       "  0.497600257396698,\n",
       "  0.4920653700828552,\n",
       "  0.4802609980106354,\n",
       "  0.4718872010707855,\n",
       "  0.4720466136932373,\n",
       "  0.469262957572937,\n",
       "  0.4598357379436493,\n",
       "  0.4548206925392151,\n",
       "  0.4580931067466736,\n",
       "  0.4520214796066284,\n",
       "  0.4500926434993744,\n",
       "  0.44770318269729614,\n",
       "  0.4503750503063202,\n",
       "  0.4441363513469696,\n",
       "  0.44294026494026184,\n",
       "  0.43898269534111023,\n",
       "  0.4416716396808624,\n",
       "  0.4356226921081543,\n",
       "  0.4407561421394348,\n",
       "  0.43733444809913635,\n",
       "  0.43447116017341614,\n",
       "  0.43634146451950073,\n",
       "  0.4357619285583496,\n",
       "  0.43285509943962097,\n",
       "  0.433255136013031,\n",
       "  0.4254980683326721,\n",
       "  0.4262170195579529,\n",
       "  0.433068186044693,\n",
       "  0.42538467049598694],\n",
       " 'accuracy': [0.6449090838432312,\n",
       "  0.7692000269889832,\n",
       "  0.7906363606452942,\n",
       "  0.803672730922699,\n",
       "  0.8116363883018494,\n",
       "  0.8166909217834473,\n",
       "  0.8201272487640381,\n",
       "  0.824363648891449,\n",
       "  0.8244181871414185,\n",
       "  0.8294181823730469,\n",
       "  0.8321636319160461,\n",
       "  0.8322727084159851,\n",
       "  0.8330909013748169,\n",
       "  0.8374181985855103,\n",
       "  0.8375272750854492,\n",
       "  0.8378182053565979,\n",
       "  0.8390363454818726,\n",
       "  0.8389272689819336,\n",
       "  0.8400181531906128,\n",
       "  0.8407636284828186,\n",
       "  0.8418181538581848,\n",
       "  0.8426181674003601,\n",
       "  0.842236340045929,\n",
       "  0.8426545262336731,\n",
       "  0.8437818288803101,\n",
       "  0.8433636426925659,\n",
       "  0.8450727462768555,\n",
       "  0.8464000225067139,\n",
       "  0.8461272716522217,\n",
       "  0.8460181951522827,\n",
       "  0.8456727266311646,\n",
       "  0.8457090854644775,\n",
       "  0.8472727537155151,\n",
       "  0.8473091125488281,\n",
       "  0.8465090990066528,\n",
       "  0.8489636182785034],\n",
       " 'val_loss': [0.45956626534461975,\n",
       "  0.4250109791755676,\n",
       "  0.417146772146225,\n",
       "  0.3891223967075348,\n",
       "  0.37655460834503174,\n",
       "  0.36938419938087463,\n",
       "  0.3605286478996277,\n",
       "  0.35876721143722534,\n",
       "  0.3489591181278229,\n",
       "  0.34479349851608276,\n",
       "  0.3428192734718323,\n",
       "  0.3507276773452759,\n",
       "  0.3361613154411316,\n",
       "  0.34093576669692993,\n",
       "  0.34093907475471497,\n",
       "  0.3329995274543762,\n",
       "  0.33883872628211975,\n",
       "  0.3305957615375519,\n",
       "  0.34021666646003723,\n",
       "  0.32248997688293457,\n",
       "  0.33220937848091125,\n",
       "  0.32153576612472534,\n",
       "  0.32202082872390747,\n",
       "  0.3265407979488373,\n",
       "  0.32258760929107666,\n",
       "  0.31337833404541016,\n",
       "  0.32370099425315857,\n",
       "  0.33011722564697266,\n",
       "  0.3193483352661133,\n",
       "  0.32625770568847656,\n",
       "  0.32612064480781555,\n",
       "  0.31489840149879456,\n",
       "  0.3254103660583496,\n",
       "  0.31818854808807373,\n",
       "  0.31389832496643066,\n",
       "  0.3236507177352905],\n",
       " 'val_accuracy': [0.8327999711036682,\n",
       "  0.8438000082969666,\n",
       "  0.850600004196167,\n",
       "  0.8592000007629395,\n",
       "  0.8668000102043152,\n",
       "  0.8650000095367432,\n",
       "  0.8664000034332275,\n",
       "  0.8712000250816345,\n",
       "  0.870199978351593,\n",
       "  0.8726000189781189,\n",
       "  0.8737999796867371,\n",
       "  0.8694000244140625,\n",
       "  0.8773999810218811,\n",
       "  0.8736000061035156,\n",
       "  0.8751999735832214,\n",
       "  0.8776000142097473,\n",
       "  0.8722000122070312,\n",
       "  0.8805999755859375,\n",
       "  0.8736000061035156,\n",
       "  0.8787999749183655,\n",
       "  0.881600022315979,\n",
       "  0.8784000277519226,\n",
       "  0.8812000155448914,\n",
       "  0.8787999749183655,\n",
       "  0.8755999803543091,\n",
       "  0.8822000026702881,\n",
       "  0.8809999823570251,\n",
       "  0.8758000135421753,\n",
       "  0.8790000081062317,\n",
       "  0.8777999877929688,\n",
       "  0.8781999945640564,\n",
       "  0.8823999762535095,\n",
       "  0.881600022315979,\n",
       "  0.8813999891281128,\n",
       "  0.8840000033378601,\n",
       "  0.8799999952316284]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit( X_train_scaled, y_train, epochs=100, validation_data=(X_valid_scaled, y_valid), callbacks=callbacks_ )\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAI/CAYAAACS3NQgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABzu0lEQVR4nO3deXwcd33/8dd3b0m7uiXLuizFd2z5lI9cTuzchCMcaQh3ylHKDS00pbSlhdJSytU2PyBQCCnQAAkBmjtpnNhxEt+O7zg+ZEuyrdu6pb3m98esVkdkW7YlraR9P2EfMzs7u/vRSI7e+u5nvmMsy0JEREREJBk5El2AiIiIiEiiKAyLiIiISNJSGBYRERGRpKUwLCIiIiJJS2FYRERERJKWwrCIiIiIJC1Xot44NzfXKisrS9Tbi4iIiEiS2L59e6NlWXnDPZawMFxWVsa2bdsS9fYiIiIikiSMMcfP9pjaJEREREQkaSkMi4iIiEjSUhgWERERkaSVsJ5hERERkckuFApRU1NDT09PoksRwOfzUVxcjNvtHvFzFIZFRERELlJNTQ2BQICysjKMMYkuJ6lZlkVTUxM1NTWUl5eP+HlqkxARERG5SD09PeTk5CgITwDGGHJyci54lF5hWEREROQSKAhPHBfzvVAYFhEREZnE/H5/okuY1BSGRURERCRpKQyLiIiITAGWZfHFL36RhQsXUlFRwa9//WsATp06xZo1a1iyZAkLFy5k48aNRCIRPvShD8X3/e53v5vg6hNHs0mIiIiITAG/+93v2LVrF6+++iqNjY2sWLGCNWvW8Ktf/Yqbb76Zv/mbvyESidDV1cWuXbuora1l7969AJw5cyaxxSeQwrCIiIjIKPiH/93H/pNto/qalxem8/dvWTCifV988UXuuusunE4n06ZN49prr2Xr1q2sWLGCP/3TPyUUCnH77bezZMkSLrvsMo4ePcqnP/1pbrvtNm666aZRrXsyUZuEiIiIyBS2Zs0aNmzYQFFRER/60Id44IEHyMrK4tVXX+W6667jhz/8IR/5yEcSXWbCaGRYREREZBSMdAR3rFxzzTX86Ec/4oMf/CDNzc1s2LCBb33rWxw/fpzi4mI++tGP0tvby44dO3jTm96Ex+Phne98J3PnzuV973tfQmtPJIVhERERkSng7W9/Oy+//DKLFy/GGMO//uu/UlBQwM9//nO+9a1v4Xa78fv9PPDAA9TW1nL33XcTjUYB+Od//ucEV584xrKshLxxZWWltW3btoS8t4iIiMhoOHDgAPPnz090GTLAcN8TY8x2y7Iqh9tfPcMiIiIikrQUhkVEREQkaSkMi4iIiEjSUhgWERERkaSlMCwiIiIiSUthWERERESSVlKF4VOt3dzwnRd4Ys+pRJciIiIiIhPAecOwMeanxph6Y8zeszz+XmPMbmPMHmPMS8aYxaNf5uhwOx0cru+gvr030aWIiIiITBrhcDjRJYyZkYwM3w/cco7HjwHXWpZVAXwNuG8U6hoTAZ99wb2O3qn7DRUREZHkcvvtt7N8+XIWLFjAfffZMezJJ59k2bJlLF68mOuvvx6Ajo4O7r77bioqKli0aBEPP/wwAH6/P/5aDz30EB/60IcA+NCHPsTHP/5xVq1axZe+9CW2bNnCFVdcwdKlS7nyyit57bXXAIhEIvzlX/4lCxcuZNGiRfzHf/wHzz33HLfffnv8dZ955hne/va3j8PRuHDnvRyzZVkbjDFl53j8pQF3XwGKR6GuMeF1OfE4HbT1hBJdioiIiMio+OlPf0p2djbd3d2sWLGCt73tbXz0ox9lw4YNlJeX09zcDMDXvvY1MjIy2LNnDwAtLS3nfe2amhpeeuklnE4nbW1tbNy4EZfLxbPPPsuXv/xlHn74Ye677z6qqqrYtWsXLpeL5uZmsrKy+MQnPkFDQwN5eXn87Gc/40//9E/H9DhcrPOG4Qv0YeCJUX7NURXwuejo0ciwiIiIjLIn7oHTe0b3NQsq4NZ/Oecu//7v/84jjzwCQHV1Nffddx9r1qyhvLwcgOzsbACeffZZHnzwwfjzsrKyzvv2d9xxB06nE4DW1lY++MEP8vrrr2OMIRQKxV/34x//OC6Xa9D7vf/97+cXv/gFd999Ny+//DIPPPDAhXzl42bUwrAxZi12GL76HPt8DPgYQGlp6Wi99QXx+1y0KwyLiIjIFPD888/z7LPP8vLLL5Oamsp1113HkiVLOHjw4IhfwxgTX+/p6Rn0WFpaWnz9b//2b1m7di2PPPIIVVVVXHfdded83bvvvpu3vOUt+Hw+7rjjjnhYnmhGpSpjzCLgJ8CtlmU1nW0/y7LuI9ZTXFlZaY3Ge1+ogM+lnmEREREZfecZwR0Lra2tZGVlkZqaysGDB3nllVfo6elhw4YNHDt2LN4mkZ2dzY033si9997L9773PcBuk8jKymLatGkcOHCAuXPn8sgjjxAIBM76XkVFRQDcf//98e033ngjP/rRj1i7dm28TSI7O5vCwkIKCwv5+te/zrPPPjvWh+KiXfLUasaYUuB3wPstyzp06SWNLb/XRbt6hkVERGQKuOWWWwiHw8yfP5977rmH1atXk5eXx3333cc73vEOFi9ezJ133gnAV77yFVpaWli4cCGLFy9m/fr1APzLv/wLb37zm7nyyiuZPn36Wd/rS1/6En/913/N0qVLB80u8ZGPfITS0lIWLVrE4sWL+dWvfhV/7L3vfS8lJSXMnz9/jI7ApTOWde4BWmPM/wDXAblAHfD3gBvAsqwfGmN+ArwTOB57StiyrMrzvXFlZaW1bdu2i6/8In30gW1UN3fx5OfWjPt7i4iIyNRy4MCBCR30Eu1Tn/oUS5cu5cMf/vC4vedw3xNjzPaz5dORzCZx13ke/wjwkQspMpECXvUMi4iIiIy15cuXk5aWxre//e1El3JOE7OTeQwFfGqTEBERERlr27dvT3QJI5JUl2MGezaJjt4w52sPEREREZGpL+nCcMDnJmpBVzCS6FJEREREJMGSLgz7vboks4iIiIjYki4MB3x2GFbfsIiIiIgkcRjWyLCIiIhIskvCMOwGFIZFREQk+fj9/rM+VlVVxcKFC8exmokhCcOweoZFRERExJZ0YbjvBDr1DIuIiMhkd88993DvvffG73/1q1/l61//Otdffz3Lli2joqKCP/zhDxf8uj09Pdx9991UVFSwdOnS+KWb9+3bx8qVK1myZAmLFi3i9ddfp7Ozk9tuu43FixezcOFCfv3rX4/a1zcekvCiG2qTEBERkdH3zS3f5GDzwVF9zXnZ8/irlX911sfvvPNOPve5z/HJT34SgN/85jc89dRTfOYznyE9PZ3GxkZWr17NW9/6VowxI37fe++9F2MMe/bs4eDBg9x0000cOnSIH/7wh3z2s5/lve99L8FgkEgkwuOPP05hYSGPPfYYAK2trZf2RY+zJB4ZVhgWERGRyW3p0qXU19dz8uRJXn31VbKysigoKODLX/4yixYt4oYbbqC2tpa6uroLet0XX3yR973vfQDMmzePGTNmcOjQIa644gq+8Y1v8M1vfpPjx4+TkpJCRUUFzzzzDH/1V3/Fxo0bycjIGIsvdcwk3ciw02FI8zjVMywiIiKj6lwjuGPpjjvu4KGHHuL06dPceeed/PKXv6ShoYHt27fjdrspKyujp6dnVN7rPe95D6tWreKxxx7jTW96Ez/60Y9Yt24dO3bs4PHHH+crX/kK119/PX/3d383Ku83HpIuDIN9SWb1DIuIiMhUcOedd/LRj36UxsZGXnjhBX7zm9+Qn5+P2+1m/fr1HD9+/IJf85prruGXv/wl69at49ChQ5w4cYK5c+dy9OhRLrvsMj7zmc9w4sQJdu/ezbx588jOzuZ973sfmZmZ/OQnPxmDr3LsJGUYDvjcGhkWERGRKWHBggW0t7dTVFTE9OnTee9738tb3vIWKioqqKysZN68eRf8mp/4xCf48z//cyoqKnC5XNx///14vV5+85vf8N///d+43e54O8bWrVv54he/iMPhwO1284Mf/GAMvsqxYyzLSsgbV1ZWWtu2bUvIe99+7yYCPhf//eFVCXl/ERERmRoOHDjA/PnzE12GDDDc98QYs92yrMrh9k+6E+jAnmtYJ9CJiIiISJK2Sbg4eaY70WWIiIiIjLs9e/bw/ve/f9A2r9fL5s2bE1RRYiVnGPa6NTIsIiIiSamiooJdu3YluowJIynbJPw+l06gExEREZHkDMMBn4uuYIRwJJroUkREREQkgZIyDPddha6zN5LgSkREREQkkZIyDKf73AC06cIbIiIiIkktKcOw32ePDKtvWERERJKJ3+9PdAkTTlKG4UAsDGtGCREREZHxFw5PnAyWpGHYbpPo6FWbhIiIiExe99xzD/fee2/8/le/+lW+/vWvc/3117Ns2TIqKir4wx/+MKLX6ujoOOvzHnjgARYtWsTixYvjcxTX1dXx9re/ncWLF7N48WJeeuklqqqqWLhwYfx5//Zv/8ZXv/pVAK677jo+97nPUVlZyfe//33+93//l1WrVrF06VJuuOEG6urq4nXcfffdVFRUsGjRIh5++GF++tOf8rnPfS7+uj/+8Y/5/Oc/f7GHbZCknGe47wQ6jQyLiIjIaDn9jW/Qe+DgqL6md/48Cr785bM+fuedd/K5z32OT37ykwD85je/4amnnuIzn/kM6enpNDY2snr1at761rdijDnne/l8Ph555JE3PG///v18/etf56WXXiI3N5fm5mYAPvOZz3DttdfyyCOPEIlE6OjooKWl5ZzvEQwG2bZtGwAtLS288sorGGP4yU9+wr/+67/y7W9/m6997WtkZGSwZ8+e+H5ut5t/+qd/4lvf+hZut5uf/exn/OhHPxrxcTyXpAzD6WqTEBERkSlg6dKl1NfXc/LkSRoaGsjKyqKgoIDPf/7zbNiwAYfDQW1tLXV1dRQUFJzztSzL4stf/vIbnvfcc89xxx13kJubC0B2djYAzz33HA888AAATqeTjIyM84bhO++8M75eU1PDnXfeyalTpwgGg5SXlwPw7LPP8uCDD8b3y8rKAmDdunU8+uijzJ8/n1AoREVFxQUereElZRj2KwyLiIjIKDvXCO5YuuOOO3jooYc4ffo0d955J7/85S9paGhg+/btuN1uysrK6OnpOe/rXOzzBnK5XESj/ddxGPr8tLS0+PqnP/1pvvCFL/DWt76V559/Pt5OcTYf+chH+MY3vsG8efO4++67L6iuc0nKnuEUtxOnw6hnWERERCa9O++8kwcffJCHHnqIO+64g9bWVvLz83G73axfv57jx4+P6HXO9rx169bx29/+lqamJoB4m8T111/PD37wAwAikQitra1MmzaN+vp6mpqa6O3t5dFHHz3n+xUVFQHw85//PL79xhtvHNQH3TfavGrVKqqrq/nVr37FXXfdNdLDc15JGYaNMfi9Lo0Mi4iIyKS3YMEC2tvbKSoqYvr06bz3ve9l27ZtVFRU8MADDzBv3rwRvc7ZnrdgwQL+5m/+hmuvvZbFixfzhS98AYDvf//7rF+/noqKCpYvX87+/ftxu9383d/9HStXruTGG28853t/9atf5Y477mD58uXxFgyAr3zlK7S0tLBw4UIWL17M+vXr44/9yZ/8CVdddVW8dWI0GMuyRu3FLkRlZaXV10CdCFd/8zlWlmXznTuXJKwGERERmdwOHDjA/PnzE11G0njzm9/M5z//ea6//vqz7jPc98QYs92yrMrh9k/KkWGwZ5Ro08iwiIiIyIR35swZ5syZQ0pKyjmD8MVIyhPowL4ks3qGRUREJNns2bMnPldwH6/Xy+bNmxNU0fllZmZy6NChMXntpA3Dfp+LurYLO0NSREREZLKrqKhg165diS5jwkjaNomAz0VHr9okRERE5NIk6vwreaOL+V4kbRjWbBIiIiJyqXw+H01NTQrEE4BlWTQ1NeHz+S7oeUnbJhHwuWnvCWFZ1nkvTygiIiIynOLiYmpqamhoaEh0KYL9x0lxcfEFPSeJw7CLUMSiNxzF53YmuhwRERGZhNxud/wywjI5JW2bRECXZBYRERFJekkbhv1eOwzrJDoRERGR5JW0YTjgcwPQ3qO5hkVERESSVRKH4djIsNokRERERJJW0obhvjYJXZJZREREJHklbRhOj7VJqGdYREREJHklbRj2x2eTUM+wiIiISLJK3jDsVc+wiIiISLJL2jDscTnwuhy0q01CREREJGklbRiGvksyKwyLiIiIJKskD8Mu9QyLiIiIJLGkD8OaTUJEREQkeSV1GPZ7XWqTEBEREUliSR2GAz6XZpMQERERSWJJHYb9Xrd6hkVERESSWFKH4YDPpanVRERERJJY0ofhjt4w0aiV6FJEREREJAGSPgxbFnQGNTosIiIikoySOgz7vW4ATa8mIiIikqSSOgwHfC4ATa8mIiIikqQUhlEYFhEREUlWCsOg6dVEREREklSSh2H1DIuIiIgks6QOw36v2iREREREkllSh+G+NgldkllEREQkOSV1GE7zuDBGPcMiIiIiySqpw7DDYfB7dElmERERkWSV1GEYwO9zqWdYREREJEklfRgO+FzqGRYRERFJUkkfhv1eF+296hkWERERSUZJH4YDPrdGhkVERESSVNKHYfUMi4iIiCSvpA/D6T7NJiEiIiKSrJI+DPu9Ls0zLCIiIpKkkj4MB3xuekJRQpFooksRERERkXGW9GHY79UlmUVERESSVdKH4YDPDsM6iU5EREQk+SgM94VhzTUsIiIiknQUhn1uQCPDIiIiIslIYdinnmERERGRZJX0YbjvBDq1SYiIiIgkn6QPw31tEhoZFhEREUk+CsOxNok2hWERERGRpJP0YdjrcuB2Gjp0SWYRERGRpJP0YdgYo0syi4iIiCSppA/DYPcNq2dYREREJPkoDENsZFhhWERERCTZKAxjn0TXrp5hERERkaSjMEwsDGtkWERERCTpKAwT6xnWRTdEREREko7CMOoZFhEREUlWCsPYbRIdPWEsy0p0KSIiIiIyjhSGAb/PRThq0ROKJroUERERERlHCsPYPcOALrwhIiIikmQUhoGA1wWg6dVEREREkozCMHbPMKCT6ERERESSjMIw/W0SuiSziIiISHJRGMaeWg3UMywiIiKSbBSGGdAmoZ5hERERkaSiMIx6hkVERESSlcIw/W0S6hkWERERSS4Kw4DL6SDF7VTPsIiIiEiSURiOCfhcdKhnWERERCSpnDcMG2N+aoypN8bsPcvjxhjz78aYw8aY3caYZaNf5tjz+1zqGRYRERFJMiMZGb4fuOUcj98KzI7dPgb84NLLGn8Bn1uzSYiIiIgkmfOGYcuyNgDN59jlbcADlu0VINMYM320ChwvAa9LPcMiIiIiSWY0eoaLgOoB92ti2yaVgM+l2SREREREksy4nkBnjPmYMWabMWZbQ0PDeL71efm96hkWERERSTajEYZrgZIB94tj297Asqz7LMuqtCyrMi8vbxTeevQEfG7NJiEiIiKSZEYjDP8R+EBsVonVQKtlWadG4XXHlT82tVokaiW6FBEREREZJ67z7WCM+R/gOiDXGFMD/D3gBrAs64fA48CbgMNAF3D3WBU7ltJjl2TuDIZJ97kTXI2IiIiIjIfzhmHLsu46z+MW8MlRqyhB+i7J3N6jMCwiIiKSLHQFuphALABrejURERGR5KEwHBOItUloejURERGR5KEwHOP39bdJiIiIiEhyUBiO6TuBTpdkFhEREUkeCsMxfq96hkVERESSjcJwjHqGRURERJKPwnBMqseJw6hnWERERCSZKAzHGGPwe126JLOIiIhIElEYHiDgc9OmnmERERGRpKEwPEDA51LPsIiIiEgSURgewO91qWdYREREJIkoDA8Q8KlnWERERCSZKAwP4Pe5Nc+wiIiISBJRGB5AI8MiIiIiyUVheICA10WbeoZFREREkobC8AABn4tgOEpvOJLoUkRERERkHCgMD+D36pLMIiIiIslEYXiAgM8NoL5hERERkSShMDxAwGePDGuuYREREZHkoDA8gD8WhnVJZhEREZHkoDA8QHpfm4RGhkVERESSgsLwAH0n0KlNQkRERCQ5KAwP0NczrBPoRERERJKDwvAA/vgJdOoZFhEREUkGCsMDeF1OPC4H7RoZFhEREUkKCsNDBLwu9QyLiIiIJAmF4SECPpdmkxARERFJEgrDQ/h9LvUMi4iIiCQJheEhAl63ZpMQERERSRIKw0PYI8MKwyIiIiLJQGF4iIDCsIiIiEjSUBgewp5NQj3DIiIiIslAYXiIgM/uGbYsK9GliIiIiMgYUxgewu9zEbWgKxhJdCkiIiIiMsYUhocIxC7JrBklRERERKY+heEh/F47DKtvWERERGTqUxgeIt3nBtCMEiIiIiJJQGF4iL42CYVhERERkalPYXgIv8KwiIiISNJQGB4iEGuT6OhVz7CIiIjIVKcwPET/CXQaGRYRERGZ6hSGh1AYFhEREUkeCsNDOB2GNI9TYVhEREQkCSgMD8O+JLN6hkVERESmOoXhYfh9Lo0Mi4iIiCQBheFhBHwuXY5ZREREJAkoDA/D73XRppFhERERkSlPYXgY6T43HT3qGRYRERGZ6hSGh+H3qmdYREREJBkoDA9DPcMiIiIiyUFheBh+n4uuYIRwJJroUkRERERkDCkMDyPgcwPQ2RtJcCUiIiIiMpYUhocRiF2SuU0n0YmIiIhMaQrDwwj47DCsvmERERGRqU1heBh9bRKaUUJERERkalMYHoY/PjKsNgkRERGRqUxheBh9bRIaGRYRERGZ2hSGh9F/Ap3CsIiIiMhU5kp0ARNRX89wh8KwiIiIJCnLsrC6ugi3tGDcblx5eRjH1BtHVRgehs/twOkwtGtqNRERmWCsYJBgbS3G5cLh82FSUuylS7/SE82KRgnX1RGqqcEKhzFuN8bjOf9ynAKmZVlEOzuJNDURbm4m0tJCpLmZcLO9jLQ0E25qtrfFHrN6e+PPN2437sJC3MXF9q2oCE9xEe6iItzFxTizszHGjMvXMpr0L2cYxhhdkllExlWorp5QTTXeufNw+tMSXc55Rbu6CDc12b9Um5oINzYRbmok0tRsb29sJNLejjMrC1d+Hu78fFxDb3l5OLzeUavJCgYJt7QQbmyM1dVMpKmRcGMT0e5unOnpOLOycGZm4szKxJmZiSsrC2dWFo5AYEKOeFnRKMGq4/Ts3UP37j1079lN74GDWMHgG3d2u3F4vZgUHw5fLCD7fLHAHNuW4sN4ffbSl4J7egHeWbPwzJyJKytr/L/ASSja2UmwppZQ9QmC1TWEqqsJ1lQTqq6xQ3DoIgbSnM5hQrIb43KDAWMc4HCAMeAwGIx93+F4w+PGmNh+DnAYsCDS2mqH3ebms9ZnUlLsfw85OTjzcvHOmYMzOxtXdhbOrGysYC+h2lr7a6+tpefpp4m0tLzhNdxFhXZILiqOh+S+0OzIyJiQYVlh+Cz8XpdOoBORMRPp6KRr6xY6X36ZzpdeInj4iP2Aw4F39mxSliyJ3RbjKSsbt18g0c5Oeo8eI1RbGwu3fUF3QPBtasLq6hr2+Y70dFw5ObhycnAXFRFpaaF7+w7a6+uH/SXszMgYHJCn2Uv3gMBsRSJEGhvj7322mqKtrcPWZFJTcaSkEGlthfBZ/rvucNghOTNzUGB2DbqfhSsvz64rJ2dMRmJDdfX07NlN95698WW0vd3+OlJSSFmwgKz3vhfv3DlggdXTTbS7h2hPN1Z3D9HeHnvZ0xN/zOrpIdLcQqjnZGyfXqzubqLd3RCN9n8vcnLwzpqFd+ZMPLNm2uuzZuHKzh71r9OKRom0tBCur7dvjY3gdOLwpWB83v7g7kvB4fPayxQ72ON2j+m/BysaJVxfb4fc6hqC1SfsoFtdTbCmhkhT06D9HYEAnpISvHPmELjhetzFJbiLi3B4vVjBIFYoRDQYhNjSCoXi261gCCsUjC0Hbo8tQyGwLLCiWJYFUcv+nlkWlhW17/c93rcejdqPhaPx7687Px/f/PnxYBsPudk5sWU2jpSUCz5W0c5OgrW1hGIBOVRTQ+ikHZi7d+4i2tY2+Fj5/ZT//hE8xcUX/w0aAwrDZxHwuRWGRQYIt7TQtWUrwWNHceXl2R+VFRbimj4dh8eT6PLOygqFiJw5Y3/kd+YMkZYzsaV9P9rZibukBO/sWXhnz8FdOH1MRgitUIjuPXvofOllOl9+me5XX4VwGOP1klpZSebb346nvJyeffvp3rWLtsce48yvfw2AMzOTlMWLSVkaC8gVFTjSLm30ONLRSfDoEXoPH6H38GF6jxwmePgIodrawTsaY//izMnBmZNNyuLF9npuDq7sHFy5OThzcnHl5uDKzsac5WfBsiz7+1Df0B+A6usI1dfHt/UePmyHokjkvPUPDN3e2bNJW73ariknF1dONs6cHFy5ubhycnCkpsZriHZ22t/7+M9Dyxt/PlpaCFVX07N7N5EzZ4YfSTMGZ24O7ryhI955g8K8Mzv7rD9PkfZ2evbujY/49uzZS7iuzn7Q5cI7Zzbpb3oTKYsq8C2swDvzslEN4JZlET51it4jR+h9vf9noPUPfyDa2Rnfz5mVZY8ez5qJd+asWEieiTMn5w2h1LIsom1thOrqhnyv6wk31Pd/vxsazv6Hyfk4nbER8JRBo97G58U4XViRMESiWNGIvYxEIBIZ5n60fxkOx+/3Bdc4h8P+711JMYF163CXlOApKcZdUoqnpBhnRsbFfR1TgCMtDd+cOfjmzBn28UhbW2w0uSYemF25ueNc5fkZy7IS8saVlZXWtm3bEvLeI/EnP3wZY+DXf3ZFoksRSYhIWxtdW7fSuXkzXZu30Pvaa8PvaAyu3Fz7l0VRLCAXFuKePh13YRHuokKcfv8l1WKFw0Q7OwfdIp2dRNvb44HmrGG3o+Osr2tSUuwRw+bm+DZHaiqe2bPwzp6Nb/ZsvLGbMzf3gkajLMsiePQonZteovPll+nassUOGMbgW7CAtCuvJO3KK0hZunTYVgErGiV45Ahdu3bRvWsX3bteJXhkwOjxnDmkLFlMypIlpC5ZgnvGjGHri7S3EzxyZEDgOULvkcOET57qPw5uN57LLouHHM/MmXhmzLBDb1YWxukc8dd9qaxIhEhzcyw02cHJuFz9oTsWdMfrDzA7QHfFfqaaCTc0Dh/u6uvfMGIIgMtlh/JYUHbn5xPt7KR79x6Cx47Fd/PMmIFv0SJSKhbiq6jAN3++PQqaAJZlEa6ri/2h9Lr98xP7o6lvlBrsUX3P7Fm4cnIJN/Yfl4E9pn0cGRm48/NwDfPHgzs/H2duLkSj9kh2b09sRLt70P1oTzdWT2zUe+Dod09vfGTcikYwDic4HRiny14OuG+cDnA47Z9pp/ON9x0OjMdjf7xfUoynpAT39OkYt3s8vwUyBowx2y3Lqhz2MYXh4X34/q2cbuvhsc9ck+hSZAqxLMv+6Ku7O/Yf9O7+jyx7eoh2d2P19g76RRDt6YZwGFf+NDwzSvGUluIqKBj1gBLp6KR7+zY6X9lM1+bN9Bw4AJaF8XpJWbaUtFWrSF25Ct+8uYSbmgjVniR08o238KlTbxhJc6Snx0eS3bGgDNbgYBu/db0h+A73y3UoR2rqoI+z+5cZ9sfbfff7HsvMjIeNSFub/cv+9df7b4cODeqHc2Zm2mFxTn9A9s6ePWhUKFRfT9crr8QDcLi+HgB3aSlpV1xhB+BVK3FmZl7c96i1le7du+neGQvIu3fHw74zK4uUxYvxVSwk2vf1HDlC+PTp+PON19sfemfOxBv7KNxdXKyTr0aBFQzaLRv19YPC/MDR0VB9PcbjJqViUXzEN2Xhgov+mRhPlmURrm8geOTwgE8UjhBpaelvHxmuPzwvL2HBXqSPwvBF+OyDO9l54gwbvrQ20aXIBbKiUSKtrZjYySS4XKPaXzZ4pCg2GnmmZfiPW8+cIdrWZgfdWPhlFP7NGbfb/qiutBR3aQme0hnxoOwuLBzRKEa0q4uuHTvp2ryZzi2b6dm7DyIRjNttjzauWkXaqpX4Fi++oFE4Kxq1R4mGBuUB4XngR7CO1FQcaWnnufXv4xy4PRDAmZmFMytzTEYKw01NsWA8ICQfPjxotNmVn4931izCDfX0vn4YsINz6hWr4wF4rPrjrEiE3iNH4iPH3bt2ETx6FJOSgveyy2KjvP0fa7uLisZ1lFdEZKJQGL4IX/n9Hh7fc5odf3tjokuRs4h0dBI8doxg1TGCx47Re+wYwWNVBKuqsHp6+nd0ODBeLw6PB+P12us+L8bjjd334PB4MT6fve6NPebxEO3uGvyxeyzonvVsYWNwZmQMHp1MD8R621Ls3rYBZ3IPPrPbhyMlxa4v3guXYgd6h4NwXR3BEycInjhB6MQJgsft9WB19eCTmZxO+8zdkhI8M0pxl5baYbm0hHBjE11bNtP5yma69+yx++JcLlIqKkhdtZK0Vavsj+3HcBTHsiw7TBoHjtSUCXkG/7lYlkX49OkBI8h2QHZmpJN25ZWkXnEFvvnzE/Z1RTs7MSmT77iKiIylc4VhfS52Fn6vm/aeEJZlTchpQJKFFYkQOnnSDr0DA++xY/GPoAH7BIeiIjzlZaStWom7sBArEsUK9tojsr1Bu/0g2Btft3p77RaFnl7CrW1vfCwYxJGSEg+17tISfIsq7KlnMjPjI5LOzAFTNaWnj9nIW1+LQdrq1YOPkWURaWy0g/HxEwRPHCd0oprgiRO0/u+jg3r8+o6Vb+FCcj70QVJXriJ12dJLPhnrQhhjcAYC4/Z+o80YY/dDT5+Of82aRJfzBuP5vRQRmQoUhs8i4HMRilj0hqP43FPzY8VoVxfdu3bRtW0bwZoanH4/jjS//dFzwI/Db9+cgUBsvX/7xQQ+Kxwm2t1NtKsbq7uLaFdX7H4X0a7YsruL8Om6/hHf4ycGzafpyMjAW1Zmf/RcXo6nvAxveTnuGTMm9IwGY8kYY/fr5eWRunz5oMf6zuAPVVcTPH4CR8BPamXlJZ/QJiIiMlUoDJ9FwGcfmvae8JQJw5HWVrq276Br2za6tm+jZ99+e2obhwN3QQHRri4iHR0jmu7GpKba4TkQwOFPw+kP4EhLwwoG+wNuLPBasaA77CTxw3G57I/4y8tJW7MGb3l5LPiW22e2a6R+xIwxuLKycGVlkbJoUaLLERERmXAUhs+iLwx39IbJC4zeFZLGU7ihga7t2+nauo2ubdvoPXTInh3A7ca3aBE5H/4wqZWVpCxdEh8ptCzLbhFobyfS3kG0s6N/vaODaEdsvb2dSGcH0b71jnZCdacxHo99Vn9mJu7CQrv3NTUFR2qq3f+ammZvS7Mnwbe3pfbfUlJwZmRoGhsREREZFwrDZxHw2mGsveciLquYIKHaWnvUd9s2urZuI1hVBdijuKlLlhD49Kfs8Lto0VlPkDLGxC/f6crLG8fqRURERMafwvBZ+PtGhifwVehCtbV0bNoUH/kNn7In0Xekp5O6fDmZd9xB6opK+8x2jbSKiIiIvIHC8Fn0tUm0TaAwHOnopGvLFjo3baJz06b4yK8zN5fUFZWkfvjDpK6oxDt7tqZVEhERERkBheGz6GuT6OhNXBi2IhF69u+3w++Lm+jatQvCYUxKCqkrV5D1nrvsWRVmztRJZSIiIiIXQWH4LPpnkxjfnuHQqVN0btpktz+89DKR1lYAfJdfTs7dd5N21VWkLFuatNOIiYiIiIwmheGz8A+YWm0sRTs76dy6lc5NL9mtD0ePAvYlXv3r1pF21VWkXbEaV07OmNYhIiIikowUhs/C7XTgcztGvU0i3NxM96uv2rcdO+nauRNCIYzPR+qKFWT+yR34r7oKz6xZan0QERERGWMKw+fQd0nmixUNBundv5/u3bvp3vUq3bt3E6qpsR90OvHOnUPOBz8Qa31YhsM7OeczFhERkSQW7oWuZuhqGnIbZtsH/gCp2YmueBCF4XNI97lG3CZhWRah6urYqO9uunfvpufAAQjZYdpVUEDKokVk3XUXKYsX4VuwAEdKyliWLyIicmmiEQh1Qagbgp32erALQp392yJBMI5z3xzO2LoZsN05ZD8DmAHLviLMMI+dY2mc4Ii9vsPZ/z6Ogcsh6w5n7DVGiWXZATHYYd96hyxHtB47xv0v+sb3OOtjQ+pxusDpBacbXF5wevpvrr718zx+rsAbbD/7sfBlQGqOfUsvhMjEu36DwvA5+M8RhiNtbXTv3kP3brvloWf3HiItLYB9kYuUBQvI+eAH8C1aRMrixbinTRvP0kVEJBmFe6G3HXrb7FDV2z7g1jb4fl/4CnbFQm7nG4NvuCfRX9E4Mv2Buc/ZAmd8+3Dbhmw/H4cbvH7wxG5eP3jSwD8N3CkM+KtgmMA+kscsO4BGgv23cDD2h0yz/Vi4N7ZPb//jkSBEhwRXj98e1e0Lt7mzY+sDtg28pWTZAXuCUxg+h4DPNahnOHT6NG2PP0HbY4/Rs2+fvdEYPDMvw79uLSmLFpOyeBHeWbMwLh1aEZFhWRZEw7FfwEN+QUeCsV/Iof7HsQaP8jmc4HANM7LnfOPon8Nlr2PAitgjndHwgPVIbD085P7A/cIQjcZq7rFvoe7YsgtCZ9vWPWA5YD0aGfA1xEYx4+uuAV+Da8jXMWA/Y+wwMzTgRoLnP/7GAd4AeAJ28HKn2jd/vr30pNkhLL6eCp7U/v36trlT7HWnx/4eRaNgDXeLxJZW/7ZoZJh9sF/HsoiHyb71ES0Z8vqRAe8TidU3dFtk8P5964OC5dkC53DbB2xz++xj7EkbJuz6Y9+DNHskdqKKRu1AHO61v8/u4a9eO9kpsZ2D3+uis6GOlgd/Tdtjj9G1bRtYFr6FC8n77GdIWbwYX0UFzkAg0aWKiJxfNDogfA4YBRo0ahRbD/cOCHi9dogL9w6+3xcC4wFxmPW+YDs07E4lxgGuFDsouFJiQdLXv82XEduWAi6fHXDjYS06JHT3BbLwkEAetY+f1R3bZtlhKqPEXvbdPH7wpg/e5g0M3uZOGd2WAJm6HA5weCd2YB8FCsPDiHZ20v7cet7x0P9QeGgXp60onvJycj/1STJuuw1PWVmiSxSR8RYJxUb3uvs/Sh64bkViOw7Xx8g5HostAbCGBMruYZa9Q0YchyzDvQM+8hwSdOM1joJ4+Btw67vv8UNaXqzf0HdpfYpOD4NGdQeN5oWH2RZ5477RiH1sB462xkdihxtxHrp9wGhtX6CNL1Pt+hUuRSYtheEYKxik48VNtD36KO3r12N1d5ObkcPjc67ls//8Kbzz52uqM5FLEY1C+yloOQYtx+0QCYN770b6kWjf8wZ99DrgY9c3fAQ7dNuAj22jkQEfYw8MukMCb3QCXJq9L1zGg+eQ0cjU7NjjsYA5MFzGb+6zrw99Xjz0ee33cHnt+06Pwp+ITBlJHYatSISubdtpe/RR2p5+mmhrK87MTDLe9lYybruNHzb5+eELR/niPAVhkREJB6G1GpqPQvMxO/j2LVuqxv5knEFnpg84U90xzPaBZ7f39T+6U+0TPtILB3zcnTpkOXQ9xd7X6RoQ2uHCeh9j+2MGh89BgTf28bqIiIyqpAvDlmXRs3cfbY89RtvjjxOur8ekphK44XoybruNtCuvxLjtMx/9G45gWdAZDBPwTfyzIUXGnGXZZ5+3VA0Ou81H7fXWGnvEtY87FbLKIWcWzLoBsssh+zLIKrM/So+3CTB4fUTTKDEk9BqNVoqIyAVLqjAcrKqi+s8+TvD4cXC78a9ZQ8abb8N/3XXDzvnbF4A7ehWGZZxYFvS0QmdD/62j3p7HMRrmrCOKZz2zesj2aHjIiUzBwWf0Dzu9zjBn9g+Ukm2H3OKVsOjd9npWub30T1NAFRGRCS2pwrC7sBDPzJnkfPQjBG68EWdGxjn3D/jsw9PeE2b6uXcVObtIaEi4bRh8f+j2ofM6DjLM6OiFTEjvcA44Ock7ZN0NqWnDn9A0cN2TCpkz7BHe7HL7THkREZFJKqnCsPF4KPl/9454f7+3PwyLnJNl2SO4ja9B4yFoOBRbfx3aaod/jtNrz+uZlgv+AphWEVvPt8/ET8uFtNh6ao7dkyoiIiKjSr9dz6GvNaK9Z+JdOlASJBqx+2UbD0FDLOz2BeCe1v79PH7InQNl19gjqP68WMCNhd+0PHu+T7UQiIiIJJTC8Dn0tUkMvAqdTHCWZV8rvf1U/9RZ9gP9j/fvPGjxhn2sqD0zQkMs7DYegqbDg6/w5J9mh96F74K8ufZ67hx7NgIFXRERkQlPYfgcBvYMywQSCcWm74pN19U3bVdzlb0Mto/u+xmH3SObN9eeESEeemfb03CJiIjIpKUwfA59PcMdCsPjr6d1mLAbW7bWDL6SltMLWTPs6bpmXGkvM4rsq0YB8at7DXft+KHbht5Pnw7ZM6fs9dhFRESSncLwOaR5XBijnuFRF+yy2xjaaqHt5IBlbNuZ49DdMvg5qTl2yC1eARV3xKbvKrOn8ApMty+qICIiInKBFIbPweEw+D0u2jQyPHI9bXawbT8ZC7gDw25sfWjQBfBlQnqR3WtbuLR/rtqsMvvmSx/nL0RERESSgcLweQR8Lp1AN9SgGRUODphG7DD0tr5x/7Q8O+RmlkLpanu9L/gGCu1WBE/auH8ZIiIiIgrD5+H3uZK3TSLca8+e0PBabEaF1+zg23TYvipZH38B5M2BRXfYgbcv6KYX2i0MLm/ivgYRERGRc1AYPo+Azz31R4ZDPVC3LxZ2BwTflip7ejEAjH2SWu5cmLXOXubNi82okJnA4kVEREQunsLwefi9Llq6guffcTIJ90LNNqjaCMc2Qs3W/pFehxtyZkFBhX2iWu4ceyqxnFngTkls3SIiIiKjTGH4PAI+F9XNXYku49KEg3ByR3/4rd4C4W7AwPRFsPKjdi9v3nz7ZDVd9ldERESShFLPeQR8k3A2iUgYTu60w2/VRjjxCoRigX7aQlj+ISi/xp6TVxeNEBERkSQ2ojBsjLkF+D7gBH5iWda/DHm8FPg5kBnb5x7Lsh4f3VITw+4ZnuAn0EUjcOrV/pHfEy9DsMN+LG8+LH0flF0DZVdDanZiaxURERGZQM4bho0xTuBe4EagBthqjPmjZVn7B+z2FeA3lmX9wBhzOfA4UDYG9Y47v9dFTyhKKBLF7ZxAF3aIRuHY87D9fjiyHnrb7O25c2DRnbGR36vBn5fIKkVEREQmtJGMDK8EDluWdRTAGPMg8DZgYBi2gL6rImQAJ0ezyEQK+PovyZyV5klwNdgXrNj1K9j6X9B8xL4y24K3Q/kae+Q3UJDoCkVEREQmjZGE4SKgesD9GmDVkH2+CjxtjPk0kAbcMCrVTQABnxuA9kSH4ZO7YOuPYc/D9slvJavgunvg8rdpHl8RERGRizRaJ9DdBdxvWda3jTFXAP9tjFloWfFJagEwxnwM+BhAaWnpKL312PJ77UPUnoi+4VAP7HsEtv4EareBOxUW3wmVH7ZngRARERGRSzKSMFwLlAy4XxzbNtCHgVsALMt62RjjA3KB+oE7WZZ1H3AfQGVlpXWRNY+r9FibRPt4zijRfAy2/RR2/gK6m+0+4Fv/FRa/G3wZ41eHiIiIyBQ3kjC8FZhtjCnHDsHvBt4zZJ8TwPXA/caY+YAPaBjNQhPFP6BneExFI/D6M/Yo8OFnwThg/pthxUfsmSCMGdv3FxEREUlC5w3DlmWFjTGfAp7Cnjbtp5Zl7TPG/COwzbKsPwJ/AfzYGPN57JPpPmRZ1qQY+T2feM/wWLVJdDbCjgdg28+g9QT4C+Dav4LlH4T0wrF5TxEREREBRtgzHJsz+PEh2/5uwPp+4KrRLW1i6OsZHvWR4Zbj8NzXYf/vIRK0R39v+hrMuw2c7tF9LxEREREZlq5Adx59U6uN2lXoLAt2/Bye+hv7/vK7YcWHIW/u6Ly+iIiIiIyYwvB5eF0O3E5DR+8ohOG2U/C/n4HXn7bnBX7b/4PMkvM/T0RERETGhMLweRhjCPjctPdcQs+wZcHeh+Gxv4BwL9z6LfvEOMcEuqKdiIiISBJSGB4Bv9d18VOrdTbCY1+A/X+A4hVw+w8hd9boFigiIiIiF0VheAQCPtfFnUB38HG7LaKnFW74Klz5GXA4R70+EREREbk4CsMjcMEjwz2t8ORfw65fwrQK+MAfYNqCsStQRERERC6KwvAIBHxuas90j2znI+vhD5+C9lOw5ouw5kvg8oxtgSIiIiJyURSGRyDgc53/BLpgJzzz97D1x5AzGz78DBQvH58CRUREROSiKAyPQMDnOvfUaic2w+8/Ds1HYfUn4Pq/A3fK+BUoIiIiIhdFYXgE+nqGLcvCGNP/QKgHnv8GvPQfkFEMH3wUyq9JXKEiIiIickEUhkcg4HMTiVr0hKKkeGKzQZzcBY98HBoOwLIPws3/BN5AQusUERERkQujMDwC/tglmdt7QnYY3vHf8OjnIDUX3vNbmHNTYgsUERERkYuiMDwC6X1huDdMPsDGb0PBInjfw5CandDaREREROTi6XrAIxCIjwyHobUGWo5BxbsUhEVEREQmOY0Mj4Df6wawr0LXtNHeWKYT5UREREQmO40Mj0BgQM8wVS9CShZMW5jgqkRERETkUikMj4Df298zTNUGmHEVOHToRERERCY7JboRSPfZbRJWy3E4cwLK1yS4IhEREREZDQrDI5DmtecWzq7fbG8ouzqB1YiIiIjIaFEYHgGX00Gqx8m05i2QmgN58xNdkoiIiIiMAoXhEfJ7nJS27bBHhdUvLCIiIjIlKNWN0BxvI5mhek2pJiIiIjKFKAyP0Gqz317RyXMiIiIiU4bC8Agti+6hxZEFuXMSXYqIiIiIjBKF4ZGwLC7v3c0ux0IwJtHViIiIiMgoURgeiaYjZEaa2GxdnuhKRERERGQUKQyPRNUGADaE5iW4EBEREREZTQrDI3FsIx2ePPYH84lErURXIyIiIiKjRGH4fCwLql7kdFYlYOjoDSe6IhEREREZJQrD59N4CDrraclfBaAwLCIiIjKFKAyfzzG7X7iz8EoA2ntCiaxGREREREaRwvD5VG2E9GIc2eUAdPRoZFhERERkqlAYPpdoFKpehLKrCaS4AWhXGBYRERGZMhSGz6XhAHQ1Qfk1BHwuANrVMywiIiIyZbgSXcCEVvWivSy7hoCzb2RYPcMiIiIiU4VGhs/l2AbILIWsGfi99t8N6hkWERERmToUhs8mGoXjm6BsDQCpHicOo55hERERkalEYfhs6vZCdwuUXQ2AMQa/16V5hkVERESmEIXhs+nrFy6/Jr4p4HPTpp5hERERkSlDYfhsqjZCVjlkFMc3BXwu9QyLiIiITCEKw8OJRqBq06BRYbDDsHqGRURERKYOheHhnN4Nva3xk+f6+L0u2nvVJiEiIiIyVSgMD+fYRnsZO3muT8DnVpuEiIiIyBSiMDycqhchZxakTx+02a82CREREZEpRWF4qEgYjr8EZde84aGAz6XLMYuIiIhMIQrDQ516FYLtbzh5DiDgdREMR+kNRxJQmIiIiIiMNoXhoao22MthR4bdgC7JLCIiIjJVKAwPVfUi5M4Ff/4bHgr4XIAuySwiIiIyVSgMDxQJwfGXh22RAHtqNUCXZBYRERGZIhSGBzq5E0Kdw7ZIQH+bhC7JLCIiIjI1KAwPdOzs/cLQ3yahnmERERGRqUFheKCqjZC/ANJyhn1YPcMiIiIiU4vCcJ9wEE5sfsNV5wZSz7CIiIjI1KIw3Kd2O4S7z3ryHNhXoANoV8+wiIiIyJSgMNynaiNgYMZVZ93F63LicTl0FToRERGRKUJhuM+xDVCwEFKzz7lbus+lnmERERGRKUJhGCDUAzVboWzNeXf1e12aTUJERERkilAYBqjdBuGec5481yfgc6tnWERERGSKUBgGOLYRjANmXHneXf1el2aTEBEREZkiFIbBPnmuYBGkZJ5314B6hkVERESmDIXhULfdL3yOKdUG8isMi4iIiEwZCsPVWyASHNHJcwDp6hkWERERmTIUhqs2gnFC6eoR7d7XM2xZ1hgXJiIiIiJjTWH42EYoXAK+9BHtHvC5iFrQFYyMbV0iIiIiMuaSOwwHO+3LMJeNrF8Y7KnVAPUNi4iIiEwByR2GT7wC0dCIT54D+wQ6gI5e9Q2LiIiITHbJHYarXgSHC0pG1i8MdpsEQJtGhkVEREQmvSQPwxuhcBl4/SN+SsAbGxlWGBYRERGZ9JI3DPe2Q+2OC2qRAPUMi4iIiEwlyRuGT7wCVuSCTp4D9QyLiIiITCXJG4arNoLDDSWrLuhpfT3DGhkWERERmfySNwwf2wjFleBJvaCnpXkUhkVERESmiuQMwz2tcGrXBbdIADgdBr/XpTAsIiIiMgUkZxg+/jJY0Qs+ea6PfUlm9QyLiIiITHbJGYarNoLTC8UrL+rpAZ9GhkVERESmguQNwyUrwe27qKf7fS46ehWGRURERCa75AvD3S1wajeUXX3RL5Ef8PLa6XZ6QpFRLExERERExlvyheHjLwHWRZ081+eDV5RR397L/2w5MXp1iYiIiMi4S74wfGwjuHz2tGoX6cpZuVxxWQ73rj9CV1DtEiIiIiKTVfKF4aoX7QttuLyX9DJ/cdMcGjt6eeDl46NUmIiIiIiMt+QKw13NULfnoqdUG6iyLJtr5+TxoxeO0N6jadZEREREJqPkCsPRCFz9BZhzy6i83F/cNIeWrhA/21Q1Kq8nIiIiIuMrucKwPw9u+HsoqBiVl1tUnMmNl0/jxxuP0tql0WERERGRySa5wvAY+MKNc2jvCfPjjUcTXYqIiIiIXCCF4Us0f3o6b140nZ9uOkZTR2+iyxERERGRC6AwPAo+d8McekIRfvjCkUSXIiIiIiIXQGF4FMzK93P70iIeePk49W09iS5HREREREZIYXiUfPb62USiFveuP5zoUkRERERkhBSGR8mMnDTuqCzmf7ZUU3umO9HliIiIiMgIKAyPok+tmw3Afz73eoIrEREREZGRUBgeRUWZKbxnVSm/2VbD8abORJcjIiIiIuehMDzKPnHdTFwOw/f/T6PDIiIiIhOdwvAoy0/38cEry/j9zloO17cnuhwREREROQeF4THwZ2suI8Xt5LvPanRYREREZCJTGB4DOX4vd19VzmO7T3HgVFuiyxERERGRs1AYHiMfveYyAj4X33nmUKJLEREREZGzUBgeIxmpbj52zWU8s7+OV6vPJLocERERERmGwvAYuvvqcrJS3RodFhEREZmgFIbHkN/r4uPXzuSFQw1srWpOdDkiIiIiMoTC8Bj7wBVl5Pq9fPvp1xJdioiIiIgMoTA8xlI8Tj65diavHG3mpcONiS5HRERERAZQGB4Hd60sZXqGj397+jUsy0p0OSIiIiISM6IwbIy5xRjzmjHmsDHmnrPs8yfGmP3GmH3GmF+NbpmTm8/t5NPrZrPjxBmef60h0eWIiIiISMx5w7AxxgncC9wKXA7cZYy5fMg+s4G/Bq6yLGsB8LnRL3Vyu6OymJLsFL79jEaHRURERCaKkYwMrwQOW5Z11LKsIPAg8LYh+3wUuNeyrBYAy7LqR7fMyc/tdPDZ6+ewt7aNp/bVJbocEREREWFkYbgIqB5wvya2baA5wBxjzCZjzCvGmFtGq8Cp5PYlhVyWl8Z3nzlENKrRYREREZFEG60T6FzAbOA64C7gx8aYzKE7GWM+ZozZZozZ1tCQfL2zLqeDz90wh9fq2nl0z6lElyMiIiKS9EYShmuBkgH3i2PbBqoB/mhZVsiyrGPAIexwPIhlWfdZllVpWVZlXl7exdY8qb25YjpzpwX43jOHCEeiiS5HREREJKmNJAxvBWYbY8qNMR7g3cAfh+zze+xRYYwxudhtE0dHr8ypw+EwfOGmORxt7OT3u04muhwRERGRpHbeMGxZVhj4FPAUcAD4jWVZ+4wx/2iMeWtst6eAJmPMfmA98EXLsprGqujJ7qbLp1FRlMH3nj1EbziS6HJEREREkpZJ1DRflZWV1rZt2xLy3hPBxtcbeP9/beHOyhL+5Z0VGGMSXZKIiIjIlGSM2W5ZVuVwj+kKdAlyzew8Pr1uFr/eVs3PX6pKdDkiIiIiSUlhOIE+f8Mcbpg/ja89doBNhxsTXY6IiIhI0lEYTiCHw/DdOxdzWW4an/zVDk40dSW6JBEREZGkojCcYAGfm598sBLLgo88sJWO3nCiSxIRERFJGgrDE8CMnDTufc8yjjR08vlf79LV6URERETGicLwBHH17Fz+5k3zeWZ/Hd979lCiyxERERFJCq5EFyD97r6qjAOn2vj35w4ztyCd2xZNT3RJIiIiIlOaRoYnEGMMX3/7QpaVZvKXv32VfSdbE12SiIiIyJSmMDzBeF1Ofvj+5WSkuPnYA9tp6uhNdEkiIiIiU5bC8ASUH/Bx3weW09jRy5//cgfBcDTRJYmIiIhMSQrDE9Si4kz+9V2L2HKsmX/4332JLkdERERkStIJdBPY25YUsf9UGz964Sjzp6fzvtUzEl2SiIiIyJSikeEJ7ks3z2Pt3Dy++sd9vHK0KdHliIiIiEwpCsMTnNNh+P5dSynNSeUTv9xBdbMu2SwiIiIyWhSGJ4F0n5sff6CSUCTKRx/YRldQl2wWERERGQ0Kw5PEzDw//37XUl6ra+cvf/sqlqVLNouIiIhcKoXhSWTt3HzuuWUej+85zX8+dzjR5YiIiIhMeppNYpL52JrLOHi6nW8/c4i5BQFuWlCQ6JJEREREJi2NDE8yxhj++R0VLCrO4PO/3sVrp9sTXZKIiIjIpKUwPAn53E7ue38lqV4XH31gGy2dwUSXJCIiIjIpKQxPUgUZPn70/uWcbu3hbfduYsux5kSXJCIiIjLpKAxPYstKs/jlR1cBcOd9L/O1R/fTE4okuCoRERGRyUNheJJbUZbNE5+9hvetmsF/vXiMN/37RnaeaEl0WSIiIiKTgsLwFJDmdfG12xfyiw+voicY4Z0/eIlvPnmQ3rBGiUVERETORWF4Crl6di5Pfn4N71pezA+eP8Jb/uNF9tS0JrosERERkQlLYXiKSfe5+dd3LeanH6rkTFeI2//fJr77zCFCkWiiSxMRERGZcBSGp6h186bx9OfX8NbFhXz//17n9ns3cfB0W6LLEhEREZlQFIansMxUD9+9cwk/fN9y6tp6eMt/vMi96w8T1iixiIiICKAwnBRuWVjAU59bw02XF/Ctp17jnT98mcP1HYkuS0RERCThFIaTRI7fy73vXcZ/3LWU402d3PbvG/nJxqNEolaiSxMRERFJGIXhJPOWxYU8/fk1XDM7j68/doB33/cyVY2diS5LREREJCEUhpNQfsDHjz+wnG/fsZiDp9u59fsbuW/DEVq7QokuTURERGRcGctKzMfklZWV1rZt2xLy3tLvVGs39zy8hxcONeBxObhx/jTesayINXPycDv1t5KIiIhMfsaY7ZZlVQ73mGu8i5GJZXpGCvffvYJ9J9t4aHsNf3z1JI/tOUWu38NbFxfxzuVFLCjMSHSZIiIiImNCI8MySDAc5YVDDTy8vYb/O1hHKGIxryDAO5cV87alheQHfIkuUUREROSCnGtkWGFYzqqlM8iju0/y8I5adlWfwWFgzZw83rmsmBsvn4bP7Ux0iSIiIiLnpTAsl+xwfQe/21HDIztrOdXaQ8Dn4s2LpvOOZcVUzsjCGJPoEkVERESGpTAsoyYatXj5aBMP76jhyb2n6QpGmJGTyjuWFvOOZUWUZKcmukQRERGRQRSGZUx09oZ5cu9pHt5Rw8tHm7AsuOKyHN69soSbFxSojUJEREQmBIVhGXO1Z7r53fYafrO9murmbjJT3bx9aRHvXlHK3IJAossTERGRJKYwLOMmGrV46UgTD249wdP76ghGoiwtzeTdK0p486JC0ryazU9ERETGl8KwJERzZ5Df7ajhwa3VHK7vIM3j5K1LCnn3ilIWFWfopDsREREZFwrDklCWZbHjRAv/s6WaR3efpCcUZV5BgLtWlnL7kiIyUt2JLlFERESmMIVhmTDaekL8cddJfr21mj21rXhdDt5UMZ07V5Swqjxbo8UiIiIy6hSGZULaW9vKr7dW8/udtbT3hinPTePOFSW8Y2kR+em60p2IiIiMDoVhmdC6gxEe33OKB7eeYGtVC8bAihnZ3FpRwC0LC5iekZLoEkVERGQSUxiWSeNwfQeP7j7JE3tO81pdOwBLSzN508Lp3LKwQBf1EBERkQumMCyT0pGGDp7ce5rH95xi38k2ABYVZ3DrwuncurCAsty0BFcoIiIik4HCsEx6x5s6eWLvaZ7Ye5pXq88AcPn0dG5dWMCtFdOZle9PbIEiIiIyYSkMy5RS09LFk7FgvP14CwBzpvm5deF03lQxnTnT/JqVQkREROIUhmXKOt3aw1P77FaKLVXNWBZclpvGjQumUVGUwbyCAGU5abicjkSXKiIiIgmiMCxJob69h6f31fHk3tO8fLSJSNT+2fa4HMzO9zO3IMC8ggBzC9KZVxAgP+DVCLKIiEgSUBiWpNMTinC4voPXTrfzWl07B0+389rpNuraeuP7ZKa6mTutPyDPLQgwtyCA3+tKYOUiIiIy2s4VhvVbX6Ykn9vJwqIMFhZlDNre0hm0w/GptnhIfmh7DZ3BSHyf4qyUWEAOcO2cfFaUZWkEWUREZIrSyLAkvWjUovZMd3z02F62c7Sxk0jUYkZOKu9cVsw7lhVRnKV5jkVERCYbtUmIXISuYJgn9pzmoe01vHy0CYArZ+bwruXF3LKwgFSPPlgRERGZDBSGRS5RdXMXv9tRy0M7qqlu7sbvdXFbxXTeVVlM5Qy1UYiIiExkCsMioyQatdha1cxD22t4bM8puoIRZuSk8q5lxbxjeTFFmSmJLlFERESGUBgWGQOdvWGe2Huah7ZX88rRZowZ0EaxYDopHmeiSxQREREUhkXGXHVzFw/vqOHhHTWD2ijuqCxmudooREREEkphWGScRKMWW2JtFI/H2iiKMlNYMyeXq2blcuXMXLLTPIkuU0REJKkoDIskQGdvmMf3nOKZ/XW8fLSJ9p4wAAsK07l6Vi5Xz85lRVk2PrfaKURERMaSwrBIgoUjUfbUtrLpcCMvHm5k+/EWQhELj8tB5YwsrpqVy9WzcllYlIHToZYKERGR0aQwLDLBdAXDbDnWHAvHTRw41QZAus/FlTNzuWp2LtfMymVGTqr6jUVERC6RLscsMsGkelxcNzef6+bmA9DY0cumw412OH69kSf3nQagKDOFq2flsnpmNmkeFxZgWWBZVnw9Gl+3/7CNWlZsH7Bi97HAwsLndpLn95Lj95Lr95CV6sGhkWgREUliGhkWmWAsy6KqqYsXDzey6fVGXjrSSFus33i0OR2GrFQPuX4PeQEvOWkecv1ecvvWA95YePaQk+bF43KMSR0iIiJjSSPDIpOIMYby3DTKc9N4/+oZRKIWh+s7CEWiGAMGYy8NOIzBYK+DwWHs5xtij5m+17S3d/WGaejopakjSGNHL42D1oMca+yksaOXnlB02NoyUtwUZqawZnYu18+fxrLSTFxOBWQREZm8NDIsIoNYlkVXMBIPy42xsNwXmo80dLDlWDOhiEVmqpu1c/NZNy+fa+fmke5zJ7p8ERGRN9DIsIiMmDGGNK+LNK+LGTlpw+7T3hNiw6FG/u9gHesP1vPIzlpcDsPK8mzWzcvnhvnTKMsd/rkiIiITiUaGReSSRKIWO0+08H8H6/m/A3UcqusAYGZeGtfPn8b18/JZPiNL7RQiIpIwmlpNRMbNiaYu/u9gHc8drOeVo02EIhYZKW6um5vH9fOnce2cPDJS1E4hIiLjR2E4JhQN8Z87/5P3X/5+clNyx/W9RZJRe0+Ija838uyBOp5/rYHmziBOh2FFWRZLSrKYle9nVr6fmXlpBNRvLCIiY0RhOObImSPc9dhdlAZK+dktPyPgCYzr+4sks0jUYld1C88eqGf9wXoO13cQjvb/96cg3RcPxrPy/cyMBeU8v3dULjzS3hOirq2XurYeTrf2UNfeQ11rD2e6Q5TlpLGgMJ2FRRlMz/DpQiciIlOMwvAAL9W+xCf/75MsyV/CD2/8IV6nd9xrEBEIRaIcb+riSEMHh+s7OFLfweEGe9kZjMT3S/e5YiHZHx9JnpXvpzgrFafDEAxHaejotQNum3073dZDfdvgbQNfc+Brp6e4OXmmm75cnpXqZkFhBguK0llQmMHCwnTKctJ0cRIRkUlMYXiIx44+xj0b7+GG0hv4t2v/DafDmZA6ROSNLMvidFsPh+s74jc7MNtzIPfxuBwEvC6aOoNveA2P00F+upeCdB/TYreCDG//erqP/HQvqR57Qp3uYIQDp9vYV9vKvpNt7D3ZyqHTHQQj9nzLaR4n86fbI8eXF6azsDCD2dP8uHVSoIjIpKAwPIxf7P8F39z6Td4151383eq/08eiIpNAa1eIww3tHKnv5HBDB+09oUEB1w69PrJS3Zf8bzoYjvJ6fTv7TvaH5P2n2uiKjTB7nA7mFPhZWJjBgsJ0irNTSfe546PN6T43PrdD/20REZkAFIbP4vs7vs9P9vyEP1v0Z3xq6acSWouITHyRqEVVUyd7a1vZHxtB3neyjTNdoWH3dzlMLBi7CPjcpKe4YoHZTSAemvses9ez0zxkpnrITHWP28hzMByluTN2cZXOIM2dvbidDhYUZjAjO1UtIiIy6emiG2fxmaWfobmnmR/t/hHZvmzeM/89iS5JRCYwp8MwM8/uX37bkiLAbus42WqflNfeE6KtJ0xbd4j2njBtPSHauu1t7bH1urbe2HqY7tAb+5gHCgwIx9mpbrJSPWSlechKdceWsVuam+xUez+Py0EkatHSFaSpI0hTLOD2LRs77LDb1BGM3e+lvSd89hq8LhYUpVNRlMHC2K1cPdQiMoUkdRg2xvC3q/+Wlp4W/mXLv5Cdks0tZbckuiwRmUSMMRRlplCUmXLBzw1FonZo7g7R1hOitTtES1eIM11BmjuDnOkK0dwZpKUrSENHL4fqOmjpCsZbNYaT6nHSHYow3Id+DgPZaR5y0rxkp3lYUJhOrt9LTpqHbL+9PdfvITvNQ1cwwt7aVvaebGVPbRs/f/k4wbDdQ+33uri8sC8g28vyXD9OBWQRmYSSuk2iT0+4hz975s/Y3bib/3f9/+OKwisSXZKIyFn1hiODgnJLZyi2DHKmO0Sa10VOmoecIQE3M9Vz0YE1FInyel0He0+2sre2lT21rRw41UZPyA7IqR5nfHq6hYUZVBRnMDNPAVlEJgb1DI9AW7CNDz35IWrba/npzT9lQe6CRJckIjKhhSNRjjR0sqfWDsh7Yyca9rV/eJwO0rxOUtxOfJ7Y0j1g6XHiczlIiT3mjT2W4ra3+WL75fq9lGSlkOv3qj1DRC6KwvAI1XfV84EnPkB3uJsHbn2AGekzEl2SiMikEolaHG2wR5BfO91BZ6/dG90Tu3WHInQHI/SEovH7/cvoOV/b43JQnJlCcXYqxVkpsVsqJbFlrt9zybN3RKMWbT0hGof0Wzd2BGntDlGUmcKCQnsO6ozUxFw10bIs2nrCBLwu/XEgMkIKwxegqrWKDzzxAVLdqTxw6wPkp+YnuiQRkaQQjVr0hvtDcl9wbmjvpaali5qWbmpauqmOrTcPmWPa63L0B+Rse9l3PzPF3X9SYWdvLOza630nEzZ19NLcGRx0ZcSB/F4XHb39JxsWZ/UH474WkfzA6Fwxse941LR0c7ihndfrOni93r4dqe+gozccn097eoaPgowUe5nui923b3l+Ly7Nhy2iMHyh9jXu40+f+lOKAkXcf8v9pHvSE12SiIgM0dkbpvZMNzUtXVQ3dw8KzDUtXbScZcq7Pn6vPVvHwN7qvvVBS7+H7FQPLqeDxo5ee+7p2LR6+0+2cayxM/6auX4Pl8fC8YLYBVpKzzM9XTgS5XhzF6/X2ReYeb2u3Q69DR2DRsvzA15m5fuZne+nKCuF5s4QdW09nGrt5nRrD6dae+gNDx5ddxjID9jBOB6S0/vup5Af8JIb8JLmcWpObJnSFIYvwssnX+YT//cJFuUu4kc3/gify5fokkRE5AK094TssNzczZnuUP9JhbEZNHzu0bn6aHtPiAOn2uMBed/JNl6va4+PMPu9Li6fnm5fvbAoA5/bwet1/VdYPNrYQSjS/7u4KDMlftnx2fl+Zk/zMysvcN62DMuyONMV4lRrD6fbujnV2kNdLCSfbrOXp850D3tp8hS3k9yAh1y/lzy/HZDtdQ95sfVcv5e8gJc078gmorIsi85ghPaeUHzWlL4pBwcu23tCdPSEMcbgchhcTgdup8HpMLidjvg2e2lwOxy4nGbQdrfT3pbmdZEXqzMnzaNRcYlTGL5ITx57ki9t+BLXlVzHd677Di5HUs9EJyIiI9QbjnDodEc8IO89OXj2DWOgNDuV2fl+ZuUH4sF3Zr4f/wjD5sVq7wnFR5Ib2ntp7OiNLxs7gvH15q7gsFP09QXnvFhATvO64qG2b07tvvtn6TiJczkMAZ8rHrDDEYtw1CIcjcbWo/FtF8oYyE71xEO8Her7w33/Ni/ZqR71X09xCsOX4FcHfsU/b/ln3jH7HXz1iq/qYyQREbkokajFscYOesNRZub5R21keqyEI1Gau/rCcZDG9l4aOnppHBKcO4NhAn1XVey7omJsGRiwTE8ZvE/A5yLFPbL2DMuyiETtUByKRIlELUJDwnI4EqW9N0xDe++gkB9fj90f7kRNp8OQk2YH5+w0DxYW4YhFNPa+kahFxLKIRO1e7nA0StSi/7HY49FYjVHLojw3jdWX5bCqPJvKsmwyUhJzwuXFqmvrYeeJFnaeOMOu6jO4nQ5WlmezsjybJSWZE/7ndyiF4Uv0Hzv/g/t238dHKz7KZ5Z9JtHliIiIyEXoa904a2Bu76WlK4jDGBwOg9PY7Rp9N4cxOB3gcjhijxPfz+Xse9wO9wdPtbOr+gzBSBRj4PLp6awqz2HVZdmsKs8mM9WT4KPRrydkX2Rn54kz7KxuYdeJM5xs7QHA7TRcXphBbyjCa3XtWJY9s8uSkkxWlWezqjyHZTMySfVM7E/PFYYvkWVZ/OMr/8hDhx7inpX38N757010SSIiIjLB9YQi7Dxxhs3HmnjlaBM7T5yhN2yH47nTAvGR45Xl2eT4veNSk2VZHG/qYmd1/6jv/pNt8VaU4qwUlpZmsbQkkyWlmVw+PT0+CnymK8jWqha2HGti87Fm9ta2ErXsdpeK4gxWlmezujyH5WVZpPsm1ki4wvAoiEQj/OULf8mzJ57lm9d8kzdd9qZElyQiIiKTSG84wqvVrWw+aofJ7cdb4hepmZ3vj40a26PH+YFLO3E/GrUIRaN09UbYezI26nuihV3VZ+IzraR6nCwuzmRpaSZLS7NYUpJJXmDkobyjN8z24y1sPtrElmPNvFpzhlDEwmHg8sJ0VpbZX8vKsmyy0hI7Eq4wPEp6I738+bN/zs66nfzDVf/AupJ1+D3+RJclIiIik1AwHGVPbWts5LiZ7VXN8dk+LstNY25BINYfHSUU6Vv2rwf77oftPuZguP+xoScdGgOz8vzx4Lu0NJPZ+YFRvWR6dzDCzuoWNh9tZvOx/pFwsEfCV5Zn8+l1s8hPH/8ZuhSGR1F7sJ0PP/VhDjQfwGEcXJ59OSsKVlBZUMmy/GUKxyIiInJRwpEoe0+2xUeOjzd14nY68LgcuGNTztnL/nVP333XGx9zOx14XQ7mFaSzqCRj3FsXesMRdte0suVYM5uPNbPzeAsv3rMuIScTKgyPsmAkyK76XWyt28rW01vZ3bCbUDSkcCwiIiJyFpGoNaoj0RdCYXiMdYe72d2wm62n7XC8p3GPwrGIiIjIBKEwPM6GhuPdjbsJR8MKxyIiIiIJoDCcYGcLx16nl69f/XVuKbsl0SWKiIiITFnnCsMTe4bkKSLFlcKq6atYNX0V0B+O7911L1964Us0djXyvsvfl+AqRURERJKPI9EFJKO+cHzfjfdxfen1fHPrN/n2tm8Ttd54iUgRERERGTsKwwnkc/n4t2v/jXfPfTf377ufezbeQzASTHRZIiIiIklDbRIJ5nQ4+fKqL1OQVsD3dnyP5u5mvrv2uwQ8gUSXJiIiIjLlaWR4AjDG8OGKD/ONq7/B9rrtfOjJD1HfVZ/oskRERESmvBGFYWPMLcaY14wxh40x95xjv3caYyxjzLBn68m5vWXmW7j3hnupaa/hfY+/jyNnjiS6JBEREZEp7bxh2BjjBO4FbgUuB+4yxlw+zH4B4LPA5tEuMplcWXgl999yP6FoiPc/8X521O1IdEkiIiIiU9ZIRoZXAoctyzpqWVYQeBB42zD7fQ34JtAzivUlpfk58/nvW/+bHF8OH336ozx7/NlElyQiIiIyJY0kDBcB1QPu18S2xRljlgEllmU9Noq1JbXiQDEP3PoA83Lm8YXnv8CvDvwq0SWJiIiITDmXfAKdMcYBfAf4ixHs+zFjzDZjzLaGhoZLfespL8uXxU9u+gnXllzLP2/5Z763/Xsk6oqBIiIiIlPRSMJwLVAy4H5xbFufALAQeN4YUwWsBv443El0lmXdZ1lWpWVZlXl5eRdfdRJJcaXw3eu+yx1z7uC/9v4Xf/Pi3xCKhBJdloiIiMiUMJJ5hrcCs40x5dgh+N3Ae/oetCyrFcjtu2+MeR74S8uyto1uqcnL5XDxt6v/lmmp0/jPXf9JY3cj3137XdLcaYkuTURERGRSO+/IsGVZYeBTwFPAAeA3lmXtM8b8ozHmrWNdoNiMMfzZ4j/jH6/8R7ac3sLdT95NY3djossSERERmdRMonpQKysrrW3bNHh8MTbWbOQvXvgLsn3Z/OCGH1CeUZ7okkREREQmLGPMdsuyhr0Ohq5ANwldU3wNP735p3SHu3n/E+/nyaonCUXVRywiIiJyoRSGJ6mFuQv5xa2/INuXzRdf+CI3/vZGvrf9e1S3V5//ySIiIiICqE1i0otEI2w6uYnfHvotG2o2ELWiXDH9Ct41512sLV2L2+FOdIkiIiIiCXWuNgmF4SnkdOdpfn/49zz8+sOc7jxNji+H22fdzjtnv5OS9JLzv4CIiIjIFKQwnGT6RosfOvQQG2o2ELEirJ6+mjvm3MHakrW4nRotFhERkeShMJzE6jrreOTwI/zu9d9xqvMU2b5sbp91O++a/S6NFouIiEhSUBiWs44Wv2vOu1hXsk6jxSIiIjJlKQzLIMONFr+p/E1UTqtkcf5iclNyz/8iIiIiIpOEwrAMKxKN8NLJl/jtod/yYu2L8bmKSwIlLMlbwpJ8+zYzYyZOhzPB1YqIiIhcHIVhOa9gJMj+pv282vAqO+t3srN+J809zQD43X4W5y1mcf5iluQtYVHeItLcaQmuWERERGRkFIblglmWRU17DbsadrGrfhc7G3ZyuOUwFhYO42BO1hwW5y1maf5SluQvoTCtEGNMossWEREReQOFYRkV7cF29jTsYWfDTnbV72J3w266wl0A5Kfkszh/Maunr+bqoqsp9BcmuFoRERERm8KwjIlINMLrZ15nV/0udjXsYnvddk53ngagPKOcq4uu5urCq1lesByv05vgakVERCRZKQzLuLAsi2Ntx9hUu4lNtZvYenorwWgQn9NHZUElVxddzVWFVzEjfYZaKkRERGTcKAxLQnSHu9let51NtZt4sfZFqtqqACjyF8WD8crpK3UynoiIiIwphWGZEGraa+xgfPJFNp/aTHe4G5fDxbL8ZVxVdBVXFV7FnKw5GjUWERGRUaUwLBNOKBJiZ/1OXjz5IptqN3Go5RBgn4g3N3sufo+fgDtAmicNv9tv3zx+0txpw273ODwK0SIiIjIshWGZ8Oq76u1e45ObONF2gs5QJx2hDjqCHQSjwfM+3+VwDQrH2b5sriy8knUl6yhJLxmHr0BEREQmKoVhmdSCkaAdjoMddkCOheSOUMeg0Nz3WGewk5qOGg6fOQzA7KzZrCtZx7rSdczPnq8RZBERkSSjMCxJqbq9mvUn1rO+ej076ncQtaIUpBWwtmQt60rXsXzactwOd6LLFBERkTGmMCxJr6WnhRdqXuC5E8/x8smX6Yn0EPAEuLb4WtaWrOXqoqtJdacmukwREREZAwrDIgN0h7t5+eTLPHfiOV6oeYEzvWfwODysLlzNupJ1XFtyLbkpuYkuc1SFoiEONB0gy5dFSUA91CIiklwUhkXOIhwNs7N+J8+deI711eup7ajFYFiSv4S1JWupyK2gOFBMfmo+DuNIdLkjFoqG2N+0n62nt7L19FZ21u+kO9yNwXDDjBu4e8HdVORVJLpMERGRcaEwLDIClmVxqOUQz1U/x/oT6znQfCD+mNvhpshfRFGgiGJ/MSWBEor9xfH7fo8/gZXbof5A0wG2nN7C1rqt7KzbSVe4C4BZmbNYUbCC5dOW81rzazz42oO0B9tZUbCCuxfczdVFV+ukQhERmdIUhkUuwunO0xxtPUptRy017TX2rcNetgXbBu2b6c2k2F9McSB2i60X+YuYljZt1E/UC0fDHGw+GB/53VG/g85QJwAzM2ZSWVDJyoKVLJ+2nJyUnEHP7Qx18tChh3hg/wPUd9UzJ2sOdy+8m5vLbtYJhSIiMiUpDIuMstbe1v6QHAvIfeunOk4RtsKD9k91pRLwBAh4AqR70uPrA+8P3d63ze+2R50Pthxk2+ltbDm9hR11O+gIdQBwWcZlrChYQWVBJZXTKkfc7xyKhHjs2GPcv/d+jrQeoTCtkA8s+ABvn/V2nUwoIiJTisKwyDgKR8PUddVR015DbUctdZ11tIfaaQ8OvrUF22gLttER7MDi3P8O3Q43oWgIgLL0MlYUrGBlwUoqC0Yefs8makXZULOBn+39GTvqd5DhzeCueXdx17y7yPZlX9Jri4iITAQKwyITWNSK0hnqHBSShwbn7nA387LnsaJgBXmpeWNWy676XfzX3v/i+ern8Tl93D7rdj644IMUB4ov6vWiVpT6rnqOtR6jqq2KqtYqjrcd53jbcXojvZdcb4Y3g8pplaycvpLKaZVk+bIu+TUnK8uyOHLmCFvrtlI5rZLZWbMTXZKIyIShMCwiF+TomaP8bN/PePToo0StKDfPuJm7F97N/Jz5w+7fGeqkqrWKY23H4oG3qs1edoe74/ululKZkT6DsvSyUWnFON15mh31O+LvMTtrNisLVrJimt02kuHNuOT3GI5lWZzuPM3B5oO81vIah1oOEfAEWFWwipXTV47b1HwDZ0N5vvp5ajpqAHAYB++c/U4+seQTU26aQBGRi6EwLCIXpa6zjl8c+AW/PfRbOkOdXFl4JW+Z+RaaupvigbeqtYqG7ob4cxzGQWFaIWUZZZSll1GeUU5Zehkz0meQn5o/6jNXhKIh9jXuGzSNXE+kB4NhbvZce+S4YCXLC5aT7km/4NcPRoIcOXOE11pe47Xm1+LLvpMoDYaSQAktvS20B9sBewaP1dNXs2r6KiqnVY7qbCMdwQ42ndzE+ur1bKzZSFuwDY/Dw6rpq1hbupZl+cv47aHf8uuDv8br8vKRio/w/svfj9fpHbUaREQmG4VhEbkkbcE2fvPab/jF/l/Q1NME2C0KZel24C3LKKM8vZyyjDJKAiV4nJ6E1RqKhNjTuCcejnc17KI30ovBMC97HisLVrJy+kqW5i8l4AkMem5LT0t/6G1+jYMtBzl25lj8hMgUVwqzM2czN3su87LnMSdrDnOy5pDqTiUSjXCg+QCvnHqFzac2s7N+J72RXpzGyYLcBayevprV01ezOG/xBR+f052neb76edZXr2fL6S2Eo2EyvZmsKV7DupJ1XFF4xRtG2o+1HuM727/D89XPU5hWyOeXf56by27WNHoikpQUhkVkVPRGejl85jBFaUVk+jITXc6IBCNBdjfstsNx3VZerX+VYDSIwzi4PPtyFuQu4FTnKQ42H6S+qz7+vPyUfOZmz+2/Zc2lNFCK0+Ec0fv2Rnp5tf5VOxyf3sy+xn1ErAg+p4+l+UtZNX0Vq6evZl72vDe8pmVZHGw+yPrq9Txf/Xx8zusZ6TNYW7KWtSVrWZy3eES1bD61mW9t/RavtbzG4rzFfGnFl1iUt2jkB/AShCIh3E5N1yciiacwLCIS0xPuscNx3Va2nNrCweaDFPoLmZc9Lz7aOzd77qjPpNEebGd73XY2n9rMK6de4fCZwwCke9JZUbCCVdNXUZhWyMbajTxf/Tx1XXWDroZ4Xcl1lGeUX9R7R6IR/njkj/z7zn+nsbuRW8tv5XPLPkehv3AUv8LBIX599Xpea7YD+C3lt3DjjBvJT80f1fcTERkphWERkQmmsbuRzac2x28nO08CdivGFdOvYG3pWtYUrxnVUN4V6uKne3/K/fvuB+ADl3+AD1d8mDR32kW/ZigaYnvd9vhJfKc6T8VDfEVuBa+ceoVDLYcwGJZNW8YtZXYwHnoxGJkcItEIR1uPsq9pH/sa97GvaR+doU7Wla7jlrJbmJM1R604MiEpDIuITGCWZVHTXsPJzpMszluMz+Ub0/c73Xma7+/4Po8efZRsXzafXvpp3j7r7SNuAekIdvDiyRdZf2I9G2s30h5sx+v0csX0K1hXuo41xWsGhd2jZ47yVNVTPFn1JEdbj+IwDlYUrOCWslu4ofSGSdNyk2yiVpTjbccHBd+DzQfjs7ekulK5POdynA4n205vI2JFKM8o59ayW7m5/GYuy7gswV+BSD+FYREReYM9DXv41rZvsbN+J7OzZvPFyi9yReEVw+5b31XP89XP89yJ59hyeguhaIgsbxZritewtnQtV0x/40l8Q1mWxetnXufJY0/yVNVTnGg/gdM4WT19NTeX3cz1M66/qBk/RltbsI0TbSc43nacE20nONF+ghNtJ6jtqCXDm0Ghv5AifxGF/kJ7Pc1ez/ZlT9pRUcuyqOmoYV/TPvY37mdv0172N+2PX+bd5/QxL3seC3IXsCBnAQtyF1CWXobDOABo7mnm2ePP8sSxJ9hetx0Li7lZc7ml/BZuKbvloucqP5+uUBf7mvbxasOr7G7YTVN3Exh7lheDwZizLO2dMBgcxjHofqorletKruP60usTejXOmvYaTnWeYkHOAl0VdBQoDIuIyLAsy+KZ48/wne3fobajljXFa/iL5X9BeUY5h88ctvt/T6xnb9NeAEoDpfZJfKVrWZK3ZMSjycO978HmgzxZZQfj2o5aXA4XVxVexc1lN7O2ZO2oTkk3VHuwPR50+0Lv8XZ7eab3THw/g6EgrYDSQClFgSLag+3xUfzW3tZBr5niSqEwrbA/JMcCc98yy5s1YcJyMBLklVOvsKt+F3sb97KvaV98ukC3w83crLmDgu9lGZfhcrhG9Nr1XfU8XfU0T1Q9we6G3QBU5FZwS9kt3FR2EwVpBRdVs2VZVLVVsbtht31r3M2hlkNErShgX52z0F+IZVn0/c/+v/2/qBWlL/NYWP37DVk2dDdQ31VPiiuF60qu482XvZkrCq/A7Rj7k0FrO2p5uuppnqp6in1N+wB7usq5WXNZkr+EpflLWZK3hOn+6WNey2g73Xmal0++zO2zbk/IvwOFYREROafeSC+/OvAr7tt9H93hbqalTov3MS/KXcTaUnsWi8syLhv1X2SWZbG3cW88GNd11eFxeLim+BpuLrM/bo9YESLRCBErQjgajt8PW+H+7QPWhz7WEeyIj/CeaD9Bc0/zoBqmpU5jRvoMStNLKQ2UUppeyozADIoDxWdtW+kIdnCy8yQnO05S21FLbUctJzv67/eFyz4prhSK/EXMzpzNNcXXcHXR1eN61cSecA+bTm7imePP8Hz183SGOnEZF7OyZsVD74KcBczOnD1qs4DUdtTaLTLHnozPirIsfxm3lt963t7xtmAbexv28mrjq/EA3HdM/W4/FbkVLM5fzKLcRVTkVoxau03UirKrfhePHn2Up6qeoi3YRpY3i5vLbua2y25jcd7iUf030BeAn656Ov5H58KchdxUdhMzM2eyu2E3u+p3sbtxd7xFZVrqNDsYxwLynKw5I/5jZbxYlsWhlkOsr17Pcyeei3////C2P3BZ5vi30CgMi4jIiDT3NHPf7vuo7ajlmqJruK7kunGdBSJqRdndsJsnq57k6aqnB13Q5VLlp+ZTGiiNh94ZAXtZHCgmxZUyau/Tpz3YPigc9912N+ymqacJg6Eir4I1RWtYU7yGednzRv0Pja5QFy/Wvsgzx5/hhZoX6A53k+HN4PrS67lxxo1UTqsc8x71PlWtVTxZ9SRPHnuSI61HcBgHKwtWckvZLawtXUtjd2P/qG/Dbo62HsXCwmCYmTmTxXmLWZS3iMV5iynPKI+3aIylUCTEi7Uv8ujRR3mh5gV6I70U+4u57bLbuO2y2y56hpeTHSfjI8B9AXhBzgJuLruZG2fcOGxbSTga5lDLIXbW72RX/S521u+krqsOsP/QWpS7KB6OF+UtesM86uNh4FUx11evp7ajFoNhUd6i+CdKieolVxgWEZFJJxKN8GrDqzT3NOM0TpwOJy7jwulw4jROXA5XfPtw9wc+x+fyjVvoO5+oFeVA0wE21GxgQ82GeBjKT8nnmuJruKb4mhH1YJ9NZ6iTDTUbeOb4M2ys2UhPpIdsX3Z/AC6oHJeP/M/l9ZbXeeLYE/He8YEyvZksylvEotxFLMqzR33HsmVmpDqCHTx74lkeO/oYm09txsJiQc4CbrvsNm4tv/W8lz4/2XGSZ44/w1NVT7GncQ8Al+dcHg/AJYGSC67pVMcpOxw37GJX/S5ea3mNqBXFYJiVNYulefbocXlGOSWBkjG5RH1XqIuXTr7E+ur1vFDzAq29rXgcHlYXro5PCzkRLguvMCwiIjJBNXY38mLti2yo2cDLJ1+mI9SB2+Gmclola4rtUePS9NJzvkZ7sJ3nq5/nmePPsKl2E8FokNyUXG4ovYGbym5iWf6yi+7vHkuWZbG/eT+bajcxPW06i/IWURoonTC91WdT31XPE8ee4LGjj3Gg+QAO42BVwSrePPPNXF96fXy6wlMdp3j6uN0CsbvR7p++POdybppxEzeV3XRRAfhcOkOd8baKnfU72d24O34SJEDAE6AkUDLsLT81f8Sj7Y3djbxQ/QLrq9fzyqlX6I30ku5J59ria1lbuparCq+acCf9KQyLiIhMAqFIiJ31O+1R49oNHGs9Btgnh11TfA1ritewPH85bqeb1t5WnjvxHM+eeJaXTr5EOBomPzWfm2bcxI0zbmRJ/pJxaSVIdkfPHOXRo4/y+LHHqe2oxef0cU3xNdR11cVPIJyfPZ+by27mphk3UZI+ugH4XPrmhT7RdoLq9mqq26up6aihur2akx0niViR+L4eh4eiQNEbQnJxoJhifzEnO07G+39fbXgVC4vCtELWla5jbclalk5bmvBPHM5FYVhERGQSqm6rZkOt3U6x9fRWQtEQqa5UZmXOYn/TfsJWmMK0Qm6ccSM3lt1IRW6FAnCCWJbFqw2v8ujRR3n2+LP2HyZlN3HzjJvHNQCPVDga5lTnKTsgt9fEw3Lfre9kPbBnVbGw8+L87PmsLV3LupJ1k+oiKwrDIiIik1xXqIvNpzazoXYDrzW/xoqCFdw04yYuz7l80gQSmRwsy6K5p7l/NLm9hgxvBmtL1k7Kad1AYVhEREREkti5wrA+SxERERGRpKUwLCIiIiJJS2FYRERERJKWwrCIiIiIJC2FYRERERFJWgrDIiIiIpK0FIZFREREJGkpDIuIiIhI0lIYFhEREZGkpTAsIiIiIklLYVhEREREkpbCsIiIiIgkLYVhEREREUlaCsMiIiIikrQUhkVEREQkaSkMi4iIiEjSUhgWERERkaSlMCwiIiIiSUthWERERESSlsKwiIiIiCQthWERERERSVoKwyIiIiKStBSGRURERCRpGcuyEvPGxjQAxxPy5pALNCbovac6Hduxo2M7dnRsx4aO69jRsR07OrZjJ5HHdoZlWXnDPZCwMJxIxphtlmVVJrqOqUjHduzo2I4dHduxoeM6dnRsx46O7diZqMdWbRIiIiIikrQUhkVEREQkaSVrGL4v0QVMYTq2Y0fHduzo2I4NHdexo2M7dnRsx86EPLZJ2TMsIiIiIgLJOzIsIiIiIpJcYdgYc4sx5jVjzGFjzD2JrmcqMcZUGWP2GGN2GWO2JbqeycwY81NjTL0xZu+AbdnGmGeMMa/HllmJrHGyOsux/aoxpjb2s7vLGPOmRNY4WRljSowx640x+40x+4wxn41t18/uJTrHsdXP7iUyxviMMVuMMa/Gju0/xLaXG2M2x/LCr40xnkTXOtmc49jeb4w5NuDndkmCS02eNgljjBM4BNwI1ABbgbssy9qf0MKmCGNMFVBpWZbmZrxExpg1QAfwgGVZC2Pb/hVotizrX2J/yGVZlvVXiaxzMjrLsf0q0GFZ1r8lsrbJzhgzHZhuWdYOY0wA2A7cDnwI/exeknMc2z9BP7uXxBhjgDTLsjqMMW7gReCzwBeA31mW9aAx5ofAq5Zl/SCRtU425zi2HwcetSzroYQWOEAyjQyvBA5blnXUsqwg8CDwtgTXJPIGlmVtAJqHbH4b8PPY+s+xfxHKBTrLsZVRYFnWKcuydsTW24EDQBH62b1k5zi2coksW0fsrjt2s4B1QF9Y08/tRTjHsZ1wkikMFwHVA+7XoP+YjCYLeNoYs90Y87FEFzMFTbMs61Rs/TQwLZHFTEGfMsbsjrVR6GP8S2SMKQOWApvRz+6oGnJsQT+7l8wY4zTG7ALqgWeAI8AZy7LCsV2UFy7S0GNrWVbfz+0/xX5uv2uM8SauQlsyhWEZW1dblrUMuBX4ZOzjaBkDlt3bNCH/up6kfgDMBJYAp4BvJ7SaSc4Y4wceBj5nWVbbwMf0s3tphjm2+tkdBZZlRSzLWgIUY3+KPC+xFU0dQ4+tMWYh8NfYx3gFkA0kvG0qmcJwLVAy4H5xbJuMAsuyamPLeuAR7P+gyOipi/UN9vUP1ie4ninDsqy62H+wo8CP0c/uRYv1BT4M/NKyrN/FNutndxQMd2z1szu6LMs6A6wHrgAyjTGu2EPKC5dowLG9Jdb2Y1mW1Qv8jAnwc5tMYXgrMDt2hqgHeDfwxwTXNCUYY9JiJ3VgjEkDbgL2nvtZcoH+CHwwtv5B4A8JrGVK6QtqMW9HP7sXJXayzH8BByzL+s6Ah/Sze4nOdmz1s3vpjDF5xpjM2HoK9kn2B7CD27tiu+nn9iKc5dgeHPDHscHuxU74z23SzCYBEJt25nuAE/ipZVn/lNiKpgZjzGXYo8EALuBXOrYXzxjzP8B1QC5QB/w98HvgN0ApcBz4E8uydCLYBTrLsb0O+2NmC6gC/mxAj6uMkDHmamAjsAeIxjZ/Gbu3VT+7l+Acx/Yu9LN7SYwxi7BPkHNiDxD+xrKsf4z9XnsQ+2P8ncD7YiOZMkLnOLbPAXmAAXYBHx9wol1CJFUYFhEREREZKJnaJEREREREBlEYFhEREZGkpTAsIiIiIklLYVhEREREkpbCsIiIiIgkLYVhEREREUlaCsMiIiIikrQUhkVEREQkaf1/4+oveYydLu8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame( history.history ).plot( figsize=(12,10) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on training data (without dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2858 - accuracy: 0.8921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28584596514701843, 0.892090916633606]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate( X_train_scaled, y_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3505 - accuracy: 0.8739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3504771888256073, 0.8738999962806702]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate( X_test_scaled, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.5051089e-05, 2.6564681e-05, 8.8214019e-06, ..., 1.6759995e-01,\n",
       "        2.6316513e-04, 7.7944928e-01],\n",
       "       [9.5630399e-05, 1.4343266e-07, 9.9409938e-01, ..., 2.6819896e-12,\n",
       "        5.8884268e-07, 3.0143663e-12],\n",
       "       [7.3646025e-15, 1.0000000e+00, 1.7784303e-19, ..., 2.7937077e-24,\n",
       "        5.7066699e-20, 5.3353843e-25],\n",
       "       ...,\n",
       "       [1.0110600e-03, 9.9294248e-06, 3.2802814e-04, ..., 9.4580400e-06,\n",
       "        9.9724209e-01, 2.0273756e-06],\n",
       "       [2.7853091e-11, 1.0000000e+00, 6.2220431e-15, ..., 1.1188477e-18,\n",
       "        2.9959102e-15, 1.1512458e-18],\n",
       "       [2.9817170e-06, 8.4498339e-07, 3.8743924e-06, ..., 3.2824850e-01,\n",
       "        4.9352663e-04, 5.2687887e-04]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = model.predict( X_test_scaled )\n",
    "print ( y_proba.shape )\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_entry_test = 10\n",
    "class_names[ y_proba[ i_entry_test ].argmax() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow( X_test[i_entry_test], cmap=\"binary\" )\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_learning_rate( lr_init=1e-4, lr_end=5e-2, steps=20, epochs=30, model_build_fn=build_model, *build_fn_args, **build_fn_kwargs ):\n",
    "    results_ = {}\n",
    "    results_['learning_rate'] = []\n",
    "    results_['loss'] = []\n",
    "    results_['accuracy'] = []\n",
    "    results_['val_loss'] = []\n",
    "    results_['val_accuracy'] = []\n",
    "    c_ = (lr_end/lr_init) ** (1/steps)\n",
    "    lr_ = lr_init\n",
    "    for i_it in range( steps + 1 ):\n",
    "        results_['learning_rate'].append( lr_ )\n",
    "        model_ = model_build_fn( *build_fn_args, **build_fn_kwargs, learning_rate=lr_ )\n",
    "        callbacks_ = callbacks(patience=10)\n",
    "        history_ = model_.fit( X_train_scaled, y_train, epochs=epochs, validation_data=(X_valid_scaled, y_valid), callbacks=callbacks_ )\n",
    "        results_['loss'].append( history_.history['loss'] )\n",
    "        results_['accuracy'].append( history_.history['accuracy'] )\n",
    "        results_['val_loss'].append( history_.history['val_loss'] )\n",
    "        results_['val_accuracy'].append( history_.history['val_accuracy'] )\n",
    "        # Update lerning rate\n",
    "        lr_ = lr_ * c_\n",
    "        \n",
    "    return results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.0001\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 2.4960 - accuracy: 0.4331 - val_loss: 0.6832 - val_accuracy: 0.7700\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.3325 - accuracy: 0.6056 - val_loss: 0.5850 - val_accuracy: 0.7918\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.0202 - accuracy: 0.6651 - val_loss: 0.5209 - val_accuracy: 0.8114\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.8694 - accuracy: 0.7015 - val_loss: 0.4856 - val_accuracy: 0.8194\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7758 - accuracy: 0.7273 - val_loss: 0.4564 - val_accuracy: 0.8322\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7102 - accuracy: 0.7478 - val_loss: 0.4485 - val_accuracy: 0.8308\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.6703 - accuracy: 0.7611 - val_loss: 0.4319 - val_accuracy: 0.8360\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.6339 - accuracy: 0.7731 - val_loss: 0.4191 - val_accuracy: 0.8466\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.6108 - accuracy: 0.7809 - val_loss: 0.4135 - val_accuracy: 0.8456\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5966 - accuracy: 0.7875 - val_loss: 0.4101 - val_accuracy: 0.8464\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5768 - accuracy: 0.7932 - val_loss: 0.3993 - val_accuracy: 0.8520\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5633 - accuracy: 0.7995 - val_loss: 0.4006 - val_accuracy: 0.8478\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5532 - accuracy: 0.8009 - val_loss: 0.3922 - val_accuracy: 0.8554\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5380 - accuracy: 0.8066 - val_loss: 0.3873 - val_accuracy: 0.8562\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5334 - accuracy: 0.8089 - val_loss: 0.3860 - val_accuracy: 0.8558\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5288 - accuracy: 0.8085 - val_loss: 0.3798 - val_accuracy: 0.8598\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5201 - accuracy: 0.8121 - val_loss: 0.3815 - val_accuracy: 0.8582\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5120 - accuracy: 0.8167 - val_loss: 0.3784 - val_accuracy: 0.8602\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5076 - accuracy: 0.8172 - val_loss: 0.3758 - val_accuracy: 0.8630\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4992 - accuracy: 0.8208 - val_loss: 0.3712 - val_accuracy: 0.8652\n",
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.00016986464646342474\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 2.0921 - accuracy: 0.5030 - val_loss: 0.6005 - val_accuracy: 0.7988\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 1.0780 - accuracy: 0.6575 - val_loss: 0.5041 - val_accuracy: 0.8240\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.8429 - accuracy: 0.7090 - val_loss: 0.4703 - val_accuracy: 0.8350\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.7247 - accuracy: 0.7438 - val_loss: 0.4391 - val_accuracy: 0.8460\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6630 - accuracy: 0.7614 - val_loss: 0.4271 - val_accuracy: 0.8462\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.6215 - accuracy: 0.7787 - val_loss: 0.4215 - val_accuracy: 0.8462\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5870 - accuracy: 0.7916 - val_loss: 0.4037 - val_accuracy: 0.8554\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5680 - accuracy: 0.7962 - val_loss: 0.3953 - val_accuracy: 0.8602\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5460 - accuracy: 0.8050 - val_loss: 0.3856 - val_accuracy: 0.8610\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5364 - accuracy: 0.8092 - val_loss: 0.3858 - val_accuracy: 0.8602\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5236 - accuracy: 0.8122 - val_loss: 0.3757 - val_accuracy: 0.8610\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5156 - accuracy: 0.8137 - val_loss: 0.3760 - val_accuracy: 0.8632\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5076 - accuracy: 0.8171 - val_loss: 0.3686 - val_accuracy: 0.8684\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5039 - accuracy: 0.8176 - val_loss: 0.3670 - val_accuracy: 0.8668\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4927 - accuracy: 0.8231 - val_loss: 0.3649 - val_accuracy: 0.8658\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4890 - accuracy: 0.8219 - val_loss: 0.3598 - val_accuracy: 0.8700\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4851 - accuracy: 0.8255 - val_loss: 0.3592 - val_accuracy: 0.8674\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4759 - accuracy: 0.8283 - val_loss: 0.3545 - val_accuracy: 0.8688\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4745 - accuracy: 0.8291 - val_loss: 0.3514 - val_accuracy: 0.8722\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4697 - accuracy: 0.8294 - val_loss: 0.3503 - val_accuracy: 0.8720\n",
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.00028853998118144277\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 1.6975 - accuracy: 0.5535 - val_loss: 0.5351 - val_accuracy: 0.8064\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.8728 - accuracy: 0.6968 - val_loss: 0.4650 - val_accuracy: 0.8280\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.6981 - accuracy: 0.7510 - val_loss: 0.4346 - val_accuracy: 0.8388\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.6264 - accuracy: 0.7753 - val_loss: 0.4155 - val_accuracy: 0.8508\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5831 - accuracy: 0.7906 - val_loss: 0.3991 - val_accuracy: 0.8518\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5565 - accuracy: 0.8008 - val_loss: 0.3937 - val_accuracy: 0.8544\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5343 - accuracy: 0.8087 - val_loss: 0.3796 - val_accuracy: 0.8598\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5203 - accuracy: 0.8118 - val_loss: 0.3701 - val_accuracy: 0.8656\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5075 - accuracy: 0.8156 - val_loss: 0.3620 - val_accuracy: 0.8652\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5004 - accuracy: 0.8201 - val_loss: 0.3659 - val_accuracy: 0.8644\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4859 - accuracy: 0.8245 - val_loss: 0.3563 - val_accuracy: 0.8706\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4856 - accuracy: 0.8254 - val_loss: 0.3608 - val_accuracy: 0.8622\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4778 - accuracy: 0.8274 - val_loss: 0.3512 - val_accuracy: 0.8766\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4718 - accuracy: 0.8302 - val_loss: 0.3479 - val_accuracy: 0.8694\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4671 - accuracy: 0.8296 - val_loss: 0.3444 - val_accuracy: 0.8718\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4620 - accuracy: 0.8313 - val_loss: 0.3439 - val_accuracy: 0.8742\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4537 - accuracy: 0.8350 - val_loss: 0.3444 - val_accuracy: 0.8720\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4524 - accuracy: 0.8363 - val_loss: 0.3366 - val_accuracy: 0.8764\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4502 - accuracy: 0.8365 - val_loss: 0.3416 - val_accuracy: 0.8732\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4430 - accuracy: 0.8415 - val_loss: 0.3318 - val_accuracy: 0.8758\n",
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.00049012741893949\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 1.3990 - accuracy: 0.6034 - val_loss: 0.4918 - val_accuracy: 0.8156\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.7226 - accuracy: 0.7410 - val_loss: 0.4442 - val_accuracy: 0.8320\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6208 - accuracy: 0.7783 - val_loss: 0.4293 - val_accuracy: 0.8384\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5722 - accuracy: 0.7957 - val_loss: 0.3967 - val_accuracy: 0.8490\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5402 - accuracy: 0.8057 - val_loss: 0.3853 - val_accuracy: 0.8588\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5296 - accuracy: 0.8114 - val_loss: 0.3804 - val_accuracy: 0.8588\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5075 - accuracy: 0.8192 - val_loss: 0.3708 - val_accuracy: 0.8606\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4993 - accuracy: 0.8197 - val_loss: 0.3667 - val_accuracy: 0.8646\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4879 - accuracy: 0.8245 - val_loss: 0.3517 - val_accuracy: 0.8674\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4824 - accuracy: 0.8261 - val_loss: 0.3553 - val_accuracy: 0.8658\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4744 - accuracy: 0.8298 - val_loss: 0.3511 - val_accuracy: 0.8684\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4703 - accuracy: 0.8297 - val_loss: 0.3532 - val_accuracy: 0.8650\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4616 - accuracy: 0.8330 - val_loss: 0.3405 - val_accuracy: 0.8732\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4540 - accuracy: 0.8359 - val_loss: 0.3520 - val_accuracy: 0.8638\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4514 - accuracy: 0.8378 - val_loss: 0.3383 - val_accuracy: 0.8720\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4493 - accuracy: 0.8366 - val_loss: 0.3367 - val_accuracy: 0.8696\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4453 - accuracy: 0.8393 - val_loss: 0.3390 - val_accuracy: 0.8688\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4442 - accuracy: 0.8403 - val_loss: 0.3294 - val_accuracy: 0.8750\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4412 - accuracy: 0.8406 - val_loss: 0.3395 - val_accuracy: 0.8716\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4330 - accuracy: 0.8444 - val_loss: 0.3259 - val_accuracy: 0.8794\n",
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.0008325532074018733\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.1859 - accuracy: 0.6474 - val_loss: 0.4703 - val_accuracy: 0.8288\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6520 - accuracy: 0.7661 - val_loss: 0.4240 - val_accuracy: 0.8436\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5908 - accuracy: 0.7891 - val_loss: 0.4082 - val_accuracy: 0.8504\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5596 - accuracy: 0.8001 - val_loss: 0.3856 - val_accuracy: 0.8562\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5362 - accuracy: 0.8057 - val_loss: 0.3803 - val_accuracy: 0.8610\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5255 - accuracy: 0.8145 - val_loss: 0.3695 - val_accuracy: 0.8608\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5116 - accuracy: 0.8184 - val_loss: 0.3612 - val_accuracy: 0.8658\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5053 - accuracy: 0.8192 - val_loss: 0.3625 - val_accuracy: 0.8704\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4942 - accuracy: 0.8245 - val_loss: 0.3499 - val_accuracy: 0.8722\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4862 - accuracy: 0.8274 - val_loss: 0.3508 - val_accuracy: 0.8722\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4810 - accuracy: 0.8299 - val_loss: 0.3474 - val_accuracy: 0.8728\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4763 - accuracy: 0.8306 - val_loss: 0.3482 - val_accuracy: 0.8692\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4708 - accuracy: 0.8315 - val_loss: 0.3415 - val_accuracy: 0.8762\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4670 - accuracy: 0.8333 - val_loss: 0.3510 - val_accuracy: 0.8674\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4636 - accuracy: 0.8341 - val_loss: 0.3341 - val_accuracy: 0.8724\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4618 - accuracy: 0.8363 - val_loss: 0.3312 - val_accuracy: 0.8728\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4543 - accuracy: 0.8387 - val_loss: 0.3411 - val_accuracy: 0.8696\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4515 - accuracy: 0.8397 - val_loss: 0.3314 - val_accuracy: 0.8768\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4537 - accuracy: 0.8397 - val_loss: 0.3410 - val_accuracy: 0.8734\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4522 - accuracy: 0.8402 - val_loss: 0.3291 - val_accuracy: 0.8770\n",
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.0014142135623730955\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 1.0430 - accuracy: 0.6779 - val_loss: 0.4525 - val_accuracy: 0.8332\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6318 - accuracy: 0.7759 - val_loss: 0.4173 - val_accuracy: 0.8454\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5889 - accuracy: 0.7915 - val_loss: 0.4245 - val_accuracy: 0.8498\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5676 - accuracy: 0.8005 - val_loss: 0.3905 - val_accuracy: 0.8542\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5477 - accuracy: 0.8068 - val_loss: 0.3947 - val_accuracy: 0.8544\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5435 - accuracy: 0.8098 - val_loss: 0.3795 - val_accuracy: 0.8626\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5347 - accuracy: 0.8136 - val_loss: 0.3659 - val_accuracy: 0.8676\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5304 - accuracy: 0.8152 - val_loss: 0.3615 - val_accuracy: 0.8694\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5203 - accuracy: 0.8186 - val_loss: 0.3598 - val_accuracy: 0.8696\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5194 - accuracy: 0.8187 - val_loss: 0.3669 - val_accuracy: 0.8664\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5154 - accuracy: 0.8189 - val_loss: 0.3593 - val_accuracy: 0.8690\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5139 - accuracy: 0.8208 - val_loss: 0.3621 - val_accuracy: 0.8606\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5156 - accuracy: 0.8212 - val_loss: 0.3524 - val_accuracy: 0.8692\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5072 - accuracy: 0.8242 - val_loss: 0.3553 - val_accuracy: 0.8634\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5062 - accuracy: 0.8264 - val_loss: 0.3624 - val_accuracy: 0.8652\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5041 - accuracy: 0.8240 - val_loss: 0.3600 - val_accuracy: 0.8700\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5000 - accuracy: 0.8263 - val_loss: 0.3601 - val_accuracy: 0.8644\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5002 - accuracy: 0.8271 - val_loss: 0.3482 - val_accuracy: 0.8736\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4992 - accuracy: 0.8281 - val_loss: 0.3449 - val_accuracy: 0.8706\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4973 - accuracy: 0.8264 - val_loss: 0.3469 - val_accuracy: 0.8708\n",
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.0024022488679628635\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.9345 - accuracy: 0.7023 - val_loss: 0.4653 - val_accuracy: 0.8298\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6584 - accuracy: 0.7695 - val_loss: 0.4262 - val_accuracy: 0.8440\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6342 - accuracy: 0.7812 - val_loss: 0.4271 - val_accuracy: 0.8494\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6196 - accuracy: 0.7880 - val_loss: 0.4183 - val_accuracy: 0.8478\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6194 - accuracy: 0.7879 - val_loss: 0.4315 - val_accuracy: 0.8450\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6137 - accuracy: 0.7922 - val_loss: 0.4047 - val_accuracy: 0.8552\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6095 - accuracy: 0.7924 - val_loss: 0.4197 - val_accuracy: 0.8540\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6098 - accuracy: 0.7931 - val_loss: 0.3910 - val_accuracy: 0.8608\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6143 - accuracy: 0.7936 - val_loss: 0.3848 - val_accuracy: 0.8604\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6089 - accuracy: 0.7967 - val_loss: 0.4088 - val_accuracy: 0.8524\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6055 - accuracy: 0.7963 - val_loss: 0.3909 - val_accuracy: 0.8516\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6071 - accuracy: 0.7952 - val_loss: 0.4017 - val_accuracy: 0.8494\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6158 - accuracy: 0.7961 - val_loss: 0.3930 - val_accuracy: 0.8624\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6055 - accuracy: 0.7937 - val_loss: 0.4100 - val_accuracy: 0.8590\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6189 - accuracy: 0.7949 - val_loss: 0.4111 - val_accuracy: 0.8566\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6062 - accuracy: 0.7989 - val_loss: 0.4058 - val_accuracy: 0.8538\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6158 - accuracy: 0.7964 - val_loss: 0.3944 - val_accuracy: 0.8546\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6128 - accuracy: 0.7959 - val_loss: 0.3907 - val_accuracy: 0.8670\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6264 - accuracy: 0.7932 - val_loss: 0.3863 - val_accuracy: 0.8602\n",
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.004080571546736741\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.9505 - accuracy: 0.6967 - val_loss: 0.4811 - val_accuracy: 0.8312\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7538 - accuracy: 0.7479 - val_loss: 0.4871 - val_accuracy: 0.8284\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7796 - accuracy: 0.7414 - val_loss: 0.5363 - val_accuracy: 0.8248\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7947 - accuracy: 0.7391 - val_loss: 0.4950 - val_accuracy: 0.8320\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.7948 - accuracy: 0.7385 - val_loss: 0.4885 - val_accuracy: 0.8214\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.8143 - accuracy: 0.7319 - val_loss: 0.4597 - val_accuracy: 0.8336\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.8277 - accuracy: 0.7312 - val_loss: 0.4968 - val_accuracy: 0.8220\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.8095 - accuracy: 0.7319 - val_loss: 0.5100 - val_accuracy: 0.8394\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.8279 - accuracy: 0.7281 - val_loss: 0.5066 - val_accuracy: 0.8224\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.8423 - accuracy: 0.7259 - val_loss: 0.5214 - val_accuracy: 0.8194\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.8947 - accuracy: 0.7163 - val_loss: 0.5255 - val_accuracy: 0.8170\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.8814 - accuracy: 0.7139 - val_loss: 0.4905 - val_accuracy: 0.8226\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.9192 - accuracy: 0.7063 - val_loss: 0.5329 - val_accuracy: 0.8070\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.9668 - accuracy: 0.7021 - val_loss: 0.5953 - val_accuracy: 0.8214\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.9910 - accuracy: 0.6939 - val_loss: 0.5157 - val_accuracy: 0.8350\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.8851 - accuracy: 0.7103 - val_loss: 0.4755 - val_accuracy: 0.8274\n",
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.006931448431551467\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.1034 - accuracy: 0.6491 - val_loss: 0.6367 - val_accuracy: 0.7782\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.1140 - accuracy: 0.6347 - val_loss: 0.6971 - val_accuracy: 0.7718\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.2093 - accuracy: 0.5988 - val_loss: 0.7160 - val_accuracy: 0.7352\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.3062 - accuracy: 0.5651 - val_loss: 0.7716 - val_accuracy: 0.6590\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.2867 - accuracy: 0.5558 - val_loss: 0.8200 - val_accuracy: 0.6662\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.4654 - accuracy: 0.4943 - val_loss: 0.8384 - val_accuracy: 0.6830\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.6636 - accuracy: 0.4618 - val_loss: 1.0952 - val_accuracy: 0.5848\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.5724 - accuracy: 0.4388 - val_loss: 1.0222 - val_accuracy: 0.5448\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 2.0115 - accuracy: 0.3809 - val_loss: 1.2029 - val_accuracy: 0.4656\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.7776 - accuracy: 0.3680 - val_loss: 1.1685 - val_accuracy: 0.5048\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 1.9026 - accuracy: 0.3672 - val_loss: 1.3149 - val_accuracy: 0.4114\n",
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.011774080373049499\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.8846 - accuracy: 0.3856 - val_loss: 1.7410 - val_accuracy: 0.2966\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 2.1576 - accuracy: 0.2263 - val_loss: 1.7775 - val_accuracy: 0.2418\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.9546 - accuracy: 0.2231 - val_loss: 1.7190 - val_accuracy: 0.2796\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 1.9952 - accuracy: 0.2006 - val_loss: 1.7986 - val_accuracy: 0.1998\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 2.0426 - accuracy: 0.1928 - val_loss: 1.8201 - val_accuracy: 0.2000\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 2.3428 - accuracy: 0.1925 - val_loss: 1.7627 - val_accuracy: 0.1902\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 2.1243 - accuracy: 0.1907 - val_loss: 1.7928 - val_accuracy: 0.1964\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 2.1238 - accuracy: 0.1953 - val_loss: 1.7560 - val_accuracy: 0.1976\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 2.8268 - accuracy: 0.1894 - val_loss: 1.8229 - val_accuracy: 0.1984\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 2.2939 - accuracy: 0.1866 - val_loss: 1.8320 - val_accuracy: 0.1968\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.9606 - accuracy: 0.1923 - val_loss: 1.8295 - val_accuracy: 0.1916\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 1.9289 - accuracy: 0.1927 - val_loss: 1.8292 - val_accuracy: 0.1992\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.9572 - accuracy: 0.1924 - val_loss: 1.8158 - val_accuracy: 0.2122\n",
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.02000000000000001\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 2.2681 - accuracy: 0.2329 - val_loss: 2.0702 - val_accuracy: 0.2536\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 2.7604 - accuracy: 0.1601 - val_loss: 2.1811 - val_accuracy: 0.1626\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 3.1284 - accuracy: 0.1477 - val_loss: 2.7616 - val_accuracy: 0.1324\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 4.6083 - accuracy: 0.1296 - val_loss: 2.4306 - val_accuracy: 0.1350\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 3.0267 - accuracy: 0.1213 - val_loss: 2.2933 - val_accuracy: 0.1230\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 3.2633 - accuracy: 0.1285 - val_loss: 2.3101 - val_accuracy: 0.1048\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 5.0623 - accuracy: 0.1303 - val_loss: 2.4152 - val_accuracy: 0.1434\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 14.5812 - accuracy: 0.1264 - val_loss: 3.1578 - val_accuracy: 0.1112\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 5.7478 - accuracy: 0.1023 - val_loss: 2.9282 - val_accuracy: 0.1024\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 3.8484 - accuracy: 0.1008 - val_loss: 2.6191 - val_accuracy: 0.0980\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 2.9986 - accuracy: 0.1016 - val_loss: 2.4891 - val_accuracy: 0.0914\n"
     ]
    }
   ],
   "source": [
    "epochs_lr_scan=20\n",
    "results = find_max_learning_rate(\n",
    "            lr_init=1e-4,\n",
    "            lr_end=2e-2,\n",
    "            steps=10,\n",
    "            epochs=epochs_lr_scan,\n",
    "            model_build_fn=build_model,\n",
    "            n_hidden=3,\n",
    "            n_neurons=100,\n",
    "            input_shape=[28,28],\n",
    "            dropout=0.40\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pd.DataFrame( np.array( results['val_loss'] ).T,\n",
    "#              columns=[\"lr_{}\".format(lr_) for lr_ in np.round( results['learning_rate'], 4)]  ).plot( figsize=(12,10) )\n",
    "\n",
    "metrics_ = 'val_loss'\n",
    "columns=[\"lr_{}\".format(lr_) for lr_ in np.round( results['learning_rate'], 4)] \n",
    "df = pd.DataFrame( np.full((epochs_lr_scan,len(columns)),np.nan), columns=columns )\n",
    "for i_lr_,col_ in enumerate(columns):\n",
    "    df[col_] = pd.Series( results[ metrics_ ][i_lr_] )\n",
    "df.plot( figsize=(12,10) )\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f74dc041e50>]\n",
      "Building model with:\n",
      "Number of hidden layers: 1\n",
      "Number of neurons per layer: 50\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.7894 - accuracy: 0.7345 - val_loss: 0.4484 - val_accuracy: 0.8472\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5720 - accuracy: 0.7972 - val_loss: 0.4207 - val_accuracy: 0.8486\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5229 - accuracy: 0.8109 - val_loss: 0.4039 - val_accuracy: 0.8564\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5116 - accuracy: 0.8151 - val_loss: 0.3956 - val_accuracy: 0.8612\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4973 - accuracy: 0.8223 - val_loss: 0.3898 - val_accuracy: 0.8578\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4852 - accuracy: 0.8240 - val_loss: 0.3881 - val_accuracy: 0.8642\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4751 - accuracy: 0.8260 - val_loss: 0.3832 - val_accuracy: 0.8644\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4711 - accuracy: 0.8293 - val_loss: 0.3702 - val_accuracy: 0.8722\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4621 - accuracy: 0.8309 - val_loss: 0.3780 - val_accuracy: 0.8658\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4672 - accuracy: 0.8286 - val_loss: 0.3657 - val_accuracy: 0.8738\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4583 - accuracy: 0.8341 - val_loss: 0.3715 - val_accuracy: 0.8654\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4585 - accuracy: 0.8336 - val_loss: 0.3671 - val_accuracy: 0.8702\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4530 - accuracy: 0.8346 - val_loss: 0.3605 - val_accuracy: 0.8718\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.8326 - val_loss: 0.3666 - val_accuracy: 0.8718\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.8361 - val_loss: 0.3573 - val_accuracy: 0.8704\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4501 - accuracy: 0.8358 - val_loss: 0.3578 - val_accuracy: 0.8752\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4472 - accuracy: 0.8373 - val_loss: 0.3587 - val_accuracy: 0.8722\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4472 - accuracy: 0.8361 - val_loss: 0.3630 - val_accuracy: 0.8726\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4432 - accuracy: 0.8374 - val_loss: 0.3615 - val_accuracy: 0.8722\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4422 - accuracy: 0.8369 - val_loss: 0.3593 - val_accuracy: 0.8714\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4420 - accuracy: 0.8381 - val_loss: 0.3642 - val_accuracy: 0.8726\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4402 - accuracy: 0.8382 - val_loss: 0.3759 - val_accuracy: 0.8694\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4380 - accuracy: 0.8393 - val_loss: 0.3596 - val_accuracy: 0.8778\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4375 - accuracy: 0.8395 - val_loss: 0.3641 - val_accuracy: 0.8736\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4415 - accuracy: 0.8388 - val_loss: 0.3587 - val_accuracy: 0.8784\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.3650 - accuracy: 0.8632\n",
      "Building model with:\n",
      "Number of hidden layers: 1\n",
      "Number of neurons per layer: 50\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8151 - accuracy: 0.7295 - val_loss: 0.4622 - val_accuracy: 0.8376\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5777 - accuracy: 0.7920 - val_loss: 0.4297 - val_accuracy: 0.8494\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.8070 - val_loss: 0.4112 - val_accuracy: 0.8590\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5085 - accuracy: 0.8139 - val_loss: 0.4052 - val_accuracy: 0.8604\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4955 - accuracy: 0.8194 - val_loss: 0.3949 - val_accuracy: 0.8652\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4818 - accuracy: 0.8198 - val_loss: 0.3965 - val_accuracy: 0.8600\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4703 - accuracy: 0.8264 - val_loss: 0.3922 - val_accuracy: 0.8630\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4695 - accuracy: 0.8272 - val_loss: 0.3894 - val_accuracy: 0.8636\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4713 - accuracy: 0.8270 - val_loss: 0.3783 - val_accuracy: 0.8734\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4636 - accuracy: 0.8284 - val_loss: 0.3763 - val_accuracy: 0.8718\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4614 - accuracy: 0.8297 - val_loss: 0.3769 - val_accuracy: 0.8702\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4584 - accuracy: 0.8330 - val_loss: 0.3760 - val_accuracy: 0.8720\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4543 - accuracy: 0.8309 - val_loss: 0.3738 - val_accuracy: 0.8698\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4519 - accuracy: 0.8346 - val_loss: 0.3713 - val_accuracy: 0.8740\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4482 - accuracy: 0.8349 - val_loss: 0.3758 - val_accuracy: 0.8694\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4462 - accuracy: 0.8352 - val_loss: 0.3719 - val_accuracy: 0.8720\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4482 - accuracy: 0.8358 - val_loss: 0.3705 - val_accuracy: 0.8696\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4452 - accuracy: 0.8353 - val_loss: 0.3661 - val_accuracy: 0.8736\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4418 - accuracy: 0.8368 - val_loss: 0.3738 - val_accuracy: 0.8720\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4420 - accuracy: 0.8367 - val_loss: 0.3721 - val_accuracy: 0.8724\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4410 - accuracy: 0.8364 - val_loss: 0.3743 - val_accuracy: 0.8688\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4366 - accuracy: 0.8376 - val_loss: 0.3662 - val_accuracy: 0.8784\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4417 - accuracy: 0.8384 - val_loss: 0.3644 - val_accuracy: 0.8758\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4396 - accuracy: 0.8360 - val_loss: 0.3682 - val_accuracy: 0.8708\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4364 - accuracy: 0.8356 - val_loss: 0.3646 - val_accuracy: 0.8774\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4381 - accuracy: 0.8394 - val_loss: 0.3661 - val_accuracy: 0.8736\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4361 - accuracy: 0.8380 - val_loss: 0.3676 - val_accuracy: 0.8774\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4369 - accuracy: 0.8388 - val_loss: 0.3713 - val_accuracy: 0.8750\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4350 - accuracy: 0.8374 - val_loss: 0.3646 - val_accuracy: 0.8770\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4374 - accuracy: 0.8383 - val_loss: 0.3698 - val_accuracy: 0.8754\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4343 - accuracy: 0.8386 - val_loss: 0.3637 - val_accuracy: 0.8740\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4302 - accuracy: 0.8408 - val_loss: 0.3672 - val_accuracy: 0.8766\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4327 - accuracy: 0.8406 - val_loss: 0.3665 - val_accuracy: 0.8720\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4344 - accuracy: 0.8396 - val_loss: 0.3623 - val_accuracy: 0.8762\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4306 - accuracy: 0.8398 - val_loss: 0.3544 - val_accuracy: 0.8776\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4378 - accuracy: 0.8375 - val_loss: 0.3620 - val_accuracy: 0.8772\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4327 - accuracy: 0.8391 - val_loss: 0.3612 - val_accuracy: 0.8734\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4267 - accuracy: 0.8408 - val_loss: 0.3590 - val_accuracy: 0.8804\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4299 - accuracy: 0.8406 - val_loss: 0.3637 - val_accuracy: 0.8754\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4300 - accuracy: 0.8396 - val_loss: 0.3658 - val_accuracy: 0.8772\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4232 - accuracy: 0.8438 - val_loss: 0.3667 - val_accuracy: 0.8752\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4289 - accuracy: 0.8393 - val_loss: 0.3744 - val_accuracy: 0.8758\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4334 - accuracy: 0.8397 - val_loss: 0.3634 - val_accuracy: 0.8746\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4314 - accuracy: 0.8409 - val_loss: 0.3638 - val_accuracy: 0.8774\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4304 - accuracy: 0.8406 - val_loss: 0.3682 - val_accuracy: 0.8742\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.3527 - accuracy: 0.8768\n",
      "Building model with:\n",
      "Number of hidden layers: 1\n",
      "Number of neurons per layer: 50\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8284 - accuracy: 0.7277 - val_loss: 0.4445 - val_accuracy: 0.8418\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5843 - accuracy: 0.7932 - val_loss: 0.4199 - val_accuracy: 0.8478\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5308 - accuracy: 0.8073 - val_loss: 0.3956 - val_accuracy: 0.8586\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5070 - accuracy: 0.8154 - val_loss: 0.3944 - val_accuracy: 0.8572\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4946 - accuracy: 0.8198 - val_loss: 0.3794 - val_accuracy: 0.8614\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4864 - accuracy: 0.8220 - val_loss: 0.3823 - val_accuracy: 0.8624\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4735 - accuracy: 0.8267 - val_loss: 0.3757 - val_accuracy: 0.8644\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4721 - accuracy: 0.8265 - val_loss: 0.3715 - val_accuracy: 0.8678\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4634 - accuracy: 0.8291 - val_loss: 0.3661 - val_accuracy: 0.8664\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4657 - accuracy: 0.8286 - val_loss: 0.3618 - val_accuracy: 0.8702\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4606 - accuracy: 0.8320 - val_loss: 0.3670 - val_accuracy: 0.8684\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4523 - accuracy: 0.8316 - val_loss: 0.3583 - val_accuracy: 0.8730\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4499 - accuracy: 0.8347 - val_loss: 0.3499 - val_accuracy: 0.8740\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4501 - accuracy: 0.8342 - val_loss: 0.3656 - val_accuracy: 0.8728\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4462 - accuracy: 0.8356 - val_loss: 0.3573 - val_accuracy: 0.8748\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4443 - accuracy: 0.8360 - val_loss: 0.3587 - val_accuracy: 0.8740\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4487 - accuracy: 0.8366 - val_loss: 0.3602 - val_accuracy: 0.8734\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4429 - accuracy: 0.8367 - val_loss: 0.3502 - val_accuracy: 0.8738\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4420 - accuracy: 0.8352 - val_loss: 0.3598 - val_accuracy: 0.8688\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4398 - accuracy: 0.8367 - val_loss: 0.3529 - val_accuracy: 0.8744\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4361 - accuracy: 0.8379 - val_loss: 0.3558 - val_accuracy: 0.8756\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4363 - accuracy: 0.8400 - val_loss: 0.3547 - val_accuracy: 0.8732\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4384 - accuracy: 0.8389 - val_loss: 0.3520 - val_accuracy: 0.8766\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.3631 - accuracy: 0.8669\n",
      "Building model with:\n",
      "Number of hidden layers: 1\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.7786 - accuracy: 0.7495 - val_loss: 0.4388 - val_accuracy: 0.8518\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.8059 - val_loss: 0.4121 - val_accuracy: 0.8544\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4992 - accuracy: 0.8196 - val_loss: 0.3939 - val_accuracy: 0.8602\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4763 - accuracy: 0.8251 - val_loss: 0.3838 - val_accuracy: 0.8662\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4591 - accuracy: 0.8334 - val_loss: 0.3632 - val_accuracy: 0.8714\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4486 - accuracy: 0.8361 - val_loss: 0.3635 - val_accuracy: 0.8714\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4390 - accuracy: 0.8403 - val_loss: 0.3658 - val_accuracy: 0.8698\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4363 - accuracy: 0.8414 - val_loss: 0.3487 - val_accuracy: 0.8790\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4244 - accuracy: 0.8434 - val_loss: 0.3602 - val_accuracy: 0.8698\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4276 - accuracy: 0.8429 - val_loss: 0.3472 - val_accuracy: 0.8768\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4152 - accuracy: 0.8485 - val_loss: 0.3539 - val_accuracy: 0.8718\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4188 - accuracy: 0.8462 - val_loss: 0.3495 - val_accuracy: 0.8764\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4138 - accuracy: 0.8490 - val_loss: 0.3472 - val_accuracy: 0.8746\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4085 - accuracy: 0.8503 - val_loss: 0.3406 - val_accuracy: 0.8810\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4063 - accuracy: 0.8519 - val_loss: 0.3454 - val_accuracy: 0.8792\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4026 - accuracy: 0.8514 - val_loss: 0.3465 - val_accuracy: 0.8790\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4023 - accuracy: 0.8532 - val_loss: 0.3412 - val_accuracy: 0.8830\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3947 - accuracy: 0.8536 - val_loss: 0.3483 - val_accuracy: 0.8786\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4020 - accuracy: 0.8528 - val_loss: 0.3396 - val_accuracy: 0.8832\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3915 - accuracy: 0.8551 - val_loss: 0.3439 - val_accuracy: 0.8800\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3957 - accuracy: 0.8527 - val_loss: 0.3489 - val_accuracy: 0.8802\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3924 - accuracy: 0.8565 - val_loss: 0.3457 - val_accuracy: 0.8828\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3930 - accuracy: 0.8559 - val_loss: 0.3428 - val_accuracy: 0.8848\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3917 - accuracy: 0.8549 - val_loss: 0.3490 - val_accuracy: 0.8812\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3919 - accuracy: 0.8561 - val_loss: 0.3561 - val_accuracy: 0.8834\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3909 - accuracy: 0.8581 - val_loss: 0.3518 - val_accuracy: 0.8788\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3921 - accuracy: 0.8562 - val_loss: 0.3456 - val_accuracy: 0.8806\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3889 - accuracy: 0.8575 - val_loss: 0.3433 - val_accuracy: 0.8842\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3830 - accuracy: 0.8583 - val_loss: 0.3548 - val_accuracy: 0.8768\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.3440 - accuracy: 0.8738\n",
      "Building model with:\n",
      "Number of hidden layers: 1\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8087 - accuracy: 0.7409 - val_loss: 0.4422 - val_accuracy: 0.8514\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5514 - accuracy: 0.8010 - val_loss: 0.4066 - val_accuracy: 0.8594\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5029 - accuracy: 0.8150 - val_loss: 0.3940 - val_accuracy: 0.8608\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4781 - accuracy: 0.8248 - val_loss: 0.3915 - val_accuracy: 0.8648\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4626 - accuracy: 0.8298 - val_loss: 0.3824 - val_accuracy: 0.8676\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4548 - accuracy: 0.8326 - val_loss: 0.3712 - val_accuracy: 0.8696\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4419 - accuracy: 0.8354 - val_loss: 0.3775 - val_accuracy: 0.8712\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4333 - accuracy: 0.8381 - val_loss: 0.3712 - val_accuracy: 0.8690\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4311 - accuracy: 0.8419 - val_loss: 0.3572 - val_accuracy: 0.8738\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4284 - accuracy: 0.8435 - val_loss: 0.3564 - val_accuracy: 0.8764\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4193 - accuracy: 0.8451 - val_loss: 0.3544 - val_accuracy: 0.8764\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4202 - accuracy: 0.8434 - val_loss: 0.3600 - val_accuracy: 0.8778\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4158 - accuracy: 0.8452 - val_loss: 0.3586 - val_accuracy: 0.8778\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4092 - accuracy: 0.8467 - val_loss: 0.3555 - val_accuracy: 0.8822\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4109 - accuracy: 0.8495 - val_loss: 0.3578 - val_accuracy: 0.8792\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4041 - accuracy: 0.8502 - val_loss: 0.3618 - val_accuracy: 0.8770\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4100 - accuracy: 0.8481 - val_loss: 0.3605 - val_accuracy: 0.8782\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4000 - accuracy: 0.8511 - val_loss: 0.3483 - val_accuracy: 0.8806\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4036 - accuracy: 0.8509 - val_loss: 0.3627 - val_accuracy: 0.8804\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3972 - accuracy: 0.8540 - val_loss: 0.3506 - val_accuracy: 0.8804\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3972 - accuracy: 0.8535 - val_loss: 0.3513 - val_accuracy: 0.8780\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3938 - accuracy: 0.8546 - val_loss: 0.3465 - val_accuracy: 0.8790\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3928 - accuracy: 0.8558 - val_loss: 0.3515 - val_accuracy: 0.8772\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3921 - accuracy: 0.8555 - val_loss: 0.3430 - val_accuracy: 0.8780\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3940 - accuracy: 0.8549 - val_loss: 0.3419 - val_accuracy: 0.8836\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3902 - accuracy: 0.8550 - val_loss: 0.3471 - val_accuracy: 0.8766\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3947 - accuracy: 0.8542 - val_loss: 0.3418 - val_accuracy: 0.8804\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3921 - accuracy: 0.8555 - val_loss: 0.3494 - val_accuracy: 0.8780\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3909 - accuracy: 0.8541 - val_loss: 0.3493 - val_accuracy: 0.8840\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3886 - accuracy: 0.8547 - val_loss: 0.3527 - val_accuracy: 0.8816\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3920 - accuracy: 0.8549 - val_loss: 0.3482 - val_accuracy: 0.8810\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3833 - accuracy: 0.8538 - val_loss: 0.3407 - val_accuracy: 0.8842\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3862 - accuracy: 0.8568 - val_loss: 0.3508 - val_accuracy: 0.8820\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3842 - accuracy: 0.8571 - val_loss: 0.3462 - val_accuracy: 0.8832\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3797 - accuracy: 0.8581 - val_loss: 0.3350 - val_accuracy: 0.8852\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3827 - accuracy: 0.8579 - val_loss: 0.3477 - val_accuracy: 0.8848\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3846 - accuracy: 0.8574 - val_loss: 0.3494 - val_accuracy: 0.8822\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3817 - accuracy: 0.8581 - val_loss: 0.3474 - val_accuracy: 0.8852\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3792 - accuracy: 0.8586 - val_loss: 0.3489 - val_accuracy: 0.8856\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3801 - accuracy: 0.8582 - val_loss: 0.3576 - val_accuracy: 0.8850\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3790 - accuracy: 0.8613 - val_loss: 0.3512 - val_accuracy: 0.8836\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3782 - accuracy: 0.8597 - val_loss: 0.3567 - val_accuracy: 0.8814\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3841 - accuracy: 0.8594 - val_loss: 0.3481 - val_accuracy: 0.8844\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3849 - accuracy: 0.8576 - val_loss: 0.3437 - val_accuracy: 0.8874\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3820 - accuracy: 0.8579 - val_loss: 0.3541 - val_accuracy: 0.8772\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.3306 - accuracy: 0.8855\n",
      "Building model with:\n",
      "Number of hidden layers: 1\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8115 - accuracy: 0.7438 - val_loss: 0.4262 - val_accuracy: 0.8492\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5566 - accuracy: 0.8007 - val_loss: 0.4041 - val_accuracy: 0.8542\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4980 - accuracy: 0.8184 - val_loss: 0.3867 - val_accuracy: 0.8622\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4768 - accuracy: 0.8249 - val_loss: 0.3857 - val_accuracy: 0.8622\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4584 - accuracy: 0.8312 - val_loss: 0.3681 - val_accuracy: 0.8748\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4488 - accuracy: 0.8350 - val_loss: 0.3666 - val_accuracy: 0.8676\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4410 - accuracy: 0.8383 - val_loss: 0.3592 - val_accuracy: 0.8752\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4336 - accuracy: 0.8387 - val_loss: 0.3554 - val_accuracy: 0.8714\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4289 - accuracy: 0.8427 - val_loss: 0.3530 - val_accuracy: 0.8760\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4262 - accuracy: 0.8441 - val_loss: 0.3511 - val_accuracy: 0.8794\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4187 - accuracy: 0.8447 - val_loss: 0.3509 - val_accuracy: 0.8794\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4163 - accuracy: 0.8461 - val_loss: 0.3467 - val_accuracy: 0.8776\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4107 - accuracy: 0.8481 - val_loss: 0.3425 - val_accuracy: 0.8746\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4098 - accuracy: 0.8490 - val_loss: 0.3394 - val_accuracy: 0.8810\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4126 - accuracy: 0.8481 - val_loss: 0.3435 - val_accuracy: 0.8776\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4059 - accuracy: 0.8519 - val_loss: 0.3426 - val_accuracy: 0.8764\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4061 - accuracy: 0.8516 - val_loss: 0.3420 - val_accuracy: 0.8784\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4015 - accuracy: 0.8503 - val_loss: 0.3293 - val_accuracy: 0.8852\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3975 - accuracy: 0.8521 - val_loss: 0.3466 - val_accuracy: 0.8768\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4005 - accuracy: 0.8525 - val_loss: 0.3340 - val_accuracy: 0.8798\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3980 - accuracy: 0.8523 - val_loss: 0.3379 - val_accuracy: 0.8836\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3926 - accuracy: 0.8555 - val_loss: 0.3335 - val_accuracy: 0.8814\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3986 - accuracy: 0.8536 - val_loss: 0.3349 - val_accuracy: 0.8804\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3898 - accuracy: 0.8554 - val_loss: 0.3379 - val_accuracy: 0.8822\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3919 - accuracy: 0.8574 - val_loss: 0.3325 - val_accuracy: 0.8800\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3882 - accuracy: 0.8558 - val_loss: 0.3423 - val_accuracy: 0.8820\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3895 - accuracy: 0.8572 - val_loss: 0.3357 - val_accuracy: 0.8852\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3951 - accuracy: 0.8549 - val_loss: 0.3294 - val_accuracy: 0.8842\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.3393 - accuracy: 0.8787\n",
      "Building model with:\n",
      "Number of hidden layers: 2\n",
      "Number of neurons per layer: 50\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1.1891 - accuracy: 0.6328 - val_loss: 0.5005 - val_accuracy: 0.8280\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.7189 - accuracy: 0.7500 - val_loss: 0.4532 - val_accuracy: 0.8376\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.6345 - accuracy: 0.7787 - val_loss: 0.4354 - val_accuracy: 0.8414\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.6040 - accuracy: 0.7856 - val_loss: 0.4228 - val_accuracy: 0.8504\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7986 - val_loss: 0.4131 - val_accuracy: 0.8486\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5605 - accuracy: 0.8016 - val_loss: 0.4071 - val_accuracy: 0.8528\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5508 - accuracy: 0.8023 - val_loss: 0.3946 - val_accuracy: 0.8554\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.8083 - val_loss: 0.3934 - val_accuracy: 0.8578\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5293 - accuracy: 0.8115 - val_loss: 0.3914 - val_accuracy: 0.8592\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5324 - accuracy: 0.8088 - val_loss: 0.3840 - val_accuracy: 0.8590\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5198 - accuracy: 0.8133 - val_loss: 0.3918 - val_accuracy: 0.8538\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5164 - accuracy: 0.8156 - val_loss: 0.3817 - val_accuracy: 0.8586\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5154 - accuracy: 0.8168 - val_loss: 0.3764 - val_accuracy: 0.8630\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5135 - accuracy: 0.8163 - val_loss: 0.3778 - val_accuracy: 0.8590\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5026 - accuracy: 0.8196 - val_loss: 0.3738 - val_accuracy: 0.8612\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4977 - accuracy: 0.8235 - val_loss: 0.3642 - val_accuracy: 0.8672\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4998 - accuracy: 0.8216 - val_loss: 0.3693 - val_accuracy: 0.8662\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4997 - accuracy: 0.8231 - val_loss: 0.3688 - val_accuracy: 0.8618\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4957 - accuracy: 0.8236 - val_loss: 0.3672 - val_accuracy: 0.8650\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4941 - accuracy: 0.8234 - val_loss: 0.3567 - val_accuracy: 0.8744\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4945 - accuracy: 0.8247 - val_loss: 0.3592 - val_accuracy: 0.8694\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4887 - accuracy: 0.8278 - val_loss: 0.3698 - val_accuracy: 0.8684\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4847 - accuracy: 0.8268 - val_loss: 0.3566 - val_accuracy: 0.8698\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4866 - accuracy: 0.8266 - val_loss: 0.3526 - val_accuracy: 0.8702\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4881 - accuracy: 0.8252 - val_loss: 0.3523 - val_accuracy: 0.8734\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4858 - accuracy: 0.8279 - val_loss: 0.3521 - val_accuracy: 0.8698\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4882 - accuracy: 0.8255 - val_loss: 0.3578 - val_accuracy: 0.8678\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4786 - accuracy: 0.8298 - val_loss: 0.3516 - val_accuracy: 0.8674\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4803 - accuracy: 0.8282 - val_loss: 0.3553 - val_accuracy: 0.8684\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4808 - accuracy: 0.8290 - val_loss: 0.3484 - val_accuracy: 0.8724\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4808 - accuracy: 0.8298 - val_loss: 0.3510 - val_accuracy: 0.8726\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4808 - accuracy: 0.8296 - val_loss: 0.3422 - val_accuracy: 0.8796\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4767 - accuracy: 0.8295 - val_loss: 0.3527 - val_accuracy: 0.8674\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4745 - accuracy: 0.8317 - val_loss: 0.3551 - val_accuracy: 0.8688\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4748 - accuracy: 0.8307 - val_loss: 0.3578 - val_accuracy: 0.8670\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4758 - accuracy: 0.8292 - val_loss: 0.3497 - val_accuracy: 0.8700\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4726 - accuracy: 0.8309 - val_loss: 0.3455 - val_accuracy: 0.8744\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4749 - accuracy: 0.8292 - val_loss: 0.3463 - val_accuracy: 0.8758\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4673 - accuracy: 0.8309 - val_loss: 0.3497 - val_accuracy: 0.8722\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4722 - accuracy: 0.8322 - val_loss: 0.3524 - val_accuracy: 0.8716\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4751 - accuracy: 0.8308 - val_loss: 0.3453 - val_accuracy: 0.8734\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4754 - accuracy: 0.8295 - val_loss: 0.3535 - val_accuracy: 0.8706\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.3549 - accuracy: 0.8665\n",
      "Building model with:\n",
      "Number of hidden layers: 2\n",
      "Number of neurons per layer: 50\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.1364 - accuracy: 0.6362 - val_loss: 0.4827 - val_accuracy: 0.8234\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.7080 - accuracy: 0.7486 - val_loss: 0.4407 - val_accuracy: 0.8386\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6335 - accuracy: 0.7740 - val_loss: 0.4266 - val_accuracy: 0.8432\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5990 - accuracy: 0.7876 - val_loss: 0.4216 - val_accuracy: 0.8486\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5821 - accuracy: 0.7922 - val_loss: 0.4188 - val_accuracy: 0.8456\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5679 - accuracy: 0.7976 - val_loss: 0.4104 - val_accuracy: 0.8490\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5537 - accuracy: 0.8003 - val_loss: 0.3918 - val_accuracy: 0.8588\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5405 - accuracy: 0.8054 - val_loss: 0.3935 - val_accuracy: 0.8582\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.8065 - val_loss: 0.3813 - val_accuracy: 0.8652\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5314 - accuracy: 0.8089 - val_loss: 0.3826 - val_accuracy: 0.8602\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5294 - accuracy: 0.8091 - val_loss: 0.3771 - val_accuracy: 0.8604\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5214 - accuracy: 0.8100 - val_loss: 0.3740 - val_accuracy: 0.8656\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5163 - accuracy: 0.8147 - val_loss: 0.3702 - val_accuracy: 0.8642\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5125 - accuracy: 0.8170 - val_loss: 0.3675 - val_accuracy: 0.8698\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5136 - accuracy: 0.8134 - val_loss: 0.3718 - val_accuracy: 0.8586\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5069 - accuracy: 0.8163 - val_loss: 0.3669 - val_accuracy: 0.8662\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5091 - accuracy: 0.8200 - val_loss: 0.3736 - val_accuracy: 0.8590\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5020 - accuracy: 0.8201 - val_loss: 0.3691 - val_accuracy: 0.8618\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5015 - accuracy: 0.8189 - val_loss: 0.3731 - val_accuracy: 0.8622\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4922 - accuracy: 0.8201 - val_loss: 0.3635 - val_accuracy: 0.8626\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4911 - accuracy: 0.8224 - val_loss: 0.3685 - val_accuracy: 0.8600\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4896 - accuracy: 0.8249 - val_loss: 0.3645 - val_accuracy: 0.8656\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4960 - accuracy: 0.8236 - val_loss: 0.3658 - val_accuracy: 0.8618\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4935 - accuracy: 0.8194 - val_loss: 0.3606 - val_accuracy: 0.8658\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4899 - accuracy: 0.8241 - val_loss: 0.3592 - val_accuracy: 0.8648\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4880 - accuracy: 0.8257 - val_loss: 0.3568 - val_accuracy: 0.8636\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4852 - accuracy: 0.8257 - val_loss: 0.3570 - val_accuracy: 0.8662\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4913 - accuracy: 0.8221 - val_loss: 0.3559 - val_accuracy: 0.8660\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4864 - accuracy: 0.8230 - val_loss: 0.3565 - val_accuracy: 0.8704\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4873 - accuracy: 0.8235 - val_loss: 0.3627 - val_accuracy: 0.8658\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4878 - accuracy: 0.8243 - val_loss: 0.3577 - val_accuracy: 0.8658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4779 - accuracy: 0.8259 - val_loss: 0.3615 - val_accuracy: 0.8642\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4820 - accuracy: 0.8259 - val_loss: 0.3567 - val_accuracy: 0.8676\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4817 - accuracy: 0.8253 - val_loss: 0.3550 - val_accuracy: 0.8662\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4765 - accuracy: 0.8286 - val_loss: 0.3525 - val_accuracy: 0.8694\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4826 - accuracy: 0.8241 - val_loss: 0.3490 - val_accuracy: 0.8734\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4767 - accuracy: 0.8276 - val_loss: 0.3563 - val_accuracy: 0.8660\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4746 - accuracy: 0.8286 - val_loss: 0.3499 - val_accuracy: 0.8750\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4760 - accuracy: 0.8281 - val_loss: 0.3493 - val_accuracy: 0.8698\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4717 - accuracy: 0.8277 - val_loss: 0.3442 - val_accuracy: 0.8752\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4746 - accuracy: 0.8300 - val_loss: 0.3555 - val_accuracy: 0.8684\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4746 - accuracy: 0.8299 - val_loss: 0.3523 - val_accuracy: 0.8708\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4809 - accuracy: 0.8261 - val_loss: 0.3507 - val_accuracy: 0.8726\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4791 - accuracy: 0.8256 - val_loss: 0.3434 - val_accuracy: 0.8738\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4719 - accuracy: 0.8287 - val_loss: 0.3511 - val_accuracy: 0.8660\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4755 - accuracy: 0.8285 - val_loss: 0.3503 - val_accuracy: 0.8682\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4741 - accuracy: 0.8273 - val_loss: 0.3495 - val_accuracy: 0.8714\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4750 - accuracy: 0.8283 - val_loss: 0.3488 - val_accuracy: 0.8714\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4727 - accuracy: 0.8286 - val_loss: 0.3477 - val_accuracy: 0.8706\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4724 - accuracy: 0.8264 - val_loss: 0.3532 - val_accuracy: 0.8708\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4741 - accuracy: 0.8293 - val_loss: 0.3457 - val_accuracy: 0.8722\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4717 - accuracy: 0.8313 - val_loss: 0.3455 - val_accuracy: 0.8744\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4726 - accuracy: 0.8303 - val_loss: 0.3449 - val_accuracy: 0.8716\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4753 - accuracy: 0.8285 - val_loss: 0.3446 - val_accuracy: 0.8670\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.3581 - accuracy: 0.8730\n",
      "Building model with:\n",
      "Number of hidden layers: 2\n",
      "Number of neurons per layer: 50\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.1940 - accuracy: 0.6293 - val_loss: 0.4783 - val_accuracy: 0.8256\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.7205 - accuracy: 0.7451 - val_loss: 0.4455 - val_accuracy: 0.8360\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.6377 - accuracy: 0.7739 - val_loss: 0.4303 - val_accuracy: 0.8432\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6009 - accuracy: 0.7856 - val_loss: 0.4166 - val_accuracy: 0.8448\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5819 - accuracy: 0.7892 - val_loss: 0.4104 - val_accuracy: 0.8468\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5560 - accuracy: 0.8002 - val_loss: 0.4047 - val_accuracy: 0.8486\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5490 - accuracy: 0.8045 - val_loss: 0.3940 - val_accuracy: 0.8568\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.8045 - val_loss: 0.3984 - val_accuracy: 0.8544\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5309 - accuracy: 0.8105 - val_loss: 0.3874 - val_accuracy: 0.8546\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5265 - accuracy: 0.8124 - val_loss: 0.3771 - val_accuracy: 0.8624\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5179 - accuracy: 0.8130 - val_loss: 0.3754 - val_accuracy: 0.8598\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5146 - accuracy: 0.8159 - val_loss: 0.3732 - val_accuracy: 0.8614\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5132 - accuracy: 0.8150 - val_loss: 0.3692 - val_accuracy: 0.8610\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5023 - accuracy: 0.8197 - val_loss: 0.3674 - val_accuracy: 0.8646\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5040 - accuracy: 0.8199 - val_loss: 0.3687 - val_accuracy: 0.8624\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4983 - accuracy: 0.8211 - val_loss: 0.3691 - val_accuracy: 0.8626\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4991 - accuracy: 0.8197 - val_loss: 0.3652 - val_accuracy: 0.8614\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4995 - accuracy: 0.8212 - val_loss: 0.3594 - val_accuracy: 0.8648\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4953 - accuracy: 0.8208 - val_loss: 0.3631 - val_accuracy: 0.8606\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4911 - accuracy: 0.8224 - val_loss: 0.3627 - val_accuracy: 0.8608\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4940 - accuracy: 0.8226 - val_loss: 0.3624 - val_accuracy: 0.8608\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4859 - accuracy: 0.8252 - val_loss: 0.3550 - val_accuracy: 0.8658\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4914 - accuracy: 0.8216 - val_loss: 0.3618 - val_accuracy: 0.8634\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4833 - accuracy: 0.8242 - val_loss: 0.3547 - val_accuracy: 0.8680\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4876 - accuracy: 0.8252 - val_loss: 0.3500 - val_accuracy: 0.8654\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4791 - accuracy: 0.8266 - val_loss: 0.3566 - val_accuracy: 0.8648\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4830 - accuracy: 0.8260 - val_loss: 0.3515 - val_accuracy: 0.8660\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4842 - accuracy: 0.8255 - val_loss: 0.3580 - val_accuracy: 0.8640\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4807 - accuracy: 0.8271 - val_loss: 0.3491 - val_accuracy: 0.8688\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4795 - accuracy: 0.8268 - val_loss: 0.3488 - val_accuracy: 0.8686\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4794 - accuracy: 0.8281 - val_loss: 0.3479 - val_accuracy: 0.8746\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4773 - accuracy: 0.8269 - val_loss: 0.3484 - val_accuracy: 0.8690\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4741 - accuracy: 0.8295 - val_loss: 0.3485 - val_accuracy: 0.8670\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4727 - accuracy: 0.8309 - val_loss: 0.3473 - val_accuracy: 0.8668\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4787 - accuracy: 0.8300 - val_loss: 0.3524 - val_accuracy: 0.8648\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4700 - accuracy: 0.8281 - val_loss: 0.3450 - val_accuracy: 0.8680\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4788 - accuracy: 0.8257 - val_loss: 0.3538 - val_accuracy: 0.8694\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4771 - accuracy: 0.8294 - val_loss: 0.3428 - val_accuracy: 0.8706\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4738 - accuracy: 0.8311 - val_loss: 0.3459 - val_accuracy: 0.8716\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4685 - accuracy: 0.8319 - val_loss: 0.3471 - val_accuracy: 0.8672\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4721 - accuracy: 0.8305 - val_loss: 0.3454 - val_accuracy: 0.8704\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4698 - accuracy: 0.8297 - val_loss: 0.3436 - val_accuracy: 0.8694\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4726 - accuracy: 0.8309 - val_loss: 0.3498 - val_accuracy: 0.8734\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4711 - accuracy: 0.8302 - val_loss: 0.3465 - val_accuracy: 0.8698\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4698 - accuracy: 0.8313 - val_loss: 0.3447 - val_accuracy: 0.8716\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4754 - accuracy: 0.8270 - val_loss: 0.3464 - val_accuracy: 0.8692\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4695 - accuracy: 0.8331 - val_loss: 0.3461 - val_accuracy: 0.8702\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4631 - accuracy: 0.8329 - val_loss: 0.3411 - val_accuracy: 0.8758\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4709 - accuracy: 0.8307 - val_loss: 0.3457 - val_accuracy: 0.8736\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4697 - accuracy: 0.8300 - val_loss: 0.3394 - val_accuracy: 0.8728\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4655 - accuracy: 0.8310 - val_loss: 0.3369 - val_accuracy: 0.8748\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4635 - accuracy: 0.8360 - val_loss: 0.3376 - val_accuracy: 0.8762\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4668 - accuracy: 0.8324 - val_loss: 0.3464 - val_accuracy: 0.8752\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4609 - accuracy: 0.8341 - val_loss: 0.3352 - val_accuracy: 0.8734\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4640 - accuracy: 0.8347 - val_loss: 0.3420 - val_accuracy: 0.8698\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4687 - accuracy: 0.8313 - val_loss: 0.3508 - val_accuracy: 0.8676\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4678 - accuracy: 0.8315 - val_loss: 0.3368 - val_accuracy: 0.8772\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4611 - accuracy: 0.8339 - val_loss: 0.3382 - val_accuracy: 0.8722\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4598 - accuracy: 0.8318 - val_loss: 0.3430 - val_accuracy: 0.8724\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4680 - accuracy: 0.8322 - val_loss: 0.3490 - val_accuracy: 0.8696\n",
      "Epoch 61/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4639 - accuracy: 0.8329 - val_loss: 0.3434 - val_accuracy: 0.8642\n",
      "Epoch 62/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4651 - accuracy: 0.8338 - val_loss: 0.3395 - val_accuracy: 0.8680\n",
      "Epoch 63/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4678 - accuracy: 0.8319 - val_loss: 0.3454 - val_accuracy: 0.8698\n",
      "Epoch 64/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4573 - accuracy: 0.8346 - val_loss: 0.3456 - val_accuracy: 0.8734\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.3515 - accuracy: 0.8699\n",
      "Building model with:\n",
      "Number of hidden layers: 2\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.0393 - accuracy: 0.6836 - val_loss: 0.4541 - val_accuracy: 0.8376\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.6316 - accuracy: 0.7782 - val_loss: 0.4208 - val_accuracy: 0.8442\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5672 - accuracy: 0.7963 - val_loss: 0.4053 - val_accuracy: 0.8528\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5374 - accuracy: 0.8057 - val_loss: 0.3843 - val_accuracy: 0.8592\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5151 - accuracy: 0.8098 - val_loss: 0.3785 - val_accuracy: 0.8608\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4988 - accuracy: 0.8182 - val_loss: 0.3736 - val_accuracy: 0.8636\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4896 - accuracy: 0.8214 - val_loss: 0.3713 - val_accuracy: 0.8628\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4754 - accuracy: 0.8258 - val_loss: 0.3579 - val_accuracy: 0.8688\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4759 - accuracy: 0.8276 - val_loss: 0.3613 - val_accuracy: 0.8654\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4699 - accuracy: 0.8282 - val_loss: 0.3561 - val_accuracy: 0.8652\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4629 - accuracy: 0.8303 - val_loss: 0.3536 - val_accuracy: 0.8670\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4584 - accuracy: 0.8340 - val_loss: 0.3409 - val_accuracy: 0.8784\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4532 - accuracy: 0.8336 - val_loss: 0.3389 - val_accuracy: 0.8696\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.8352 - val_loss: 0.3449 - val_accuracy: 0.8712\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4439 - accuracy: 0.8373 - val_loss: 0.3405 - val_accuracy: 0.8706\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4445 - accuracy: 0.8375 - val_loss: 0.3377 - val_accuracy: 0.8724\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4413 - accuracy: 0.8393 - val_loss: 0.3468 - val_accuracy: 0.8716\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4393 - accuracy: 0.8396 - val_loss: 0.3343 - val_accuracy: 0.8734\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4347 - accuracy: 0.8420 - val_loss: 0.3394 - val_accuracy: 0.8770\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4294 - accuracy: 0.8439 - val_loss: 0.3318 - val_accuracy: 0.8788\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4273 - accuracy: 0.8443 - val_loss: 0.3369 - val_accuracy: 0.8720\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4286 - accuracy: 0.8433 - val_loss: 0.3318 - val_accuracy: 0.8788\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4285 - accuracy: 0.8440 - val_loss: 0.3267 - val_accuracy: 0.8770\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4231 - accuracy: 0.8455 - val_loss: 0.3268 - val_accuracy: 0.8796\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4271 - accuracy: 0.8427 - val_loss: 0.3253 - val_accuracy: 0.8808\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4247 - accuracy: 0.8444 - val_loss: 0.3257 - val_accuracy: 0.8776\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4280 - accuracy: 0.8452 - val_loss: 0.3288 - val_accuracy: 0.8758\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4199 - accuracy: 0.8474 - val_loss: 0.3186 - val_accuracy: 0.8802\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4196 - accuracy: 0.8484 - val_loss: 0.3322 - val_accuracy: 0.8796\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4207 - accuracy: 0.8455 - val_loss: 0.3211 - val_accuracy: 0.8822\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4181 - accuracy: 0.8457 - val_loss: 0.3152 - val_accuracy: 0.8842\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4144 - accuracy: 0.8495 - val_loss: 0.3153 - val_accuracy: 0.8822\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4165 - accuracy: 0.8481 - val_loss: 0.3254 - val_accuracy: 0.8792\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4189 - accuracy: 0.8481 - val_loss: 0.3246 - val_accuracy: 0.8760\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4122 - accuracy: 0.8472 - val_loss: 0.3221 - val_accuracy: 0.8786\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4073 - accuracy: 0.8508 - val_loss: 0.3234 - val_accuracy: 0.8782\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4117 - accuracy: 0.8493 - val_loss: 0.3212 - val_accuracy: 0.8824\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4099 - accuracy: 0.8489 - val_loss: 0.3218 - val_accuracy: 0.8798\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4116 - accuracy: 0.8506 - val_loss: 0.3205 - val_accuracy: 0.8820\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4098 - accuracy: 0.8513 - val_loss: 0.3227 - val_accuracy: 0.8804\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4102 - accuracy: 0.8516 - val_loss: 0.3156 - val_accuracy: 0.8828\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.3284 - accuracy: 0.8753\n",
      "Building model with:\n",
      "Number of hidden layers: 2\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.0682 - accuracy: 0.6784 - val_loss: 0.4608 - val_accuracy: 0.8362\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.6443 - accuracy: 0.7678 - val_loss: 0.4184 - val_accuracy: 0.8416\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5656 - accuracy: 0.7919 - val_loss: 0.4043 - val_accuracy: 0.8512\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5384 - accuracy: 0.8030 - val_loss: 0.3913 - val_accuracy: 0.8560\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5216 - accuracy: 0.8089 - val_loss: 0.3851 - val_accuracy: 0.8590\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5054 - accuracy: 0.8136 - val_loss: 0.3792 - val_accuracy: 0.8638\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4903 - accuracy: 0.8202 - val_loss: 0.3667 - val_accuracy: 0.8644\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4848 - accuracy: 0.8205 - val_loss: 0.3800 - val_accuracy: 0.8584\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4824 - accuracy: 0.8250 - val_loss: 0.3520 - val_accuracy: 0.8712\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4684 - accuracy: 0.8262 - val_loss: 0.3482 - val_accuracy: 0.8758\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4665 - accuracy: 0.8298 - val_loss: 0.3440 - val_accuracy: 0.8698\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4625 - accuracy: 0.8309 - val_loss: 0.3503 - val_accuracy: 0.8708\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4570 - accuracy: 0.8318 - val_loss: 0.3453 - val_accuracy: 0.8702\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4516 - accuracy: 0.8348 - val_loss: 0.3390 - val_accuracy: 0.8782\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4517 - accuracy: 0.8338 - val_loss: 0.3382 - val_accuracy: 0.8756\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4439 - accuracy: 0.8374 - val_loss: 0.3301 - val_accuracy: 0.8770\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4477 - accuracy: 0.8353 - val_loss: 0.3369 - val_accuracy: 0.8746\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4405 - accuracy: 0.8386 - val_loss: 0.3353 - val_accuracy: 0.8742\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4363 - accuracy: 0.8388 - val_loss: 0.3362 - val_accuracy: 0.8760\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4308 - accuracy: 0.8418 - val_loss: 0.3318 - val_accuracy: 0.8740\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4346 - accuracy: 0.8400 - val_loss: 0.3343 - val_accuracy: 0.8770\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4265 - accuracy: 0.8423 - val_loss: 0.3357 - val_accuracy: 0.8726\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4296 - accuracy: 0.8420 - val_loss: 0.3288 - val_accuracy: 0.8764\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4232 - accuracy: 0.8436 - val_loss: 0.3275 - val_accuracy: 0.8774\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4241 - accuracy: 0.8421 - val_loss: 0.3229 - val_accuracy: 0.8786\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4240 - accuracy: 0.8453 - val_loss: 0.3195 - val_accuracy: 0.8784\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4194 - accuracy: 0.8457 - val_loss: 0.3149 - val_accuracy: 0.8830\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4233 - accuracy: 0.8447 - val_loss: 0.3184 - val_accuracy: 0.8808\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4210 - accuracy: 0.8463 - val_loss: 0.3194 - val_accuracy: 0.8774\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4200 - accuracy: 0.8437 - val_loss: 0.3174 - val_accuracy: 0.8818\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4234 - accuracy: 0.8453 - val_loss: 0.3157 - val_accuracy: 0.8786\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4115 - accuracy: 0.8483 - val_loss: 0.3262 - val_accuracy: 0.8790\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4167 - accuracy: 0.8473 - val_loss: 0.3171 - val_accuracy: 0.8788\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4196 - accuracy: 0.8465 - val_loss: 0.3189 - val_accuracy: 0.8802\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4131 - accuracy: 0.8465 - val_loss: 0.3127 - val_accuracy: 0.8834\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4124 - accuracy: 0.8465 - val_loss: 0.3164 - val_accuracy: 0.8854\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4171 - accuracy: 0.8473 - val_loss: 0.3220 - val_accuracy: 0.8784\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4085 - accuracy: 0.8487 - val_loss: 0.3110 - val_accuracy: 0.8828\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4114 - accuracy: 0.8494 - val_loss: 0.3096 - val_accuracy: 0.8812\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4100 - accuracy: 0.8486 - val_loss: 0.3142 - val_accuracy: 0.8828\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4118 - accuracy: 0.8506 - val_loss: 0.3185 - val_accuracy: 0.8818\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4055 - accuracy: 0.8511 - val_loss: 0.3174 - val_accuracy: 0.8810\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4115 - accuracy: 0.8507 - val_loss: 0.3201 - val_accuracy: 0.8846\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4055 - accuracy: 0.8515 - val_loss: 0.3147 - val_accuracy: 0.8790\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4074 - accuracy: 0.8498 - val_loss: 0.3178 - val_accuracy: 0.8814\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4112 - accuracy: 0.8505 - val_loss: 0.3137 - val_accuracy: 0.8790\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4054 - accuracy: 0.8503 - val_loss: 0.3179 - val_accuracy: 0.8806\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4040 - accuracy: 0.8511 - val_loss: 0.3092 - val_accuracy: 0.8844\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4066 - accuracy: 0.8524 - val_loss: 0.3201 - val_accuracy: 0.8822\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4057 - accuracy: 0.8534 - val_loss: 0.3121 - val_accuracy: 0.8854\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4024 - accuracy: 0.8503 - val_loss: 0.3064 - val_accuracy: 0.8844\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4000 - accuracy: 0.8520 - val_loss: 0.3071 - val_accuracy: 0.8888\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4040 - accuracy: 0.8530 - val_loss: 0.3183 - val_accuracy: 0.8848\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4054 - accuracy: 0.8506 - val_loss: 0.3169 - val_accuracy: 0.8786\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3995 - accuracy: 0.8513 - val_loss: 0.3134 - val_accuracy: 0.8820\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3990 - accuracy: 0.8531 - val_loss: 0.3170 - val_accuracy: 0.8818\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4033 - accuracy: 0.8513 - val_loss: 0.3109 - val_accuracy: 0.8888\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3978 - accuracy: 0.8504 - val_loss: 0.3090 - val_accuracy: 0.8828\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.3996 - accuracy: 0.8530 - val_loss: 0.3112 - val_accuracy: 0.8876\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.3985 - accuracy: 0.8565 - val_loss: 0.3127 - val_accuracy: 0.8848\n",
      "Epoch 61/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4030 - accuracy: 0.8511 - val_loss: 0.3175 - val_accuracy: 0.8794\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.3187 - accuracy: 0.8833\n",
      "Building model with:\n",
      "Number of hidden layers: 2\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.0392 - accuracy: 0.6860 - val_loss: 0.4573 - val_accuracy: 0.8352\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6382 - accuracy: 0.7736 - val_loss: 0.4282 - val_accuracy: 0.8462\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5670 - accuracy: 0.7953 - val_loss: 0.3972 - val_accuracy: 0.8524\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5343 - accuracy: 0.8053 - val_loss: 0.3863 - val_accuracy: 0.8588\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.5168 - accuracy: 0.8122 - val_loss: 0.3782 - val_accuracy: 0.8584\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4984 - accuracy: 0.8166 - val_loss: 0.3823 - val_accuracy: 0.8560\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4864 - accuracy: 0.8245 - val_loss: 0.3601 - val_accuracy: 0.8642\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4816 - accuracy: 0.8240 - val_loss: 0.3594 - val_accuracy: 0.8638\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4758 - accuracy: 0.8262 - val_loss: 0.3623 - val_accuracy: 0.8642\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4715 - accuracy: 0.8281 - val_loss: 0.3583 - val_accuracy: 0.8676\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4615 - accuracy: 0.8321 - val_loss: 0.3542 - val_accuracy: 0.8676\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4581 - accuracy: 0.8325 - val_loss: 0.3480 - val_accuracy: 0.8708\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4557 - accuracy: 0.8319 - val_loss: 0.3355 - val_accuracy: 0.8726\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4494 - accuracy: 0.8365 - val_loss: 0.3385 - val_accuracy: 0.8748\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4453 - accuracy: 0.8353 - val_loss: 0.3408 - val_accuracy: 0.8712\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4466 - accuracy: 0.8381 - val_loss: 0.3356 - val_accuracy: 0.8736\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4431 - accuracy: 0.8372 - val_loss: 0.3315 - val_accuracy: 0.8726\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4372 - accuracy: 0.8402 - val_loss: 0.3280 - val_accuracy: 0.8742\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4354 - accuracy: 0.8377 - val_loss: 0.3342 - val_accuracy: 0.8698\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4303 - accuracy: 0.8404 - val_loss: 0.3364 - val_accuracy: 0.8710\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4297 - accuracy: 0.8407 - val_loss: 0.3306 - val_accuracy: 0.8742\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4273 - accuracy: 0.8442 - val_loss: 0.3274 - val_accuracy: 0.8738\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4296 - accuracy: 0.8451 - val_loss: 0.3340 - val_accuracy: 0.8740\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4298 - accuracy: 0.8411 - val_loss: 0.3295 - val_accuracy: 0.8708\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4269 - accuracy: 0.8438 - val_loss: 0.3241 - val_accuracy: 0.8736\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4232 - accuracy: 0.8451 - val_loss: 0.3190 - val_accuracy: 0.8784\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4222 - accuracy: 0.8460 - val_loss: 0.3198 - val_accuracy: 0.8784\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4253 - accuracy: 0.8453 - val_loss: 0.3166 - val_accuracy: 0.8826\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4168 - accuracy: 0.8468 - val_loss: 0.3214 - val_accuracy: 0.8802\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4186 - accuracy: 0.8469 - val_loss: 0.3122 - val_accuracy: 0.8830\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4130 - accuracy: 0.8478 - val_loss: 0.3153 - val_accuracy: 0.8798\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4132 - accuracy: 0.8479 - val_loss: 0.3130 - val_accuracy: 0.8814\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4154 - accuracy: 0.8468 - val_loss: 0.3125 - val_accuracy: 0.8798\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4089 - accuracy: 0.8492 - val_loss: 0.3170 - val_accuracy: 0.8768\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4102 - accuracy: 0.8501 - val_loss: 0.3153 - val_accuracy: 0.8798\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.4166 - accuracy: 0.8486 - val_loss: 0.3162 - val_accuracy: 0.8768\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4138 - accuracy: 0.8490 - val_loss: 0.3131 - val_accuracy: 0.8814\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4135 - accuracy: 0.8499 - val_loss: 0.3049 - val_accuracy: 0.8836\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4105 - accuracy: 0.8502 - val_loss: 0.3090 - val_accuracy: 0.8810\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4127 - accuracy: 0.8486 - val_loss: 0.3136 - val_accuracy: 0.8780\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4046 - accuracy: 0.8537 - val_loss: 0.3089 - val_accuracy: 0.8820\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4038 - accuracy: 0.8493 - val_loss: 0.3102 - val_accuracy: 0.8782\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4035 - accuracy: 0.8526 - val_loss: 0.3097 - val_accuracy: 0.8850\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4099 - accuracy: 0.8506 - val_loss: 0.3092 - val_accuracy: 0.8840\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4052 - accuracy: 0.8509 - val_loss: 0.3101 - val_accuracy: 0.8790\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4066 - accuracy: 0.8493 - val_loss: 0.3111 - val_accuracy: 0.8826\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4069 - accuracy: 0.8496 - val_loss: 0.3144 - val_accuracy: 0.8778\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4000 - accuracy: 0.8529 - val_loss: 0.3067 - val_accuracy: 0.8846\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.3206 - accuracy: 0.8814\n",
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 50\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1.5825 - accuracy: 0.5287 - val_loss: 0.5436 - val_accuracy: 0.8010\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.8516 - accuracy: 0.6908 - val_loss: 0.5028 - val_accuracy: 0.8110\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.7284 - accuracy: 0.7462 - val_loss: 0.4612 - val_accuracy: 0.8300\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6775 - accuracy: 0.7640 - val_loss: 0.4451 - val_accuracy: 0.8350\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6392 - accuracy: 0.7797 - val_loss: 0.4321 - val_accuracy: 0.8424\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.6163 - accuracy: 0.7878 - val_loss: 0.4278 - val_accuracy: 0.8414\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.6035 - accuracy: 0.7921 - val_loss: 0.4171 - val_accuracy: 0.8462\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5816 - accuracy: 0.7995 - val_loss: 0.4086 - val_accuracy: 0.8482\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5756 - accuracy: 0.8015 - val_loss: 0.4147 - val_accuracy: 0.8508\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5705 - accuracy: 0.8049 - val_loss: 0.4025 - val_accuracy: 0.8532\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5613 - accuracy: 0.8081 - val_loss: 0.3961 - val_accuracy: 0.8592\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5590 - accuracy: 0.8081 - val_loss: 0.3929 - val_accuracy: 0.8574\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5537 - accuracy: 0.8093 - val_loss: 0.3961 - val_accuracy: 0.8566\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5440 - accuracy: 0.8142 - val_loss: 0.3857 - val_accuracy: 0.8610\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5398 - accuracy: 0.8141 - val_loss: 0.3910 - val_accuracy: 0.8584\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5332 - accuracy: 0.8165 - val_loss: 0.3849 - val_accuracy: 0.8620\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5323 - accuracy: 0.8159 - val_loss: 0.3814 - val_accuracy: 0.8628\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5312 - accuracy: 0.8178 - val_loss: 0.3799 - val_accuracy: 0.8600\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5290 - accuracy: 0.8174 - val_loss: 0.3750 - val_accuracy: 0.8608\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5222 - accuracy: 0.8214 - val_loss: 0.3766 - val_accuracy: 0.8646\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5208 - accuracy: 0.8189 - val_loss: 0.3770 - val_accuracy: 0.8634\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5164 - accuracy: 0.8198 - val_loss: 0.3732 - val_accuracy: 0.8656\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5173 - accuracy: 0.8205 - val_loss: 0.3723 - val_accuracy: 0.8670\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5119 - accuracy: 0.8208 - val_loss: 0.3657 - val_accuracy: 0.8696\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5171 - accuracy: 0.8196 - val_loss: 0.3635 - val_accuracy: 0.8724\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5166 - accuracy: 0.8224 - val_loss: 0.3685 - val_accuracy: 0.8704\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5107 - accuracy: 0.8238 - val_loss: 0.3653 - val_accuracy: 0.8650\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5097 - accuracy: 0.8240 - val_loss: 0.3617 - val_accuracy: 0.8674\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5074 - accuracy: 0.8228 - val_loss: 0.3680 - val_accuracy: 0.8712\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5084 - accuracy: 0.8252 - val_loss: 0.3661 - val_accuracy: 0.8692\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5053 - accuracy: 0.8267 - val_loss: 0.3676 - val_accuracy: 0.8708\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5067 - accuracy: 0.8243 - val_loss: 0.3583 - val_accuracy: 0.8730\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5058 - accuracy: 0.8251 - val_loss: 0.3643 - val_accuracy: 0.8682\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5027 - accuracy: 0.8251 - val_loss: 0.3655 - val_accuracy: 0.8670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5016 - accuracy: 0.8280 - val_loss: 0.3652 - val_accuracy: 0.8664\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4984 - accuracy: 0.8264 - val_loss: 0.3554 - val_accuracy: 0.8718\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4986 - accuracy: 0.8247 - val_loss: 0.3603 - val_accuracy: 0.8692\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5006 - accuracy: 0.8273 - val_loss: 0.3551 - val_accuracy: 0.8744\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4985 - accuracy: 0.8268 - val_loss: 0.3514 - val_accuracy: 0.8756\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4978 - accuracy: 0.8265 - val_loss: 0.3571 - val_accuracy: 0.8734\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5016 - accuracy: 0.8281 - val_loss: 0.3531 - val_accuracy: 0.8738\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4953 - accuracy: 0.8300 - val_loss: 0.3562 - val_accuracy: 0.8672\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4960 - accuracy: 0.8271 - val_loss: 0.3494 - val_accuracy: 0.8736\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5010 - accuracy: 0.8275 - val_loss: 0.3569 - val_accuracy: 0.8712\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5010 - accuracy: 0.8272 - val_loss: 0.3535 - val_accuracy: 0.8734\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4949 - accuracy: 0.8285 - val_loss: 0.3526 - val_accuracy: 0.8692\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5039 - accuracy: 0.8244 - val_loss: 0.3503 - val_accuracy: 0.8766\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4957 - accuracy: 0.8277 - val_loss: 0.3514 - val_accuracy: 0.8734\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4915 - accuracy: 0.8301 - val_loss: 0.3573 - val_accuracy: 0.8692\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4880 - accuracy: 0.8309 - val_loss: 0.3505 - val_accuracy: 0.8782\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4901 - accuracy: 0.8308 - val_loss: 0.3528 - val_accuracy: 0.8762\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4983 - accuracy: 0.8281 - val_loss: 0.3481 - val_accuracy: 0.8764\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4882 - accuracy: 0.8307 - val_loss: 0.3508 - val_accuracy: 0.8740\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4937 - accuracy: 0.8310 - val_loss: 0.3476 - val_accuracy: 0.8774\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4918 - accuracy: 0.8301 - val_loss: 0.3510 - val_accuracy: 0.8742\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4938 - accuracy: 0.8286 - val_loss: 0.3518 - val_accuracy: 0.8722\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4880 - accuracy: 0.8308 - val_loss: 0.3500 - val_accuracy: 0.8774\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4896 - accuracy: 0.8319 - val_loss: 0.3477 - val_accuracy: 0.8770\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4857 - accuracy: 0.8330 - val_loss: 0.3490 - val_accuracy: 0.8794\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4892 - accuracy: 0.8307 - val_loss: 0.3505 - val_accuracy: 0.8734\n",
      "Epoch 61/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4914 - accuracy: 0.8298 - val_loss: 0.3419 - val_accuracy: 0.8804\n",
      "Epoch 62/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4867 - accuracy: 0.8308 - val_loss: 0.3506 - val_accuracy: 0.8734\n",
      "Epoch 63/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4875 - accuracy: 0.8307 - val_loss: 0.3535 - val_accuracy: 0.8720\n",
      "Epoch 64/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4871 - accuracy: 0.8320 - val_loss: 0.3470 - val_accuracy: 0.8768\n",
      "Epoch 65/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4844 - accuracy: 0.8336 - val_loss: 0.3463 - val_accuracy: 0.8766\n",
      "Epoch 66/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4939 - accuracy: 0.8298 - val_loss: 0.3459 - val_accuracy: 0.8798\n",
      "Epoch 67/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4857 - accuracy: 0.8320 - val_loss: 0.3533 - val_accuracy: 0.8730\n",
      "Epoch 68/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4907 - accuracy: 0.8308 - val_loss: 0.3582 - val_accuracy: 0.8732\n",
      "Epoch 69/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4903 - accuracy: 0.8333 - val_loss: 0.3485 - val_accuracy: 0.8744\n",
      "Epoch 70/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4855 - accuracy: 0.8309 - val_loss: 0.3497 - val_accuracy: 0.8766\n",
      "Epoch 71/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4851 - accuracy: 0.8331 - val_loss: 0.3517 - val_accuracy: 0.8730\n",
      "573/573 [==============================] - 1s 2ms/step - loss: 0.3678 - accuracy: 0.8665\n",
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 50\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1.6879 - accuracy: 0.5154 - val_loss: 0.5561 - val_accuracy: 0.7994\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.8538 - accuracy: 0.6915 - val_loss: 0.4958 - val_accuracy: 0.8208\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.7338 - accuracy: 0.7383 - val_loss: 0.4713 - val_accuracy: 0.8300\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.6790 - accuracy: 0.7610 - val_loss: 0.4551 - val_accuracy: 0.8330\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.6467 - accuracy: 0.7757 - val_loss: 0.4366 - val_accuracy: 0.8442\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.6262 - accuracy: 0.7798 - val_loss: 0.4279 - val_accuracy: 0.8520\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.6047 - accuracy: 0.7907 - val_loss: 0.4133 - val_accuracy: 0.8522\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5891 - accuracy: 0.7945 - val_loss: 0.4179 - val_accuracy: 0.8494\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5786 - accuracy: 0.7967 - val_loss: 0.4049 - val_accuracy: 0.8532\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5762 - accuracy: 0.7993 - val_loss: 0.3966 - val_accuracy: 0.8596\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5604 - accuracy: 0.8040 - val_loss: 0.3929 - val_accuracy: 0.8614\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5579 - accuracy: 0.8036 - val_loss: 0.3899 - val_accuracy: 0.8606\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5560 - accuracy: 0.8044 - val_loss: 0.3895 - val_accuracy: 0.8628\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5488 - accuracy: 0.8073 - val_loss: 0.3884 - val_accuracy: 0.8596\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5477 - accuracy: 0.8068 - val_loss: 0.3870 - val_accuracy: 0.8604\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5410 - accuracy: 0.8109 - val_loss: 0.3823 - val_accuracy: 0.8632\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5410 - accuracy: 0.8092 - val_loss: 0.3862 - val_accuracy: 0.8632\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5283 - accuracy: 0.8148 - val_loss: 0.3832 - val_accuracy: 0.8586\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5316 - accuracy: 0.8135 - val_loss: 0.3877 - val_accuracy: 0.8608\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5266 - accuracy: 0.8144 - val_loss: 0.3752 - val_accuracy: 0.8620\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5245 - accuracy: 0.8178 - val_loss: 0.3818 - val_accuracy: 0.8626\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5239 - accuracy: 0.8204 - val_loss: 0.3752 - val_accuracy: 0.8656\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5248 - accuracy: 0.8166 - val_loss: 0.3713 - val_accuracy: 0.8638\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5224 - accuracy: 0.8164 - val_loss: 0.3696 - val_accuracy: 0.8698\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5202 - accuracy: 0.8180 - val_loss: 0.3643 - val_accuracy: 0.8698\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5148 - accuracy: 0.8181 - val_loss: 0.3659 - val_accuracy: 0.8638\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5135 - accuracy: 0.8183 - val_loss: 0.3671 - val_accuracy: 0.8682\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5152 - accuracy: 0.8207 - val_loss: 0.3704 - val_accuracy: 0.8642\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5142 - accuracy: 0.8209 - val_loss: 0.3684 - val_accuracy: 0.8678\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5144 - accuracy: 0.8195 - val_loss: 0.3663 - val_accuracy: 0.8664\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5105 - accuracy: 0.8226 - val_loss: 0.3631 - val_accuracy: 0.8678\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5068 - accuracy: 0.8228 - val_loss: 0.3790 - val_accuracy: 0.8650\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5122 - accuracy: 0.8222 - val_loss: 0.3682 - val_accuracy: 0.8644\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5135 - accuracy: 0.8210 - val_loss: 0.3625 - val_accuracy: 0.8654\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5097 - accuracy: 0.8231 - val_loss: 0.3601 - val_accuracy: 0.8670\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5059 - accuracy: 0.8237 - val_loss: 0.3573 - val_accuracy: 0.8692\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5043 - accuracy: 0.8226 - val_loss: 0.3674 - val_accuracy: 0.8642\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5081 - accuracy: 0.8205 - val_loss: 0.3561 - val_accuracy: 0.8688\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5042 - accuracy: 0.8252 - val_loss: 0.3600 - val_accuracy: 0.8660\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5028 - accuracy: 0.8241 - val_loss: 0.3536 - val_accuracy: 0.8714\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4973 - accuracy: 0.8267 - val_loss: 0.3575 - val_accuracy: 0.8658\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4997 - accuracy: 0.8256 - val_loss: 0.3591 - val_accuracy: 0.8674\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5034 - accuracy: 0.8238 - val_loss: 0.3525 - val_accuracy: 0.8732\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5023 - accuracy: 0.8244 - val_loss: 0.3557 - val_accuracy: 0.8676\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4999 - accuracy: 0.8250 - val_loss: 0.3593 - val_accuracy: 0.8662\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5064 - accuracy: 0.8259 - val_loss: 0.3629 - val_accuracy: 0.8680\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4986 - accuracy: 0.8255 - val_loss: 0.3494 - val_accuracy: 0.8706\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5052 - accuracy: 0.8246 - val_loss: 0.3569 - val_accuracy: 0.8686\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5002 - accuracy: 0.8250 - val_loss: 0.3534 - val_accuracy: 0.8698\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4956 - accuracy: 0.8262 - val_loss: 0.3585 - val_accuracy: 0.8696\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5002 - accuracy: 0.8260 - val_loss: 0.3516 - val_accuracy: 0.8692\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4988 - accuracy: 0.8251 - val_loss: 0.3492 - val_accuracy: 0.8704\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4966 - accuracy: 0.8273 - val_loss: 0.3512 - val_accuracy: 0.8732\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4981 - accuracy: 0.8274 - val_loss: 0.3566 - val_accuracy: 0.8708\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4952 - accuracy: 0.8267 - val_loss: 0.3507 - val_accuracy: 0.8716\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4892 - accuracy: 0.8294 - val_loss: 0.3625 - val_accuracy: 0.8690\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4988 - accuracy: 0.8250 - val_loss: 0.3494 - val_accuracy: 0.8716\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4977 - accuracy: 0.8263 - val_loss: 0.3466 - val_accuracy: 0.8738\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4939 - accuracy: 0.8274 - val_loss: 0.3498 - val_accuracy: 0.8748\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4938 - accuracy: 0.8289 - val_loss: 0.3456 - val_accuracy: 0.8712\n",
      "Epoch 61/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4962 - accuracy: 0.8261 - val_loss: 0.3534 - val_accuracy: 0.8680\n",
      "Epoch 62/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4932 - accuracy: 0.8279 - val_loss: 0.3532 - val_accuracy: 0.8702\n",
      "Epoch 63/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5000 - accuracy: 0.8270 - val_loss: 0.3530 - val_accuracy: 0.8716\n",
      "Epoch 64/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4926 - accuracy: 0.8269 - val_loss: 0.3540 - val_accuracy: 0.8724\n",
      "Epoch 65/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4913 - accuracy: 0.8273 - val_loss: 0.3484 - val_accuracy: 0.8736\n",
      "Epoch 66/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4910 - accuracy: 0.8282 - val_loss: 0.3532 - val_accuracy: 0.8718\n",
      "Epoch 67/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4909 - accuracy: 0.8300 - val_loss: 0.3505 - val_accuracy: 0.8706\n",
      "Epoch 68/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4901 - accuracy: 0.8280 - val_loss: 0.3522 - val_accuracy: 0.8732\n",
      "Epoch 69/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4892 - accuracy: 0.8300 - val_loss: 0.3549 - val_accuracy: 0.8696\n",
      "Epoch 70/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4869 - accuracy: 0.8300 - val_loss: 0.3453 - val_accuracy: 0.8714\n",
      "Epoch 71/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4931 - accuracy: 0.8277 - val_loss: 0.3484 - val_accuracy: 0.8734\n",
      "Epoch 72/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4919 - accuracy: 0.8273 - val_loss: 0.3437 - val_accuracy: 0.8754\n",
      "Epoch 73/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4915 - accuracy: 0.8300 - val_loss: 0.3457 - val_accuracy: 0.8758\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4936 - accuracy: 0.8270 - val_loss: 0.3479 - val_accuracy: 0.8720\n",
      "Epoch 75/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4983 - accuracy: 0.8254 - val_loss: 0.3460 - val_accuracy: 0.8734\n",
      "Epoch 76/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4890 - accuracy: 0.8290 - val_loss: 0.3493 - val_accuracy: 0.8726\n",
      "Epoch 77/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4884 - accuracy: 0.8297 - val_loss: 0.3456 - val_accuracy: 0.8740\n",
      "Epoch 78/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4887 - accuracy: 0.8279 - val_loss: 0.3520 - val_accuracy: 0.8722\n",
      "Epoch 79/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4901 - accuracy: 0.8311 - val_loss: 0.3467 - val_accuracy: 0.8744\n",
      "Epoch 80/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4886 - accuracy: 0.8303 - val_loss: 0.3487 - val_accuracy: 0.8708\n",
      "Epoch 81/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4847 - accuracy: 0.8306 - val_loss: 0.3465 - val_accuracy: 0.8728\n",
      "Epoch 82/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4939 - accuracy: 0.8276 - val_loss: 0.3524 - val_accuracy: 0.8708\n",
      "573/573 [==============================] - 1s 2ms/step - loss: 0.3547 - accuracy: 0.8724\n",
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 50\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1.5703 - accuracy: 0.5274 - val_loss: 0.5471 - val_accuracy: 0.7988\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.8391 - accuracy: 0.7020 - val_loss: 0.4858 - val_accuracy: 0.8226\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.7297 - accuracy: 0.7375 - val_loss: 0.4545 - val_accuracy: 0.8362\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6729 - accuracy: 0.7656 - val_loss: 0.4402 - val_accuracy: 0.8426\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.6406 - accuracy: 0.7742 - val_loss: 0.4257 - val_accuracy: 0.8472\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6162 - accuracy: 0.7852 - val_loss: 0.4252 - val_accuracy: 0.8414\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5955 - accuracy: 0.7931 - val_loss: 0.4092 - val_accuracy: 0.8506\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5838 - accuracy: 0.7942 - val_loss: 0.4059 - val_accuracy: 0.8524\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5760 - accuracy: 0.8019 - val_loss: 0.4076 - val_accuracy: 0.8540\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5628 - accuracy: 0.8057 - val_loss: 0.3888 - val_accuracy: 0.8634\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5613 - accuracy: 0.8043 - val_loss: 0.3984 - val_accuracy: 0.8584\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5483 - accuracy: 0.8085 - val_loss: 0.3868 - val_accuracy: 0.8618\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5450 - accuracy: 0.8081 - val_loss: 0.3830 - val_accuracy: 0.8628\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5387 - accuracy: 0.8132 - val_loss: 0.3795 - val_accuracy: 0.8646\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5452 - accuracy: 0.8099 - val_loss: 0.3806 - val_accuracy: 0.8620\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5282 - accuracy: 0.8165 - val_loss: 0.3794 - val_accuracy: 0.8682\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5289 - accuracy: 0.8144 - val_loss: 0.3768 - val_accuracy: 0.8628\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5302 - accuracy: 0.8157 - val_loss: 0.3701 - val_accuracy: 0.8630\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5320 - accuracy: 0.8141 - val_loss: 0.3721 - val_accuracy: 0.8634\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5148 - accuracy: 0.8208 - val_loss: 0.3714 - val_accuracy: 0.8626\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5232 - accuracy: 0.8165 - val_loss: 0.3711 - val_accuracy: 0.8590\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5164 - accuracy: 0.8191 - val_loss: 0.3655 - val_accuracy: 0.8652\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5222 - accuracy: 0.8163 - val_loss: 0.3712 - val_accuracy: 0.8640\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5130 - accuracy: 0.8202 - val_loss: 0.3629 - val_accuracy: 0.8700\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5136 - accuracy: 0.8219 - val_loss: 0.3653 - val_accuracy: 0.8640\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5118 - accuracy: 0.8233 - val_loss: 0.3711 - val_accuracy: 0.8628\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5140 - accuracy: 0.8217 - val_loss: 0.3617 - val_accuracy: 0.8676\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5159 - accuracy: 0.8214 - val_loss: 0.3685 - val_accuracy: 0.8676\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5095 - accuracy: 0.8227 - val_loss: 0.3581 - val_accuracy: 0.8708\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5087 - accuracy: 0.8238 - val_loss: 0.3572 - val_accuracy: 0.8708\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5106 - accuracy: 0.8218 - val_loss: 0.3547 - val_accuracy: 0.8718\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5091 - accuracy: 0.8230 - val_loss: 0.3626 - val_accuracy: 0.8684\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5089 - accuracy: 0.8239 - val_loss: 0.3611 - val_accuracy: 0.8650\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5111 - accuracy: 0.8228 - val_loss: 0.3575 - val_accuracy: 0.8708\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5051 - accuracy: 0.8221 - val_loss: 0.3571 - val_accuracy: 0.8710\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5073 - accuracy: 0.8226 - val_loss: 0.3548 - val_accuracy: 0.8722\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5081 - accuracy: 0.8230 - val_loss: 0.3597 - val_accuracy: 0.8692\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5030 - accuracy: 0.8261 - val_loss: 0.3522 - val_accuracy: 0.8706\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5057 - accuracy: 0.8228 - val_loss: 0.3568 - val_accuracy: 0.8658\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5018 - accuracy: 0.8247 - val_loss: 0.3589 - val_accuracy: 0.8700\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4995 - accuracy: 0.8264 - val_loss: 0.3608 - val_accuracy: 0.8704\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5023 - accuracy: 0.8234 - val_loss: 0.3580 - val_accuracy: 0.8694\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4991 - accuracy: 0.8266 - val_loss: 0.3545 - val_accuracy: 0.8718\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5034 - accuracy: 0.8270 - val_loss: 0.3564 - val_accuracy: 0.8694\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5044 - accuracy: 0.8250 - val_loss: 0.3567 - val_accuracy: 0.8696\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4966 - accuracy: 0.8285 - val_loss: 0.3586 - val_accuracy: 0.8672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4982 - accuracy: 0.8259 - val_loss: 0.3554 - val_accuracy: 0.8732\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5004 - accuracy: 0.8265 - val_loss: 0.3563 - val_accuracy: 0.8722\n",
      "573/573 [==============================] - 1s 2ms/step - loss: 0.3677 - accuracy: 0.8664\n",
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1.3887 - accuracy: 0.6060 - val_loss: 0.5055 - val_accuracy: 0.8160\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.7300 - accuracy: 0.7428 - val_loss: 0.4494 - val_accuracy: 0.8334\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.6331 - accuracy: 0.7741 - val_loss: 0.4365 - val_accuracy: 0.8442\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5920 - accuracy: 0.7907 - val_loss: 0.4140 - val_accuracy: 0.8490\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5667 - accuracy: 0.7995 - val_loss: 0.4085 - val_accuracy: 0.8502\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5431 - accuracy: 0.8090 - val_loss: 0.3942 - val_accuracy: 0.8578\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5297 - accuracy: 0.8114 - val_loss: 0.3896 - val_accuracy: 0.8586\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5230 - accuracy: 0.8153 - val_loss: 0.3845 - val_accuracy: 0.8598\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5124 - accuracy: 0.8196 - val_loss: 0.3775 - val_accuracy: 0.8656\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.5013 - accuracy: 0.8215 - val_loss: 0.3742 - val_accuracy: 0.8616\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4937 - accuracy: 0.8238 - val_loss: 0.3747 - val_accuracy: 0.8632\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4928 - accuracy: 0.8243 - val_loss: 0.3661 - val_accuracy: 0.8644\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4862 - accuracy: 0.8267 - val_loss: 0.3636 - val_accuracy: 0.8658\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4754 - accuracy: 0.8315 - val_loss: 0.3598 - val_accuracy: 0.8702\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4752 - accuracy: 0.8305 - val_loss: 0.3551 - val_accuracy: 0.8662\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4707 - accuracy: 0.8325 - val_loss: 0.3564 - val_accuracy: 0.8634\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4651 - accuracy: 0.8339 - val_loss: 0.3478 - val_accuracy: 0.8708\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4593 - accuracy: 0.8361 - val_loss: 0.3477 - val_accuracy: 0.8726\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4597 - accuracy: 0.8350 - val_loss: 0.3479 - val_accuracy: 0.8734\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4565 - accuracy: 0.8366 - val_loss: 0.3430 - val_accuracy: 0.8738\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4523 - accuracy: 0.8400 - val_loss: 0.3445 - val_accuracy: 0.8714\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4514 - accuracy: 0.8374 - val_loss: 0.3410 - val_accuracy: 0.8778\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4494 - accuracy: 0.8420 - val_loss: 0.3458 - val_accuracy: 0.8754\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4482 - accuracy: 0.8425 - val_loss: 0.3338 - val_accuracy: 0.8766\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4459 - accuracy: 0.8410 - val_loss: 0.3447 - val_accuracy: 0.8738\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4444 - accuracy: 0.8435 - val_loss: 0.3405 - val_accuracy: 0.8752\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4405 - accuracy: 0.8412 - val_loss: 0.3379 - val_accuracy: 0.8728\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4377 - accuracy: 0.8466 - val_loss: 0.3256 - val_accuracy: 0.8778\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4352 - accuracy: 0.8444 - val_loss: 0.3312 - val_accuracy: 0.8790\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4381 - accuracy: 0.8440 - val_loss: 0.3279 - val_accuracy: 0.8808\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4345 - accuracy: 0.8442 - val_loss: 0.3303 - val_accuracy: 0.8844\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4349 - accuracy: 0.8428 - val_loss: 0.3268 - val_accuracy: 0.8804\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4343 - accuracy: 0.8433 - val_loss: 0.3334 - val_accuracy: 0.8754\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4314 - accuracy: 0.8461 - val_loss: 0.3258 - val_accuracy: 0.8770\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4332 - accuracy: 0.8451 - val_loss: 0.3283 - val_accuracy: 0.8796\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4285 - accuracy: 0.8475 - val_loss: 0.3221 - val_accuracy: 0.8812\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4312 - accuracy: 0.8475 - val_loss: 0.3352 - val_accuracy: 0.8772\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4288 - accuracy: 0.8489 - val_loss: 0.3251 - val_accuracy: 0.8820\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4248 - accuracy: 0.8474 - val_loss: 0.3220 - val_accuracy: 0.8828\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4216 - accuracy: 0.8487 - val_loss: 0.3327 - val_accuracy: 0.8792\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4268 - accuracy: 0.8489 - val_loss: 0.3253 - val_accuracy: 0.8870\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4212 - accuracy: 0.8488 - val_loss: 0.3273 - val_accuracy: 0.8782\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4208 - accuracy: 0.8494 - val_loss: 0.3321 - val_accuracy: 0.8752\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4242 - accuracy: 0.8493 - val_loss: 0.3285 - val_accuracy: 0.8770\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4192 - accuracy: 0.8497 - val_loss: 0.3187 - val_accuracy: 0.8826\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4200 - accuracy: 0.8510 - val_loss: 0.3242 - val_accuracy: 0.8770\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4194 - accuracy: 0.8510 - val_loss: 0.3228 - val_accuracy: 0.8836\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4222 - accuracy: 0.8507 - val_loss: 0.3191 - val_accuracy: 0.8804\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4226 - accuracy: 0.8490 - val_loss: 0.3218 - val_accuracy: 0.8804\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4197 - accuracy: 0.8504 - val_loss: 0.3147 - val_accuracy: 0.8844\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4130 - accuracy: 0.8531 - val_loss: 0.3157 - val_accuracy: 0.8854\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4175 - accuracy: 0.8529 - val_loss: 0.3235 - val_accuracy: 0.8794\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.4236 - accuracy: 0.8488 - val_loss: 0.3227 - val_accuracy: 0.8818\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4177 - accuracy: 0.8503 - val_loss: 0.3220 - val_accuracy: 0.8834\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4135 - accuracy: 0.8511 - val_loss: 0.3271 - val_accuracy: 0.8766\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4194 - accuracy: 0.8509 - val_loss: 0.3248 - val_accuracy: 0.8780\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4149 - accuracy: 0.8523 - val_loss: 0.3164 - val_accuracy: 0.8834\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4130 - accuracy: 0.8528 - val_loss: 0.3237 - val_accuracy: 0.8808\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4130 - accuracy: 0.8517 - val_loss: 0.3173 - val_accuracy: 0.8816\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4181 - accuracy: 0.8508 - val_loss: 0.3137 - val_accuracy: 0.8860\n",
      "Epoch 61/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4133 - accuracy: 0.8529 - val_loss: 0.3157 - val_accuracy: 0.8856\n",
      "Epoch 62/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4187 - accuracy: 0.8519 - val_loss: 0.3143 - val_accuracy: 0.8858\n",
      "Epoch 63/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4113 - accuracy: 0.8535 - val_loss: 0.3194 - val_accuracy: 0.8836\n",
      "Epoch 64/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4105 - accuracy: 0.8540 - val_loss: 0.3128 - val_accuracy: 0.8838\n",
      "Epoch 65/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4107 - accuracy: 0.8535 - val_loss: 0.3226 - val_accuracy: 0.8830\n",
      "Epoch 66/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4135 - accuracy: 0.8538 - val_loss: 0.3158 - val_accuracy: 0.8828\n",
      "Epoch 67/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4047 - accuracy: 0.8550 - val_loss: 0.3184 - val_accuracy: 0.8812\n",
      "Epoch 68/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4091 - accuracy: 0.8542 - val_loss: 0.3154 - val_accuracy: 0.8846\n",
      "Epoch 69/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4105 - accuracy: 0.8542 - val_loss: 0.3196 - val_accuracy: 0.8826\n",
      "Epoch 70/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4124 - accuracy: 0.8532 - val_loss: 0.3197 - val_accuracy: 0.8818\n",
      "Epoch 71/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4098 - accuracy: 0.8548 - val_loss: 0.3206 - val_accuracy: 0.8782\n",
      "Epoch 72/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4095 - accuracy: 0.8537 - val_loss: 0.3143 - val_accuracy: 0.8816\n",
      "Epoch 73/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4098 - accuracy: 0.8539 - val_loss: 0.3126 - val_accuracy: 0.8838\n",
      "Epoch 74/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4084 - accuracy: 0.8555 - val_loss: 0.3139 - val_accuracy: 0.8808\n",
      "Epoch 75/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4041 - accuracy: 0.8566 - val_loss: 0.3124 - val_accuracy: 0.8842\n",
      "Epoch 76/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4106 - accuracy: 0.8568 - val_loss: 0.3168 - val_accuracy: 0.8832\n",
      "Epoch 77/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4070 - accuracy: 0.8527 - val_loss: 0.3032 - val_accuracy: 0.8866\n",
      "Epoch 78/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4164 - accuracy: 0.8531 - val_loss: 0.3126 - val_accuracy: 0.8824\n",
      "Epoch 79/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4043 - accuracy: 0.8577 - val_loss: 0.3141 - val_accuracy: 0.8824\n",
      "Epoch 80/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4043 - accuracy: 0.8567 - val_loss: 0.3142 - val_accuracy: 0.8802\n",
      "Epoch 81/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4072 - accuracy: 0.8583 - val_loss: 0.3209 - val_accuracy: 0.8770\n",
      "Epoch 82/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4061 - accuracy: 0.8547 - val_loss: 0.3194 - val_accuracy: 0.8802\n",
      "Epoch 83/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4032 - accuracy: 0.8571 - val_loss: 0.3082 - val_accuracy: 0.8854\n",
      "Epoch 84/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4035 - accuracy: 0.8566 - val_loss: 0.3191 - val_accuracy: 0.8838\n",
      "Epoch 85/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4017 - accuracy: 0.8579 - val_loss: 0.3207 - val_accuracy: 0.8748\n",
      "Epoch 86/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4035 - accuracy: 0.8572 - val_loss: 0.3110 - val_accuracy: 0.8844\n",
      "Epoch 87/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4056 - accuracy: 0.8580 - val_loss: 0.3077 - val_accuracy: 0.8834\n",
      "573/573 [==============================] - 1s 2ms/step - loss: 0.3201 - accuracy: 0.8856\n",
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 1.3870 - accuracy: 0.6034 - val_loss: 0.4995 - val_accuracy: 0.8266\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.7262 - accuracy: 0.7379 - val_loss: 0.4426 - val_accuracy: 0.8418\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.6335 - accuracy: 0.7705 - val_loss: 0.4246 - val_accuracy: 0.8482\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5950 - accuracy: 0.7859 - val_loss: 0.4097 - val_accuracy: 0.8462\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5721 - accuracy: 0.7949 - val_loss: 0.4061 - val_accuracy: 0.8564\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5535 - accuracy: 0.8012 - val_loss: 0.4032 - val_accuracy: 0.8530\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5321 - accuracy: 0.8081 - val_loss: 0.3824 - val_accuracy: 0.8614\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5280 - accuracy: 0.8099 - val_loss: 0.3787 - val_accuracy: 0.8638\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5180 - accuracy: 0.8153 - val_loss: 0.3710 - val_accuracy: 0.8648\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.5091 - accuracy: 0.8166 - val_loss: 0.3696 - val_accuracy: 0.8672\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4970 - accuracy: 0.8204 - val_loss: 0.3583 - val_accuracy: 0.8706\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4972 - accuracy: 0.8226 - val_loss: 0.3695 - val_accuracy: 0.8648\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4884 - accuracy: 0.8264 - val_loss: 0.3703 - val_accuracy: 0.8660\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4819 - accuracy: 0.8278 - val_loss: 0.3543 - val_accuracy: 0.8744\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4775 - accuracy: 0.8273 - val_loss: 0.3562 - val_accuracy: 0.8692\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4727 - accuracy: 0.8303 - val_loss: 0.3538 - val_accuracy: 0.8726\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4697 - accuracy: 0.8328 - val_loss: 0.3499 - val_accuracy: 0.8722\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4612 - accuracy: 0.8356 - val_loss: 0.3520 - val_accuracy: 0.8720\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4646 - accuracy: 0.8334 - val_loss: 0.3557 - val_accuracy: 0.8754\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4539 - accuracy: 0.8370 - val_loss: 0.3482 - val_accuracy: 0.8704\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4552 - accuracy: 0.8362 - val_loss: 0.3453 - val_accuracy: 0.8696\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4487 - accuracy: 0.8388 - val_loss: 0.3522 - val_accuracy: 0.8704\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4520 - accuracy: 0.8384 - val_loss: 0.3424 - val_accuracy: 0.8770\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4458 - accuracy: 0.8384 - val_loss: 0.3433 - val_accuracy: 0.8750\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4421 - accuracy: 0.8391 - val_loss: 0.3325 - val_accuracy: 0.8774\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4430 - accuracy: 0.8394 - val_loss: 0.3374 - val_accuracy: 0.8788\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4473 - accuracy: 0.8411 - val_loss: 0.3314 - val_accuracy: 0.8768\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4477 - accuracy: 0.8397 - val_loss: 0.3332 - val_accuracy: 0.8772\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4438 - accuracy: 0.8397 - val_loss: 0.3298 - val_accuracy: 0.8788\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4377 - accuracy: 0.8418 - val_loss: 0.3300 - val_accuracy: 0.8822\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4378 - accuracy: 0.8420 - val_loss: 0.3242 - val_accuracy: 0.8832\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4344 - accuracy: 0.8448 - val_loss: 0.3286 - val_accuracy: 0.8804\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4363 - accuracy: 0.8447 - val_loss: 0.3305 - val_accuracy: 0.8742\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4308 - accuracy: 0.8442 - val_loss: 0.3245 - val_accuracy: 0.8770\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4309 - accuracy: 0.8458 - val_loss: 0.3216 - val_accuracy: 0.8832\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4342 - accuracy: 0.8452 - val_loss: 0.3304 - val_accuracy: 0.8792\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4317 - accuracy: 0.8450 - val_loss: 0.3243 - val_accuracy: 0.8790\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4278 - accuracy: 0.8458 - val_loss: 0.3218 - val_accuracy: 0.8826\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4258 - accuracy: 0.8475 - val_loss: 0.3201 - val_accuracy: 0.8812\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4280 - accuracy: 0.8439 - val_loss: 0.3261 - val_accuracy: 0.8792\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4278 - accuracy: 0.8474 - val_loss: 0.3255 - val_accuracy: 0.8762\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4263 - accuracy: 0.8473 - val_loss: 0.3238 - val_accuracy: 0.8810\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4267 - accuracy: 0.8475 - val_loss: 0.3199 - val_accuracy: 0.8858\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4219 - accuracy: 0.8501 - val_loss: 0.3278 - val_accuracy: 0.8814\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4253 - accuracy: 0.8473 - val_loss: 0.3202 - val_accuracy: 0.8812\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.4270 - accuracy: 0.8484 - val_loss: 0.3205 - val_accuracy: 0.8814\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4233 - accuracy: 0.8492 - val_loss: 0.3234 - val_accuracy: 0.8828\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4193 - accuracy: 0.8507 - val_loss: 0.3255 - val_accuracy: 0.8824\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4249 - accuracy: 0.8468 - val_loss: 0.3228 - val_accuracy: 0.8842\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4200 - accuracy: 0.8513 - val_loss: 0.3246 - val_accuracy: 0.8782\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4184 - accuracy: 0.8497 - val_loss: 0.3135 - val_accuracy: 0.8840\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4139 - accuracy: 0.8532 - val_loss: 0.3280 - val_accuracy: 0.8750\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.4219 - accuracy: 0.8489 - val_loss: 0.3235 - val_accuracy: 0.8876\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4130 - accuracy: 0.8510 - val_loss: 0.3152 - val_accuracy: 0.8850\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4164 - accuracy: 0.8528 - val_loss: 0.3169 - val_accuracy: 0.8838\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4178 - accuracy: 0.8512 - val_loss: 0.3262 - val_accuracy: 0.8838\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4155 - accuracy: 0.8514 - val_loss: 0.3180 - val_accuracy: 0.8864\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4173 - accuracy: 0.8506 - val_loss: 0.3147 - val_accuracy: 0.8838\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4163 - accuracy: 0.8514 - val_loss: 0.3144 - val_accuracy: 0.8872\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4169 - accuracy: 0.8517 - val_loss: 0.3184 - val_accuracy: 0.8838\n",
      "Epoch 61/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4137 - accuracy: 0.8522 - val_loss: 0.3151 - val_accuracy: 0.8822\n",
      "573/573 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8834\n",
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 1.4121 - accuracy: 0.6018 - val_loss: 0.5048 - val_accuracy: 0.8132\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.7365 - accuracy: 0.7365 - val_loss: 0.4639 - val_accuracy: 0.8250\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.6386 - accuracy: 0.7721 - val_loss: 0.4289 - val_accuracy: 0.8416\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5920 - accuracy: 0.7901 - val_loss: 0.4145 - val_accuracy: 0.8400\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5638 - accuracy: 0.7994 - val_loss: 0.4056 - val_accuracy: 0.8440\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5499 - accuracy: 0.8031 - val_loss: 0.3946 - val_accuracy: 0.8512\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5325 - accuracy: 0.8086 - val_loss: 0.3771 - val_accuracy: 0.8596\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5176 - accuracy: 0.8117 - val_loss: 0.3810 - val_accuracy: 0.8586\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5090 - accuracy: 0.8170 - val_loss: 0.3748 - val_accuracy: 0.8604\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5051 - accuracy: 0.8200 - val_loss: 0.3753 - val_accuracy: 0.8670\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4984 - accuracy: 0.8225 - val_loss: 0.3663 - val_accuracy: 0.8618\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4905 - accuracy: 0.8235 - val_loss: 0.3640 - val_accuracy: 0.8662\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4922 - accuracy: 0.8264 - val_loss: 0.3597 - val_accuracy: 0.8660\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4743 - accuracy: 0.8293 - val_loss: 0.3553 - val_accuracy: 0.8714\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4753 - accuracy: 0.8295 - val_loss: 0.3610 - val_accuracy: 0.8644\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4717 - accuracy: 0.8313 - val_loss: 0.3495 - val_accuracy: 0.8692\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4708 - accuracy: 0.8330 - val_loss: 0.3543 - val_accuracy: 0.8696\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4645 - accuracy: 0.8317 - val_loss: 0.3432 - val_accuracy: 0.8704\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4593 - accuracy: 0.8356 - val_loss: 0.3508 - val_accuracy: 0.8734\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4579 - accuracy: 0.8368 - val_loss: 0.3458 - val_accuracy: 0.8706\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4502 - accuracy: 0.8407 - val_loss: 0.3496 - val_accuracy: 0.8690\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4564 - accuracy: 0.8380 - val_loss: 0.3423 - val_accuracy: 0.8702\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4520 - accuracy: 0.8383 - val_loss: 0.3416 - val_accuracy: 0.8704\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4474 - accuracy: 0.8401 - val_loss: 0.3369 - val_accuracy: 0.8702\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4465 - accuracy: 0.8417 - val_loss: 0.3286 - val_accuracy: 0.8752\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4436 - accuracy: 0.8428 - val_loss: 0.3375 - val_accuracy: 0.8730\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4387 - accuracy: 0.8444 - val_loss: 0.3314 - val_accuracy: 0.8746\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4436 - accuracy: 0.8409 - val_loss: 0.3309 - val_accuracy: 0.8752\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4425 - accuracy: 0.8416 - val_loss: 0.3256 - val_accuracy: 0.8792\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4354 - accuracy: 0.8456 - val_loss: 0.3261 - val_accuracy: 0.8786\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4370 - accuracy: 0.8443 - val_loss: 0.3205 - val_accuracy: 0.8800\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4311 - accuracy: 0.8479 - val_loss: 0.3285 - val_accuracy: 0.8778\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4356 - accuracy: 0.8460 - val_loss: 0.3334 - val_accuracy: 0.8762\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4336 - accuracy: 0.8437 - val_loss: 0.3218 - val_accuracy: 0.8810\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4346 - accuracy: 0.8458 - val_loss: 0.3243 - val_accuracy: 0.8776\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4329 - accuracy: 0.8455 - val_loss: 0.3273 - val_accuracy: 0.8796\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4308 - accuracy: 0.8436 - val_loss: 0.3237 - val_accuracy: 0.8768\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4250 - accuracy: 0.8469 - val_loss: 0.3189 - val_accuracy: 0.8824\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4243 - accuracy: 0.8473 - val_loss: 0.3215 - val_accuracy: 0.8776\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4268 - accuracy: 0.8470 - val_loss: 0.3241 - val_accuracy: 0.8778\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4220 - accuracy: 0.8489 - val_loss: 0.3256 - val_accuracy: 0.8774\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4198 - accuracy: 0.8519 - val_loss: 0.3182 - val_accuracy: 0.8810\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4272 - accuracy: 0.8488 - val_loss: 0.3172 - val_accuracy: 0.8836\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4256 - accuracy: 0.8475 - val_loss: 0.3137 - val_accuracy: 0.8834\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4258 - accuracy: 0.8490 - val_loss: 0.3259 - val_accuracy: 0.8760\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4224 - accuracy: 0.8498 - val_loss: 0.3205 - val_accuracy: 0.8802\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4203 - accuracy: 0.8497 - val_loss: 0.3284 - val_accuracy: 0.8790\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4249 - accuracy: 0.8484 - val_loss: 0.3175 - val_accuracy: 0.8824\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4195 - accuracy: 0.8497 - val_loss: 0.3183 - val_accuracy: 0.8790\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4239 - accuracy: 0.8510 - val_loss: 0.3185 - val_accuracy: 0.8802\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4175 - accuracy: 0.8520 - val_loss: 0.3190 - val_accuracy: 0.8816\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4168 - accuracy: 0.8513 - val_loss: 0.3167 - val_accuracy: 0.8868\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4171 - accuracy: 0.8515 - val_loss: 0.3210 - val_accuracy: 0.8818\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4172 - accuracy: 0.8507 - val_loss: 0.3159 - val_accuracy: 0.8770\n",
      "573/573 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8791\n",
      "Building model with:\n",
      "Number of hidden layers: 4\n",
      "Number of neurons per layer: 50\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 2.1839 - accuracy: 0.3868 - val_loss: 0.6791 - val_accuracy: 0.7226\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 1.0335 - accuracy: 0.6105 - val_loss: 0.5942 - val_accuracy: 0.7896\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.8688 - accuracy: 0.6831 - val_loss: 0.5439 - val_accuracy: 0.7960\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.7916 - accuracy: 0.7183 - val_loss: 0.5207 - val_accuracy: 0.8064\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.7338 - accuracy: 0.7452 - val_loss: 0.4809 - val_accuracy: 0.8292\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.6978 - accuracy: 0.7609 - val_loss: 0.4674 - val_accuracy: 0.8380\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.6685 - accuracy: 0.7752 - val_loss: 0.4546 - val_accuracy: 0.8414\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.6511 - accuracy: 0.7820 - val_loss: 0.4300 - val_accuracy: 0.8510\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.6349 - accuracy: 0.7870 - val_loss: 0.4348 - val_accuracy: 0.8454\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.6277 - accuracy: 0.7906 - val_loss: 0.4207 - val_accuracy: 0.8540\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.6127 - accuracy: 0.7950 - val_loss: 0.4270 - val_accuracy: 0.8492\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.6040 - accuracy: 0.8004 - val_loss: 0.4129 - val_accuracy: 0.8566\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5975 - accuracy: 0.7989 - val_loss: 0.4228 - val_accuracy: 0.8496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5929 - accuracy: 0.8008 - val_loss: 0.4058 - val_accuracy: 0.8610\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5870 - accuracy: 0.8056 - val_loss: 0.4203 - val_accuracy: 0.8464\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5798 - accuracy: 0.8065 - val_loss: 0.4061 - val_accuracy: 0.8570\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5791 - accuracy: 0.8064 - val_loss: 0.4055 - val_accuracy: 0.8590\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5697 - accuracy: 0.8095 - val_loss: 0.4036 - val_accuracy: 0.8588\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5673 - accuracy: 0.8102 - val_loss: 0.4030 - val_accuracy: 0.8578\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5658 - accuracy: 0.8093 - val_loss: 0.3989 - val_accuracy: 0.8616\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5606 - accuracy: 0.8123 - val_loss: 0.3945 - val_accuracy: 0.8604\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5570 - accuracy: 0.8120 - val_loss: 0.4021 - val_accuracy: 0.8574\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5565 - accuracy: 0.8111 - val_loss: 0.3948 - val_accuracy: 0.8614\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5545 - accuracy: 0.8132 - val_loss: 0.3877 - val_accuracy: 0.8658\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5522 - accuracy: 0.8163 - val_loss: 0.3866 - val_accuracy: 0.8658\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5501 - accuracy: 0.8166 - val_loss: 0.3870 - val_accuracy: 0.8614\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5471 - accuracy: 0.8171 - val_loss: 0.3863 - val_accuracy: 0.8612\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5459 - accuracy: 0.8162 - val_loss: 0.3874 - val_accuracy: 0.8598\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5461 - accuracy: 0.8184 - val_loss: 0.3857 - val_accuracy: 0.8658\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5447 - accuracy: 0.8164 - val_loss: 0.3854 - val_accuracy: 0.8634\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5425 - accuracy: 0.8180 - val_loss: 0.3811 - val_accuracy: 0.8682\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5421 - accuracy: 0.8171 - val_loss: 0.3754 - val_accuracy: 0.8642\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5406 - accuracy: 0.8191 - val_loss: 0.3908 - val_accuracy: 0.8580\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5399 - accuracy: 0.8196 - val_loss: 0.3848 - val_accuracy: 0.8654\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5334 - accuracy: 0.8222 - val_loss: 0.3826 - val_accuracy: 0.8624\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5370 - accuracy: 0.8199 - val_loss: 0.3863 - val_accuracy: 0.8622\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5364 - accuracy: 0.8219 - val_loss: 0.3716 - val_accuracy: 0.8686\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5338 - accuracy: 0.8215 - val_loss: 0.3769 - val_accuracy: 0.8714\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5365 - accuracy: 0.8213 - val_loss: 0.3699 - val_accuracy: 0.8666\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5302 - accuracy: 0.8220 - val_loss: 0.3740 - val_accuracy: 0.8680\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5277 - accuracy: 0.8232 - val_loss: 0.3714 - val_accuracy: 0.8692\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5287 - accuracy: 0.8214 - val_loss: 0.3769 - val_accuracy: 0.8660\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5319 - accuracy: 0.8238 - val_loss: 0.3671 - val_accuracy: 0.8706\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5325 - accuracy: 0.8200 - val_loss: 0.3749 - val_accuracy: 0.8678\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5281 - accuracy: 0.8246 - val_loss: 0.3757 - val_accuracy: 0.8690\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5279 - accuracy: 0.8244 - val_loss: 0.3736 - val_accuracy: 0.8630\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5282 - accuracy: 0.8226 - val_loss: 0.3691 - val_accuracy: 0.8694\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5277 - accuracy: 0.8218 - val_loss: 0.3741 - val_accuracy: 0.8642\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5234 - accuracy: 0.8261 - val_loss: 0.3696 - val_accuracy: 0.8654\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5250 - accuracy: 0.8258 - val_loss: 0.3720 - val_accuracy: 0.8648\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5196 - accuracy: 0.8252 - val_loss: 0.3612 - val_accuracy: 0.8748\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5268 - accuracy: 0.8271 - val_loss: 0.3627 - val_accuracy: 0.8730\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5260 - accuracy: 0.8240 - val_loss: 0.3686 - val_accuracy: 0.8696\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5293 - accuracy: 0.8224 - val_loss: 0.3620 - val_accuracy: 0.8706\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5177 - accuracy: 0.8265 - val_loss: 0.3762 - val_accuracy: 0.8674\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5308 - accuracy: 0.8224 - val_loss: 0.3785 - val_accuracy: 0.8634\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5205 - accuracy: 0.8255 - val_loss: 0.3681 - val_accuracy: 0.8720\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5184 - accuracy: 0.8259 - val_loss: 0.3703 - val_accuracy: 0.8692\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5173 - accuracy: 0.8267 - val_loss: 0.3683 - val_accuracy: 0.8712\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5222 - accuracy: 0.8252 - val_loss: 0.3671 - val_accuracy: 0.8708\n",
      "Epoch 61/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5215 - accuracy: 0.8256 - val_loss: 0.3616 - val_accuracy: 0.8742\n",
      "573/573 [==============================] - 1s 2ms/step - loss: 0.3776 - accuracy: 0.8630\n",
      "Building model with:\n",
      "Number of hidden layers: 4\n",
      "Number of neurons per layer: 50\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 2.1090 - accuracy: 0.3928 - val_loss: 0.6923 - val_accuracy: 0.7496\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 1.0239 - accuracy: 0.6124 - val_loss: 0.5908 - val_accuracy: 0.7866\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.8566 - accuracy: 0.6844 - val_loss: 0.5341 - val_accuracy: 0.8008\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.7693 - accuracy: 0.7250 - val_loss: 0.5015 - val_accuracy: 0.8096\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.7224 - accuracy: 0.7495 - val_loss: 0.4861 - val_accuracy: 0.8292\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.6905 - accuracy: 0.7632 - val_loss: 0.4677 - val_accuracy: 0.8354\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.6619 - accuracy: 0.7739 - val_loss: 0.4466 - val_accuracy: 0.8408\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.6373 - accuracy: 0.7832 - val_loss: 0.4451 - val_accuracy: 0.8428\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.6383 - accuracy: 0.7840 - val_loss: 0.4279 - val_accuracy: 0.8488\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 0.6204 - accuracy: 0.7903 - val_loss: 0.4205 - val_accuracy: 0.8452\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.6089 - accuracy: 0.7964 - val_loss: 0.4221 - val_accuracy: 0.8478\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.6058 - accuracy: 0.7938 - val_loss: 0.4167 - val_accuracy: 0.8520\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.6000 - accuracy: 0.7976 - val_loss: 0.4182 - val_accuracy: 0.8524\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5862 - accuracy: 0.8038 - val_loss: 0.4113 - val_accuracy: 0.8518\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5835 - accuracy: 0.8032 - val_loss: 0.4084 - val_accuracy: 0.8544\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5784 - accuracy: 0.8019 - val_loss: 0.3937 - val_accuracy: 0.8624\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.5732 - accuracy: 0.8061 - val_loss: 0.4050 - val_accuracy: 0.8516\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5716 - accuracy: 0.8033 - val_loss: 0.3949 - val_accuracy: 0.8570\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5662 - accuracy: 0.8101 - val_loss: 0.3961 - val_accuracy: 0.8612\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5596 - accuracy: 0.8098 - val_loss: 0.3971 - val_accuracy: 0.8540\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5612 - accuracy: 0.8112 - val_loss: 0.3975 - val_accuracy: 0.8548\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5597 - accuracy: 0.8091 - val_loss: 0.3948 - val_accuracy: 0.8554\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5557 - accuracy: 0.8120 - val_loss: 0.3895 - val_accuracy: 0.8586\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5547 - accuracy: 0.8112 - val_loss: 0.3869 - val_accuracy: 0.8610\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5533 - accuracy: 0.8105 - val_loss: 0.3821 - val_accuracy: 0.8626\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5526 - accuracy: 0.8146 - val_loss: 0.3898 - val_accuracy: 0.8608\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5538 - accuracy: 0.8135 - val_loss: 0.3854 - val_accuracy: 0.8606\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5525 - accuracy: 0.8127 - val_loss: 0.3915 - val_accuracy: 0.8620\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5449 - accuracy: 0.8185 - val_loss: 0.3839 - val_accuracy: 0.8604\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5466 - accuracy: 0.8153 - val_loss: 0.3829 - val_accuracy: 0.8640\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5429 - accuracy: 0.8158 - val_loss: 0.3863 - val_accuracy: 0.8628\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5315 - accuracy: 0.8202 - val_loss: 0.3862 - val_accuracy: 0.8674\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5429 - accuracy: 0.8161 - val_loss: 0.3873 - val_accuracy: 0.8590\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5399 - accuracy: 0.8160 - val_loss: 0.3785 - val_accuracy: 0.8638\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5414 - accuracy: 0.8170 - val_loss: 0.3798 - val_accuracy: 0.8626\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5364 - accuracy: 0.8187 - val_loss: 0.3759 - val_accuracy: 0.8686\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5391 - accuracy: 0.8177 - val_loss: 0.3852 - val_accuracy: 0.8658\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5384 - accuracy: 0.8192 - val_loss: 0.3795 - val_accuracy: 0.8664\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5384 - accuracy: 0.8181 - val_loss: 0.3793 - val_accuracy: 0.8666\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5342 - accuracy: 0.8195 - val_loss: 0.3759 - val_accuracy: 0.8674\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5313 - accuracy: 0.8194 - val_loss: 0.3872 - val_accuracy: 0.8620\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5276 - accuracy: 0.8194 - val_loss: 0.3796 - val_accuracy: 0.8668\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5420 - accuracy: 0.8176 - val_loss: 0.3796 - val_accuracy: 0.8698\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5356 - accuracy: 0.8195 - val_loss: 0.3819 - val_accuracy: 0.8658\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5319 - accuracy: 0.8185 - val_loss: 0.3803 - val_accuracy: 0.8634\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5334 - accuracy: 0.8207 - val_loss: 0.3740 - val_accuracy: 0.8692\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5265 - accuracy: 0.8206 - val_loss: 0.3711 - val_accuracy: 0.8702\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5313 - accuracy: 0.8216 - val_loss: 0.3792 - val_accuracy: 0.8634\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5300 - accuracy: 0.8200 - val_loss: 0.3792 - val_accuracy: 0.8632\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5309 - accuracy: 0.8206 - val_loss: 0.3801 - val_accuracy: 0.8632\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5346 - accuracy: 0.8219 - val_loss: 0.3685 - val_accuracy: 0.8678\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5285 - accuracy: 0.8209 - val_loss: 0.3705 - val_accuracy: 0.8690\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5311 - accuracy: 0.8226 - val_loss: 0.3763 - val_accuracy: 0.8660\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5336 - accuracy: 0.8204 - val_loss: 0.3776 - val_accuracy: 0.8632\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5301 - accuracy: 0.8213 - val_loss: 0.3675 - val_accuracy: 0.8722\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5303 - accuracy: 0.8219 - val_loss: 0.3838 - val_accuracy: 0.8680\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5254 - accuracy: 0.8217 - val_loss: 0.3677 - val_accuracy: 0.8688\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5346 - accuracy: 0.8217 - val_loss: 0.3665 - val_accuracy: 0.8706\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5182 - accuracy: 0.8241 - val_loss: 0.3661 - val_accuracy: 0.8720\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5214 - accuracy: 0.8236 - val_loss: 0.3727 - val_accuracy: 0.8692\n",
      "Epoch 61/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5214 - accuracy: 0.8223 - val_loss: 0.3732 - val_accuracy: 0.8674\n",
      "Epoch 62/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5237 - accuracy: 0.8268 - val_loss: 0.3788 - val_accuracy: 0.8670\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.5264 - accuracy: 0.8225 - val_loss: 0.3738 - val_accuracy: 0.8710\n",
      "Epoch 64/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5234 - accuracy: 0.8236 - val_loss: 0.3734 - val_accuracy: 0.8708\n",
      "Epoch 65/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5207 - accuracy: 0.8241 - val_loss: 0.3728 - val_accuracy: 0.8682\n",
      "Epoch 66/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5262 - accuracy: 0.8229 - val_loss: 0.3646 - val_accuracy: 0.8752\n",
      "Epoch 67/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5208 - accuracy: 0.8237 - val_loss: 0.3711 - val_accuracy: 0.8668\n",
      "Epoch 68/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5249 - accuracy: 0.8236 - val_loss: 0.3685 - val_accuracy: 0.8716\n",
      "Epoch 69/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5176 - accuracy: 0.8256 - val_loss: 0.3708 - val_accuracy: 0.8684\n",
      "Epoch 70/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5196 - accuracy: 0.8254 - val_loss: 0.3687 - val_accuracy: 0.8690\n",
      "Epoch 71/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5194 - accuracy: 0.8284 - val_loss: 0.3658 - val_accuracy: 0.8700\n",
      "Epoch 72/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5256 - accuracy: 0.8232 - val_loss: 0.3657 - val_accuracy: 0.8692\n",
      "Epoch 73/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5194 - accuracy: 0.8260 - val_loss: 0.3651 - val_accuracy: 0.8702\n",
      "Epoch 74/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5271 - accuracy: 0.8227 - val_loss: 0.3769 - val_accuracy: 0.8648\n",
      "Epoch 75/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5202 - accuracy: 0.8261 - val_loss: 0.3733 - val_accuracy: 0.8642\n",
      "Epoch 76/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5211 - accuracy: 0.8252 - val_loss: 0.3727 - val_accuracy: 0.8708\n",
      "573/573 [==============================] - 1s 2ms/step - loss: 0.3793 - accuracy: 0.8668\n",
      "Building model with:\n",
      "Number of hidden layers: 4\n",
      "Number of neurons per layer: 50\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 2.1271 - accuracy: 0.4030 - val_loss: 0.6644 - val_accuracy: 0.7656\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 1.0216 - accuracy: 0.6152 - val_loss: 0.5826 - val_accuracy: 0.7892\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.8471 - accuracy: 0.6890 - val_loss: 0.5366 - val_accuracy: 0.8080\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.7678 - accuracy: 0.7268 - val_loss: 0.4972 - val_accuracy: 0.8188\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.7211 - accuracy: 0.7473 - val_loss: 0.4783 - val_accuracy: 0.8272\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.6970 - accuracy: 0.7588 - val_loss: 0.4741 - val_accuracy: 0.8330\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.6611 - accuracy: 0.7716 - val_loss: 0.4541 - val_accuracy: 0.8372\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.6471 - accuracy: 0.7799 - val_loss: 0.4452 - val_accuracy: 0.8416\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.6375 - accuracy: 0.7839 - val_loss: 0.4360 - val_accuracy: 0.8452\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.6280 - accuracy: 0.7884 - val_loss: 0.4345 - val_accuracy: 0.8472\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.6126 - accuracy: 0.7931 - val_loss: 0.4317 - val_accuracy: 0.8440\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.6052 - accuracy: 0.7957 - val_loss: 0.4241 - val_accuracy: 0.8488\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.6009 - accuracy: 0.7967 - val_loss: 0.4162 - val_accuracy: 0.8494\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5918 - accuracy: 0.7997 - val_loss: 0.4140 - val_accuracy: 0.8548\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5890 - accuracy: 0.8005 - val_loss: 0.4138 - val_accuracy: 0.8500\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5790 - accuracy: 0.8048 - val_loss: 0.4135 - val_accuracy: 0.8578\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5826 - accuracy: 0.8030 - val_loss: 0.4150 - val_accuracy: 0.8536\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5726 - accuracy: 0.8038 - val_loss: 0.3930 - val_accuracy: 0.8574\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5697 - accuracy: 0.8052 - val_loss: 0.3993 - val_accuracy: 0.8602\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5635 - accuracy: 0.8081 - val_loss: 0.3943 - val_accuracy: 0.8564\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5665 - accuracy: 0.8093 - val_loss: 0.3919 - val_accuracy: 0.8596\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5605 - accuracy: 0.8124 - val_loss: 0.3882 - val_accuracy: 0.8592\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5641 - accuracy: 0.8105 - val_loss: 0.4012 - val_accuracy: 0.8522\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5548 - accuracy: 0.8116 - val_loss: 0.3839 - val_accuracy: 0.8648\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5584 - accuracy: 0.8121 - val_loss: 0.3878 - val_accuracy: 0.8638\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5548 - accuracy: 0.8126 - val_loss: 0.3810 - val_accuracy: 0.8650\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5582 - accuracy: 0.8121 - val_loss: 0.3865 - val_accuracy: 0.8610\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5483 - accuracy: 0.8146 - val_loss: 0.3869 - val_accuracy: 0.8656\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5486 - accuracy: 0.8162 - val_loss: 0.3876 - val_accuracy: 0.8654\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5443 - accuracy: 0.8174 - val_loss: 0.3844 - val_accuracy: 0.8648\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5454 - accuracy: 0.8151 - val_loss: 0.3760 - val_accuracy: 0.8672\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5473 - accuracy: 0.8164 - val_loss: 0.3834 - val_accuracy: 0.8646\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5447 - accuracy: 0.8149 - val_loss: 0.3835 - val_accuracy: 0.8614\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5402 - accuracy: 0.8153 - val_loss: 0.3769 - val_accuracy: 0.8650\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5409 - accuracy: 0.8180 - val_loss: 0.3851 - val_accuracy: 0.8646\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5450 - accuracy: 0.8150 - val_loss: 0.3728 - val_accuracy: 0.8644\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5402 - accuracy: 0.8165 - val_loss: 0.3733 - val_accuracy: 0.8680\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5338 - accuracy: 0.8177 - val_loss: 0.3675 - val_accuracy: 0.8662\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5347 - accuracy: 0.8185 - val_loss: 0.3695 - val_accuracy: 0.8690\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5373 - accuracy: 0.8180 - val_loss: 0.3721 - val_accuracy: 0.8686\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5328 - accuracy: 0.8199 - val_loss: 0.3723 - val_accuracy: 0.8684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5316 - accuracy: 0.8202 - val_loss: 0.3741 - val_accuracy: 0.8678\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5347 - accuracy: 0.8194 - val_loss: 0.3751 - val_accuracy: 0.8676\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5362 - accuracy: 0.8191 - val_loss: 0.3706 - val_accuracy: 0.8664\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5346 - accuracy: 0.8185 - val_loss: 0.3775 - val_accuracy: 0.8694\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5406 - accuracy: 0.8169 - val_loss: 0.3678 - val_accuracy: 0.8692\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5277 - accuracy: 0.8205 - val_loss: 0.3743 - val_accuracy: 0.8670\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5350 - accuracy: 0.8199 - val_loss: 0.3697 - val_accuracy: 0.8680\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.3864 - accuracy: 0.8627\n",
      "Building model with:\n",
      "Number of hidden layers: 4\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 1.8452 - accuracy: 0.5207 - val_loss: 0.5680 - val_accuracy: 0.7896\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.8459 - accuracy: 0.6971 - val_loss: 0.4988 - val_accuracy: 0.8146\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.7114 - accuracy: 0.7487 - val_loss: 0.4782 - val_accuracy: 0.8322\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.6526 - accuracy: 0.7732 - val_loss: 0.4527 - val_accuracy: 0.8364\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.6213 - accuracy: 0.7856 - val_loss: 0.4287 - val_accuracy: 0.8392\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5955 - accuracy: 0.7944 - val_loss: 0.4203 - val_accuracy: 0.8474\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.5804 - accuracy: 0.7991 - val_loss: 0.4069 - val_accuracy: 0.8512\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5570 - accuracy: 0.8073 - val_loss: 0.4042 - val_accuracy: 0.8538\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5450 - accuracy: 0.8097 - val_loss: 0.3997 - val_accuracy: 0.8584\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5427 - accuracy: 0.8113 - val_loss: 0.3940 - val_accuracy: 0.8616\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.5303 - accuracy: 0.8168 - val_loss: 0.3915 - val_accuracy: 0.8552\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5236 - accuracy: 0.8199 - val_loss: 0.3844 - val_accuracy: 0.8584\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5152 - accuracy: 0.8225 - val_loss: 0.3876 - val_accuracy: 0.8596\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5103 - accuracy: 0.8224 - val_loss: 0.3765 - val_accuracy: 0.8612\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5072 - accuracy: 0.8230 - val_loss: 0.3720 - val_accuracy: 0.8636\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4973 - accuracy: 0.8267 - val_loss: 0.3662 - val_accuracy: 0.8640\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 0.4965 - accuracy: 0.8292 - val_loss: 0.3698 - val_accuracy: 0.8676\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.4963 - accuracy: 0.8280 - val_loss: 0.3746 - val_accuracy: 0.8634\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.4871 - accuracy: 0.8305 - val_loss: 0.3650 - val_accuracy: 0.8738\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4821 - accuracy: 0.8307 - val_loss: 0.3599 - val_accuracy: 0.8680\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4815 - accuracy: 0.8338 - val_loss: 0.3600 - val_accuracy: 0.8646\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4765 - accuracy: 0.8340 - val_loss: 0.3534 - val_accuracy: 0.8702\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4751 - accuracy: 0.8351 - val_loss: 0.3486 - val_accuracy: 0.8752\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4736 - accuracy: 0.8339 - val_loss: 0.3473 - val_accuracy: 0.8742\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.4712 - accuracy: 0.8329 - val_loss: 0.3551 - val_accuracy: 0.8682\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4729 - accuracy: 0.8342 - val_loss: 0.3534 - val_accuracy: 0.8712\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.4705 - accuracy: 0.8362 - val_loss: 0.3503 - val_accuracy: 0.8714\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4634 - accuracy: 0.8390 - val_loss: 0.3516 - val_accuracy: 0.8714\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4608 - accuracy: 0.8389 - val_loss: 0.3447 - val_accuracy: 0.8754\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4600 - accuracy: 0.8403 - val_loss: 0.3475 - val_accuracy: 0.8754\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4563 - accuracy: 0.8402 - val_loss: 0.3408 - val_accuracy: 0.8794\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4587 - accuracy: 0.8419 - val_loss: 0.3348 - val_accuracy: 0.8780\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4533 - accuracy: 0.8423 - val_loss: 0.3491 - val_accuracy: 0.8684\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4554 - accuracy: 0.8412 - val_loss: 0.3410 - val_accuracy: 0.8716\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4565 - accuracy: 0.8403 - val_loss: 0.3471 - val_accuracy: 0.8758\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4510 - accuracy: 0.8455 - val_loss: 0.3390 - val_accuracy: 0.8808\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4583 - accuracy: 0.8422 - val_loss: 0.3446 - val_accuracy: 0.8750\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4497 - accuracy: 0.8432 - val_loss: 0.3371 - val_accuracy: 0.8786\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4551 - accuracy: 0.8421 - val_loss: 0.3384 - val_accuracy: 0.8758\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4498 - accuracy: 0.8408 - val_loss: 0.3372 - val_accuracy: 0.8822\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4457 - accuracy: 0.8443 - val_loss: 0.3356 - val_accuracy: 0.8850\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4512 - accuracy: 0.8423 - val_loss: 0.3407 - val_accuracy: 0.8742\n",
      "573/573 [==============================] - 1s 2ms/step - loss: 0.3503 - accuracy: 0.8731\n",
      "Building model with:\n",
      "Number of hidden layers: 4\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 1.8155 - accuracy: 0.5127 - val_loss: 0.5821 - val_accuracy: 0.7718\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.8431 - accuracy: 0.6930 - val_loss: 0.5118 - val_accuracy: 0.8016\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.7094 - accuracy: 0.7456 - val_loss: 0.4596 - val_accuracy: 0.8346\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.6629 - accuracy: 0.7703 - val_loss: 0.4514 - val_accuracy: 0.8294\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.6189 - accuracy: 0.7824 - val_loss: 0.4387 - val_accuracy: 0.8412\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5962 - accuracy: 0.7894 - val_loss: 0.4277 - val_accuracy: 0.8500\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 0.5758 - accuracy: 0.7975 - val_loss: 0.4134 - val_accuracy: 0.8502\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5699 - accuracy: 0.8002 - val_loss: 0.4118 - val_accuracy: 0.8504\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5590 - accuracy: 0.8054 - val_loss: 0.3939 - val_accuracy: 0.8606\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5428 - accuracy: 0.8091 - val_loss: 0.3881 - val_accuracy: 0.8612\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5375 - accuracy: 0.8112 - val_loss: 0.3844 - val_accuracy: 0.8608\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5299 - accuracy: 0.8158 - val_loss: 0.3785 - val_accuracy: 0.8646\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5278 - accuracy: 0.8163 - val_loss: 0.3739 - val_accuracy: 0.8666\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5126 - accuracy: 0.8207 - val_loss: 0.3761 - val_accuracy: 0.8654\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5098 - accuracy: 0.8204 - val_loss: 0.3783 - val_accuracy: 0.8612\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 0.5007 - accuracy: 0.8257 - val_loss: 0.3761 - val_accuracy: 0.8660\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.5037 - accuracy: 0.8237 - val_loss: 0.3682 - val_accuracy: 0.8700\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.4980 - accuracy: 0.8259 - val_loss: 0.3623 - val_accuracy: 0.8674\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4944 - accuracy: 0.8295 - val_loss: 0.3702 - val_accuracy: 0.8670\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.4897 - accuracy: 0.8296 - val_loss: 0.3624 - val_accuracy: 0.8692\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4838 - accuracy: 0.8329 - val_loss: 0.3688 - val_accuracy: 0.8666\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4846 - accuracy: 0.8289 - val_loss: 0.3632 - val_accuracy: 0.8708\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4823 - accuracy: 0.8315 - val_loss: 0.3593 - val_accuracy: 0.8676\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4782 - accuracy: 0.8312 - val_loss: 0.3609 - val_accuracy: 0.8694\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 0.4745 - accuracy: 0.8315 - val_loss: 0.3530 - val_accuracy: 0.8734\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4735 - accuracy: 0.8372 - val_loss: 0.3647 - val_accuracy: 0.8672\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4737 - accuracy: 0.8351 - val_loss: 0.3422 - val_accuracy: 0.8758\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4682 - accuracy: 0.8367 - val_loss: 0.3527 - val_accuracy: 0.8704\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4666 - accuracy: 0.8373 - val_loss: 0.3445 - val_accuracy: 0.8720\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4692 - accuracy: 0.8348 - val_loss: 0.3497 - val_accuracy: 0.8754\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4657 - accuracy: 0.8364 - val_loss: 0.3498 - val_accuracy: 0.8716\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4545 - accuracy: 0.8377 - val_loss: 0.3560 - val_accuracy: 0.8760\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4607 - accuracy: 0.8367 - val_loss: 0.3432 - val_accuracy: 0.8698\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4576 - accuracy: 0.8399 - val_loss: 0.3452 - val_accuracy: 0.8730\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4580 - accuracy: 0.8405 - val_loss: 0.3363 - val_accuracy: 0.8756\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4560 - accuracy: 0.8399 - val_loss: 0.3455 - val_accuracy: 0.8726\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4605 - accuracy: 0.8393 - val_loss: 0.3421 - val_accuracy: 0.8690\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4526 - accuracy: 0.8408 - val_loss: 0.3368 - val_accuracy: 0.8730\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4517 - accuracy: 0.8409 - val_loss: 0.3387 - val_accuracy: 0.8754\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4594 - accuracy: 0.8386 - val_loss: 0.3402 - val_accuracy: 0.8814\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4529 - accuracy: 0.8431 - val_loss: 0.3287 - val_accuracy: 0.8796\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4526 - accuracy: 0.8417 - val_loss: 0.3392 - val_accuracy: 0.8790\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.4527 - accuracy: 0.8420 - val_loss: 0.3367 - val_accuracy: 0.8736\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4509 - accuracy: 0.8429 - val_loss: 0.3358 - val_accuracy: 0.8762\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4525 - accuracy: 0.8403 - val_loss: 0.3370 - val_accuracy: 0.8724\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4520 - accuracy: 0.8427 - val_loss: 0.3362 - val_accuracy: 0.8758\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4490 - accuracy: 0.8466 - val_loss: 0.3382 - val_accuracy: 0.8776\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4492 - accuracy: 0.8448 - val_loss: 0.3358 - val_accuracy: 0.8774\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4501 - accuracy: 0.8431 - val_loss: 0.3384 - val_accuracy: 0.8762\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4437 - accuracy: 0.8445 - val_loss: 0.3396 - val_accuracy: 0.8782\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4506 - accuracy: 0.8451 - val_loss: 0.3274 - val_accuracy: 0.8810\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4401 - accuracy: 0.8469 - val_loss: 0.3364 - val_accuracy: 0.8814\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4444 - accuracy: 0.8460 - val_loss: 0.3320 - val_accuracy: 0.8806\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4470 - accuracy: 0.8442 - val_loss: 0.3383 - val_accuracy: 0.8786\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4407 - accuracy: 0.8469 - val_loss: 0.3351 - val_accuracy: 0.8766\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.4329 - accuracy: 0.8474 - val_loss: 0.3461 - val_accuracy: 0.8778\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4411 - accuracy: 0.8454 - val_loss: 0.3259 - val_accuracy: 0.8850\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4426 - accuracy: 0.8445 - val_loss: 0.3317 - val_accuracy: 0.8774\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4420 - accuracy: 0.8484 - val_loss: 0.3223 - val_accuracy: 0.8872\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4445 - accuracy: 0.8456 - val_loss: 0.3308 - val_accuracy: 0.8776\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4417 - accuracy: 0.8467 - val_loss: 0.3309 - val_accuracy: 0.8772\n",
      "Epoch 62/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4407 - accuracy: 0.8465 - val_loss: 0.3366 - val_accuracy: 0.8752\n",
      "Epoch 63/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4364 - accuracy: 0.8472 - val_loss: 0.3210 - val_accuracy: 0.8808\n",
      "Epoch 64/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4385 - accuracy: 0.8472 - val_loss: 0.3305 - val_accuracy: 0.8810\n",
      "Epoch 65/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4371 - accuracy: 0.8488 - val_loss: 0.3312 - val_accuracy: 0.8818\n",
      "Epoch 66/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4375 - accuracy: 0.8461 - val_loss: 0.3261 - val_accuracy: 0.8832\n",
      "Epoch 67/100\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 0.4326 - accuracy: 0.8483 - val_loss: 0.3314 - val_accuracy: 0.8810\n",
      "Epoch 68/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4361 - accuracy: 0.8492 - val_loss: 0.3242 - val_accuracy: 0.8836\n",
      "Epoch 69/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.4340 - accuracy: 0.8476 - val_loss: 0.3355 - val_accuracy: 0.8768\n",
      "Epoch 70/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4329 - accuracy: 0.8487 - val_loss: 0.3209 - val_accuracy: 0.8812\n",
      "Epoch 71/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4296 - accuracy: 0.8513 - val_loss: 0.3232 - val_accuracy: 0.8808\n",
      "Epoch 72/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4385 - accuracy: 0.8476 - val_loss: 0.3215 - val_accuracy: 0.8856\n",
      "Epoch 73/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4360 - accuracy: 0.8470 - val_loss: 0.3372 - val_accuracy: 0.8770\n",
      "Epoch 74/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4351 - accuracy: 0.8474 - val_loss: 0.3340 - val_accuracy: 0.8770\n",
      "Epoch 75/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4366 - accuracy: 0.8492 - val_loss: 0.3306 - val_accuracy: 0.8772\n",
      "Epoch 76/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4319 - accuracy: 0.8495 - val_loss: 0.3249 - val_accuracy: 0.8812\n",
      "Epoch 77/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4304 - accuracy: 0.8499 - val_loss: 0.3258 - val_accuracy: 0.8814\n",
      "Epoch 78/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4277 - accuracy: 0.8509 - val_loss: 0.3239 - val_accuracy: 0.8822\n",
      "Epoch 79/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4334 - accuracy: 0.8480 - val_loss: 0.3236 - val_accuracy: 0.8840\n",
      "Epoch 80/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4306 - accuracy: 0.8494 - val_loss: 0.3309 - val_accuracy: 0.8798\n",
      "573/573 [==============================] - 1s 2ms/step - loss: 0.3302 - accuracy: 0.8844\n",
      "Building model with:\n",
      "Number of hidden layers: 4\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Epoch 1/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 1.9276 - accuracy: 0.5060 - val_loss: 0.5647 - val_accuracy: 0.7992\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.8560 - accuracy: 0.6941 - val_loss: 0.5014 - val_accuracy: 0.8188\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.7199 - accuracy: 0.7445 - val_loss: 0.4535 - val_accuracy: 0.8320\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.6543 - accuracy: 0.7698 - val_loss: 0.4413 - val_accuracy: 0.8378\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.6186 - accuracy: 0.7864 - val_loss: 0.4264 - val_accuracy: 0.8454\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5977 - accuracy: 0.7919 - val_loss: 0.4252 - val_accuracy: 0.8434\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5731 - accuracy: 0.8027 - val_loss: 0.4024 - val_accuracy: 0.8554\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5605 - accuracy: 0.8041 - val_loss: 0.4001 - val_accuracy: 0.8546\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5481 - accuracy: 0.8096 - val_loss: 0.3919 - val_accuracy: 0.8584\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.5476 - accuracy: 0.8102 - val_loss: 0.3888 - val_accuracy: 0.8630\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.5357 - accuracy: 0.8130 - val_loss: 0.3854 - val_accuracy: 0.8608\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5251 - accuracy: 0.8154 - val_loss: 0.3866 - val_accuracy: 0.8564\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.5250 - accuracy: 0.8180 - val_loss: 0.3691 - val_accuracy: 0.8664\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5068 - accuracy: 0.8226 - val_loss: 0.3740 - val_accuracy: 0.8702\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.5097 - accuracy: 0.8217 - val_loss: 0.3750 - val_accuracy: 0.8612\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.5024 - accuracy: 0.8251 - val_loss: 0.3610 - val_accuracy: 0.8682\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.5003 - accuracy: 0.8249 - val_loss: 0.3713 - val_accuracy: 0.8696\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4914 - accuracy: 0.8287 - val_loss: 0.3666 - val_accuracy: 0.8660\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4903 - accuracy: 0.8283 - val_loss: 0.3630 - val_accuracy: 0.8650\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4871 - accuracy: 0.8289 - val_loss: 0.3594 - val_accuracy: 0.8652\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4846 - accuracy: 0.8318 - val_loss: 0.3701 - val_accuracy: 0.8624\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.4837 - accuracy: 0.8313 - val_loss: 0.3547 - val_accuracy: 0.8704\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4824 - accuracy: 0.8313 - val_loss: 0.3604 - val_accuracy: 0.8688\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4737 - accuracy: 0.8321 - val_loss: 0.3490 - val_accuracy: 0.8716\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4768 - accuracy: 0.8355 - val_loss: 0.3554 - val_accuracy: 0.8714\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4732 - accuracy: 0.8346 - val_loss: 0.3532 - val_accuracy: 0.8734\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4741 - accuracy: 0.8362 - val_loss: 0.3455 - val_accuracy: 0.8702\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4638 - accuracy: 0.8356 - val_loss: 0.3470 - val_accuracy: 0.8708\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4661 - accuracy: 0.8383 - val_loss: 0.3395 - val_accuracy: 0.8780\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4650 - accuracy: 0.8382 - val_loss: 0.3422 - val_accuracy: 0.8790\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.4653 - accuracy: 0.8376 - val_loss: 0.3365 - val_accuracy: 0.8756\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4603 - accuracy: 0.8405 - val_loss: 0.3362 - val_accuracy: 0.8770\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4581 - accuracy: 0.8416 - val_loss: 0.3392 - val_accuracy: 0.8770\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4567 - accuracy: 0.8397 - val_loss: 0.3385 - val_accuracy: 0.8778\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4566 - accuracy: 0.8398 - val_loss: 0.3428 - val_accuracy: 0.8714\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4559 - accuracy: 0.8406 - val_loss: 0.3395 - val_accuracy: 0.8724\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4599 - accuracy: 0.8399 - val_loss: 0.3378 - val_accuracy: 0.8756\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4492 - accuracy: 0.8424 - val_loss: 0.3371 - val_accuracy: 0.8792\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4474 - accuracy: 0.8424 - val_loss: 0.3354 - val_accuracy: 0.8778\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4563 - accuracy: 0.8413 - val_loss: 0.3363 - val_accuracy: 0.8736\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4484 - accuracy: 0.8414 - val_loss: 0.3303 - val_accuracy: 0.8762\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4469 - accuracy: 0.8444 - val_loss: 0.3291 - val_accuracy: 0.8772\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4478 - accuracy: 0.8448 - val_loss: 0.3354 - val_accuracy: 0.8774\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4454 - accuracy: 0.8433 - val_loss: 0.3350 - val_accuracy: 0.8772\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4511 - accuracy: 0.8452 - val_loss: 0.3366 - val_accuracy: 0.8740\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 6s 5ms/step - loss: 0.4506 - accuracy: 0.8417 - val_loss: 0.3299 - val_accuracy: 0.8788\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4410 - accuracy: 0.8449 - val_loss: 0.3348 - val_accuracy: 0.8794\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4428 - accuracy: 0.8453 - val_loss: 0.3305 - val_accuracy: 0.8818\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4443 - accuracy: 0.8451 - val_loss: 0.3288 - val_accuracy: 0.8788\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4420 - accuracy: 0.8468 - val_loss: 0.3274 - val_accuracy: 0.8806\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4431 - accuracy: 0.8453 - val_loss: 0.3314 - val_accuracy: 0.8806\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4386 - accuracy: 0.8469 - val_loss: 0.3292 - val_accuracy: 0.8792\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4457 - accuracy: 0.8486 - val_loss: 0.3306 - val_accuracy: 0.8826\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4373 - accuracy: 0.8476 - val_loss: 0.3232 - val_accuracy: 0.8830\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4418 - accuracy: 0.8432 - val_loss: 0.3319 - val_accuracy: 0.8752\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4352 - accuracy: 0.8470 - val_loss: 0.3381 - val_accuracy: 0.8756\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4428 - accuracy: 0.8443 - val_loss: 0.3295 - val_accuracy: 0.8802\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4407 - accuracy: 0.8454 - val_loss: 0.3239 - val_accuracy: 0.8820\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4336 - accuracy: 0.8472 - val_loss: 0.3358 - val_accuracy: 0.8758\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4397 - accuracy: 0.8464 - val_loss: 0.3273 - val_accuracy: 0.8762\n",
      "Epoch 61/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.4366 - accuracy: 0.8466 - val_loss: 0.3310 - val_accuracy: 0.8730\n",
      "Epoch 62/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4307 - accuracy: 0.8478 - val_loss: 0.3368 - val_accuracy: 0.8712\n",
      "Epoch 63/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4314 - accuracy: 0.8481 - val_loss: 0.3200 - val_accuracy: 0.8814\n",
      "Epoch 64/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.4358 - accuracy: 0.8485 - val_loss: 0.3197 - val_accuracy: 0.8838\n",
      "Epoch 65/100\n",
      "1146/1146 [==============================] - 5s 5ms/step - loss: 0.4368 - accuracy: 0.8463 - val_loss: 0.3189 - val_accuracy: 0.8802\n",
      "Epoch 66/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4288 - accuracy: 0.8506 - val_loss: 0.3232 - val_accuracy: 0.8832\n",
      "Epoch 67/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4327 - accuracy: 0.8505 - val_loss: 0.3289 - val_accuracy: 0.8750\n",
      "Epoch 68/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4274 - accuracy: 0.8483 - val_loss: 0.3245 - val_accuracy: 0.8800\n",
      "Epoch 69/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4300 - accuracy: 0.8507 - val_loss: 0.3312 - val_accuracy: 0.8786\n",
      "Epoch 70/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4311 - accuracy: 0.8492 - val_loss: 0.3210 - val_accuracy: 0.8802\n",
      "Epoch 71/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4373 - accuracy: 0.8464 - val_loss: 0.3121 - val_accuracy: 0.8842\n",
      "Epoch 72/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4343 - accuracy: 0.8486 - val_loss: 0.3170 - val_accuracy: 0.8790\n",
      "Epoch 73/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4255 - accuracy: 0.8515 - val_loss: 0.3165 - val_accuracy: 0.8828\n",
      "Epoch 74/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4319 - accuracy: 0.8479 - val_loss: 0.3289 - val_accuracy: 0.8776\n",
      "Epoch 75/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4292 - accuracy: 0.8510 - val_loss: 0.3197 - val_accuracy: 0.8812\n",
      "Epoch 76/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4259 - accuracy: 0.8520 - val_loss: 0.3368 - val_accuracy: 0.8758\n",
      "Epoch 77/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4297 - accuracy: 0.8499 - val_loss: 0.3281 - val_accuracy: 0.8802\n",
      "Epoch 78/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4321 - accuracy: 0.8491 - val_loss: 0.3166 - val_accuracy: 0.8818\n",
      "Epoch 79/100\n",
      "1146/1146 [==============================] - 4s 4ms/step - loss: 0.4311 - accuracy: 0.8495 - val_loss: 0.3212 - val_accuracy: 0.8810\n",
      "Epoch 80/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4276 - accuracy: 0.8523 - val_loss: 0.3255 - val_accuracy: 0.8790\n",
      "Epoch 81/100\n",
      "1146/1146 [==============================] - 5s 4ms/step - loss: 0.4341 - accuracy: 0.8486 - val_loss: 0.3145 - val_accuracy: 0.8846\n",
      "573/573 [==============================] - 1s 1ms/step - loss: 0.3275 - accuracy: 0.8848\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f749d7dfb50>, as the constructor either does not set or modifies parameter n_hidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-44b42a470acd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mcallbacks_\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/envs/tf-gpu-py37/lib64/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/envs/tf-gpu-py37/lib64/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0;32m--> 762\u001b[0;31m                 **self.best_params_))\n\u001b[0m\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/envs/tf-gpu-py37/lib64/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/envs/tf-gpu-py37/lib64/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     96\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[1;32m     97\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                                (estimator, name))\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f749d7dfb50>, as the constructor either does not set or modifies parameter n_hidden"
     ]
    }
   ],
   "source": [
    "run_grid_search = True\n",
    "\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#build_fn_ = lambda n_hidden, n_neurons: build_model(n_hidden, n_neurons, learning_rate=8e-4, input_shape=[28,28], dropout=0.40)\n",
    "def build_fn_(n_hidden, n_neurons):\n",
    "    return build_model(n_hidden, n_neurons, learning_rate=8e-4, input_shape=[28,28], dropout=0.40)\n",
    "\n",
    "keras_clf = keras.wrappers.scikit_learn.KerasClassifier( build_fn_ )\n",
    "\n",
    "#param_grid = [\n",
    "#    { \"n_hidden\": [2],\n",
    "#      \"n_neurons\": [50,100] }\n",
    "#    ]\n",
    "param_grid = [\n",
    "    { \"n_hidden\": np.arange(1,5),\n",
    "      \"n_neurons\": [50,100] }\n",
    "    ]\n",
    "\n",
    "grid_search = GridSearchCV( keras_clf, param_grid, cv=3 )\n",
    "\n",
    "if run_grid_search:\n",
    "    callbacks_ = callbacks(patience=10)\n",
    "    print ( callbacks_ )\n",
    "\n",
    "    grid_search.fit( X_train_scaled, y_train, epochs=100, validation_data=(X_valid_scaled, y_valid), callbacks=callbacks_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with:\n",
      "Number of hidden layers: 3\n",
      "Number of neurons per layer: 100\n",
      "Learning rate: 0.0008\n",
      "Input shape: [28, 28]\n",
      "Dropout rate: 0.4\n",
      "Log dir: fashion_mnist_logs/run_2020_11_12-19_03_27\n",
      "[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f7458356a90>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f74507a9590>]\n",
      "Epoch 1/100\n",
      "   2/1719 [..............................] - ETA: 22:46 - loss: 5.5921 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 1.5887s). Check your callbacks.\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 1.1724 - accuracy: 0.6485 - val_loss: 0.4641 - val_accuracy: 0.8302\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.6579 - accuracy: 0.7684 - val_loss: 0.4249 - val_accuracy: 0.8436\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5889 - accuracy: 0.7903 - val_loss: 0.4171 - val_accuracy: 0.8406\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5585 - accuracy: 0.8021 - val_loss: 0.3844 - val_accuracy: 0.8608\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5372 - accuracy: 0.8069 - val_loss: 0.3820 - val_accuracy: 0.8592\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5208 - accuracy: 0.8132 - val_loss: 0.3720 - val_accuracy: 0.8594\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5064 - accuracy: 0.8213 - val_loss: 0.3657 - val_accuracy: 0.8666\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4988 - accuracy: 0.8208 - val_loss: 0.3553 - val_accuracy: 0.8734\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4909 - accuracy: 0.8254 - val_loss: 0.3440 - val_accuracy: 0.8734\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4827 - accuracy: 0.8279 - val_loss: 0.3473 - val_accuracy: 0.8700\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4769 - accuracy: 0.8290 - val_loss: 0.3492 - val_accuracy: 0.8758\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4740 - accuracy: 0.8303 - val_loss: 0.3452 - val_accuracy: 0.8680\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4689 - accuracy: 0.8319 - val_loss: 0.3314 - val_accuracy: 0.8784\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4622 - accuracy: 0.8359 - val_loss: 0.3457 - val_accuracy: 0.8724\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4600 - accuracy: 0.8362 - val_loss: 0.3327 - val_accuracy: 0.8744\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4579 - accuracy: 0.8349 - val_loss: 0.3415 - val_accuracy: 0.8704\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4517 - accuracy: 0.8383 - val_loss: 0.3328 - val_accuracy: 0.8734\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4503 - accuracy: 0.8397 - val_loss: 0.3239 - val_accuracy: 0.8810\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4507 - accuracy: 0.8388 - val_loss: 0.3352 - val_accuracy: 0.8718\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4466 - accuracy: 0.8421 - val_loss: 0.3270 - val_accuracy: 0.8782\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4492 - accuracy: 0.8403 - val_loss: 0.3257 - val_accuracy: 0.8818\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4420 - accuracy: 0.8411 - val_loss: 0.3218 - val_accuracy: 0.8828\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4402 - accuracy: 0.8416 - val_loss: 0.3120 - val_accuracy: 0.8820\n",
      "Epoch 24/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4394 - accuracy: 0.8435 - val_loss: 0.3260 - val_accuracy: 0.8784\n",
      "Epoch 25/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4358 - accuracy: 0.8449 - val_loss: 0.3246 - val_accuracy: 0.8748\n",
      "Epoch 26/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4386 - accuracy: 0.8429 - val_loss: 0.3134 - val_accuracy: 0.8808\n",
      "Epoch 27/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4374 - accuracy: 0.8443 - val_loss: 0.3244 - val_accuracy: 0.8762\n",
      "Epoch 28/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4336 - accuracy: 0.8461 - val_loss: 0.3243 - val_accuracy: 0.8780\n",
      "Epoch 29/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4332 - accuracy: 0.8466 - val_loss: 0.3178 - val_accuracy: 0.8786\n",
      "Epoch 30/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4314 - accuracy: 0.8476 - val_loss: 0.3210 - val_accuracy: 0.8792\n",
      "Epoch 31/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4313 - accuracy: 0.8478 - val_loss: 0.3170 - val_accuracy: 0.8808\n",
      "Epoch 32/100\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4310 - accuracy: 0.8480 - val_loss: 0.3134 - val_accuracy: 0.8812\n",
      "Epoch 33/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4281 - accuracy: 0.8456 - val_loss: 0.3140 - val_accuracy: 0.8824\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_39 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dropout_144 (Dropout)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dropout_145 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_146 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_147 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 99,710\n",
      "Trainable params: 99,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_final = None\n",
    "run_grid_search = False\n",
    "if run_grid_search: \n",
    "    print ( grid_search.best_params_ )\n",
    "    print ( grid_search.best_score_ )\n",
    "    #print ( grid_search.best_estimator_)\n",
    "    #model_gs = grid_search.best_estimator_.model\n",
    "    #model_final = model_gs\n",
    "else:\n",
    "    params = {'n_hidden': 3, 'n_neurons': 100}\n",
    "    model_final = build_model(**params, learning_rate=8e-4, input_shape=[28,28], dropout=0.40)\n",
    "    log_dir=\"fashion_mnist_logs\"\n",
    "    callbacks_ = callbacks(patience=10, log_dir=log_dir)\n",
    "    print ( callbacks_ )\n",
    "    model_final.fit( X_train_scaled, y_train, epochs=100, validation_data=(X_valid_scaled, y_valid), callbacks=callbacks_ )\n",
    "        \n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on training data (no dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 2s 992us/step - loss: 0.2933 - accuracy: 0.8913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29329633712768555, 0.8913454413414001]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.evaluate( X_train_scaled, y_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 994us/step - loss: 0.3562 - accuracy: 0.8699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35621726512908936, 0.8698999881744385]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.evaluate( X_test_scaled, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.save( \"model/fashion_mnist_model.h5\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KerasClassifier in module tensorflow.python.keras.wrappers.scikit_learn:\n",
      "\n",
      "class KerasClassifier(BaseWrapper)\n",
      " |  KerasClassifier(build_fn=None, **sk_params)\n",
      " |  \n",
      " |  Implementation of the scikit-learn classifier API for Keras.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KerasClassifier\n",
      " |      BaseWrapper\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  fit(self, x, y, **kwargs)\n",
      " |      Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x : array-like, shape `(n_samples, n_features)`\n",
      " |              Training samples where `n_samples` is the number of samples\n",
      " |              and `n_features` is the number of features.\n",
      " |          y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n",
      " |              True labels for `x`.\n",
      " |          **kwargs: dictionary arguments\n",
      " |              Legal arguments are the arguments of `Sequential.fit`\n",
      " |      \n",
      " |      Returns:\n",
      " |          history : object\n",
      " |              details about the training history at each epoch.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid shape for `y` argument.\n",
      " |  \n",
      " |  predict(self, x, **kwargs)\n",
      " |      Returns the class predictions for the given test data.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: array-like, shape `(n_samples, n_features)`\n",
      " |              Test samples where `n_samples` is the number of samples\n",
      " |              and `n_features` is the number of features.\n",
      " |          **kwargs: dictionary arguments\n",
      " |              Legal arguments are the arguments\n",
      " |              of `Sequential.predict_classes`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          preds: array-like, shape `(n_samples,)`\n",
      " |              Class predictions.\n",
      " |  \n",
      " |  predict_proba(self, x, **kwargs)\n",
      " |      Returns class probability estimates for the given test data.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: array-like, shape `(n_samples, n_features)`\n",
      " |              Test samples where `n_samples` is the number of samples\n",
      " |              and `n_features` is the number of features.\n",
      " |          **kwargs: dictionary arguments\n",
      " |              Legal arguments are the arguments\n",
      " |              of `Sequential.predict_classes`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          proba: array-like, shape `(n_samples, n_outputs)`\n",
      " |              Class probability estimates.\n",
      " |              In the case of binary classification,\n",
      " |              to match the scikit-learn API,\n",
      " |              will return an array of shape `(n_samples, 2)`\n",
      " |              (instead of `(n_sample, 1)` as in Keras).\n",
      " |  \n",
      " |  score(self, x, y, **kwargs)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: array-like, shape `(n_samples, n_features)`\n",
      " |              Test samples where `n_samples` is the number of samples\n",
      " |              and `n_features` is the number of features.\n",
      " |          y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n",
      " |              True labels for `x`.\n",
      " |          **kwargs: dictionary arguments\n",
      " |              Legal arguments are the arguments of `Sequential.evaluate`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          score: float\n",
      " |              Mean accuracy of predictions on `x` wrt. `y`.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the underlying model isn't configured to\n",
      " |              compute accuracy. You should pass `metrics=[\"accuracy\"]` to\n",
      " |              the `.compile()` method of the model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseWrapper:\n",
      " |  \n",
      " |  __init__(self, build_fn=None, **sk_params)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  check_params(self, params)\n",
      " |      Checks for user typos in `params`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          params: dictionary; the parameters to be checked\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if any member of `params` is not a valid argument.\n",
      " |  \n",
      " |  filter_sk_params(self, fn, override=None)\n",
      " |      Filters `sk_params` and returns those in `fn`'s arguments.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          fn : arbitrary function\n",
      " |          override: dictionary, values to override `sk_params`\n",
      " |      \n",
      " |      Returns:\n",
      " |          res : dictionary containing variables\n",
      " |              in both `sk_params` and `fn`'s arguments.\n",
      " |  \n",
      " |  get_params(self, **params)\n",
      " |      Gets parameters for this estimator.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **params: ignored (exists for API compatibility).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Dictionary of parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Sets the parameters of this estimator.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **params: Dictionary of parameter names mapped to their values.\n",
      " |      \n",
      " |      Returns:\n",
      " |          self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseWrapper:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.wrappers.scikit_learn.KerasClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
